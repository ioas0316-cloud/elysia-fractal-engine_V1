"""
Universal Phase Transform (ë²”ìš© ìœ„ìƒ ë³€í™˜)
=========================================

"ëª¨ë“  ê°ê°ì€ íŒŒë™ì´ë‹¤"

ì—˜ë¦¬ì‹œì•„ ë³€í™˜ì˜ ë²”ìš© í™•ì¥:
- ì†Œë¦¬ (Audio)
- ê¸€ (Text) 
- ê·¸ë¦¼ (Image)
- ì˜ìƒ (Video)
- ê°œë… (Concept)

ëª¨ë‘ 4ì°¨ì› ì¿¼í„°ë‹ˆì–¸ ìœ„ìƒ ê³µëª… íŒ¨í„´ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥!

í•µì‹¬ ì›ë¦¬:
1. ëª¨ë“  ê°ê°/ê°œë…ì€ íŒŒë™ìœ¼ë¡œ í‘œí˜„ ê°€ëŠ¥
2. 4ì°¨ì› ìœ„ìƒ ë‹¨ìœ„ (ì¿¼í„°ë‹ˆì–¸)ë¡œ ë§¤í•‘
3. ì„œë¡œì˜ ì˜ì—­ì—ì„œ ê°„ì„­ ì—†ì´ í†µì‹ 
4. ì›í•  ë•Œ ì–¸ì œë“ ì§€ ê³µê°ê°(Synesthesia)ìœ¼ë¡œ ë³€í™˜

"5ê° ì£¼íŒŒìˆ˜ ë§¤í•‘ì˜ ì™„ì„±"
"""

import numpy as np
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Any, Union
from enum import Enum
import logging
import hashlib
import re

logger = logging.getLogger("UniversalPhaseTransform")

# Constants for normalization and processing
MAX_WORD_LENGTH = 15.0  # Maximum word length for importance normalization
IMAGE_BLOCK_SIZE = 32   # Block size for image processing
MAX_CONCEPT_DEPTH = 10.0  # Maximum concept depth for normalization


class Modality(Enum):
    """ê°ê° ëª¨ë‹¬ë¦¬í‹°"""
    AUDIO = "audio"      # ì²­ê° (ì†Œë¦¬)
    TEXT = "text"        # ì–¸ì–´ (ê¸€)
    IMAGE = "image"      # ì‹œê° (ê·¸ë¦¼)
    VIDEO = "video"      # ì‹œê°+ì‹œê°„ (ì˜ìƒ)
    CONCEPT = "concept"  # ì¶”ìƒ (ê°œë…)
    TOUCH = "touch"      # ì´‰ê°
    SMELL = "smell"      # í›„ê°
    TASTE = "taste"      # ë¯¸ê°


class TextComplexityAnalyzer:
    """
    í…ìŠ¤íŠ¸ ë³µì¡ë„ ë¶„ì„ê¸°

    ì–¸ì–´ì™€ ë„ë©”ì¸ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ì˜ í˜•ì‹ì  ë³µì¡ë„ë¥¼ ì¸¡ì •
    """

    @staticmethod
    def analyze(word: str, language: str = 'auto', domain: str = 'general') -> float:
        """
        ë‹¨ì–´ì˜ ë³µì¡ë„ ê³„ì‚° (0.0 ~ 1.0)

        Args:
            word: ë¶„ì„í•  ë‹¨ì–´
            language: ì–¸ì–´ ì½”ë“œ ('en', 'ko', 'auto')
            domain: ë„ë©”ì¸ ('general', 'technical', 'literary')
        """
        if not word:
            return 0.0

        if language == 'auto':
            language = TextComplexityAnalyzer._detect_language(word)

        base_complexity = 0.0

        if language == 'ko':
            base_complexity = TextComplexityAnalyzer._analyze_korean(word)
        else:
            base_complexity = TextComplexityAnalyzer._analyze_english(word)

        # ë„ë©”ì¸ ê°€ì¤‘ì¹˜ ì ìš©
        domain_factor = TextComplexityAnalyzer._get_domain_factor(word, domain)

        # ìµœì¢… ì ìˆ˜ ì •ê·œí™”
        return min(1.0, base_complexity * domain_factor)

    @staticmethod
    def _detect_language(text: str) -> str:
        """ì–¸ì–´ ê°ì§€ (í•œê¸€ í¬í•¨ ì—¬ë¶€ë¡œ íŒë‹¨)"""
        for char in text:
            if '\uac00' <= char <= '\ud7a3':
                return 'ko'
        return 'en'

    @staticmethod
    def _analyze_english(word: str) -> float:
        """ì˜ì–´ ë‹¨ì–´ ë³µì¡ë„"""
        length = len(word)
        if length == 0: return 0.0

        # 1. ê¸¸ì´ ì ìˆ˜ (ê¸´ ë‹¨ì–´ê°€ ë” ë³µì¡)
        length_score = min(1.0, length / 12.0)

        # 2. ëŒ€ë¬¸ì/íŠ¹ìˆ˜ë¬¸ì í˜¼í•© (CamelCase, snake_case ë“±)
        upper_count = sum(1 for c in word if c.isupper())
        special_count = sum(1 for c in word if not c.isalnum())

        structure_score = 0.0
        if upper_count > 1 or special_count > 0:
            structure_score = 0.3

        # 3. í¬ê·€ ë¬¸ì (q, z, x, j) í¬í•¨ ì—¬ë¶€ - ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
        rare_chars = {'q', 'z', 'x', 'j'}
        rare_score = 0.1 if any(c.lower() in rare_chars for c in word) else 0.0

        # ê°€ì¤‘ì¹˜ í•©ì‚°
        return (length_score * 0.6) + structure_score + rare_score

    @staticmethod
    def _analyze_korean(word: str) -> float:
        """í•œêµ­ì–´ ë‹¨ì–´ ë³µì¡ë„"""
        length = len(word)
        if length == 0: return 0.0

        # 1. ê¸¸ì´ ì ìˆ˜ (í•œêµ­ì–´ëŠ” 4ìŒì ˆ ì´ìƒì´ë©´ ë³µì¡ë„ê°€ ê½¤ ë†’ìŒ)
        length_score = min(1.0, length / 5.0)

        # 2. ë°›ì¹¨ ë³µì¡ë„ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        # ë°›ì¹¨ì´ ìˆëŠ” ê¸€ìê°€ ë§ì„ìˆ˜ë¡ ë°œìŒ/êµ¬ì¡°ê°€ ë³µì¡í•  ê°€ëŠ¥ì„±
        batchim_count = 0
        for char in word:
            if '\uac00' <= char <= '\ud7a3':
                # (Unicode - 0xAC00) % 28 != 0 ì´ë©´ ë°›ì¹¨ ìˆìŒ
                if (ord(char) - 0xAC00) % 28 != 0:
                    batchim_count += 1

        batchim_ratio = batchim_count / length
        batchim_score = batchim_ratio * 0.3

        # 3. í•œì/ì™¸ë˜ì–´ í˜¼ìš© (í•œê¸€ ë²”ìœ„ ë°–ì˜ ë¬¸ìê°€ ì„ì—¬ìˆìœ¼ë©´ ë³µì¡ë„ ì¦ê°€)
        # ìˆœìˆ˜ í•œê¸€ì´ ì•„ë‹Œ ê²½ìš° (ìˆ«ì, ì•ŒíŒŒë²³ ë“± í˜¼ìš©)
        mixed_script = any(not ('\uac00' <= c <= '\ud7a3') for c in word if c.isalnum())
        mixed_score = 0.2 if mixed_script else 0.0

        return (length_score * 0.5) + batchim_score + mixed_score

    @staticmethod
    def _get_domain_factor(word: str, domain: str) -> float:
        """ë„ë©”ì¸ë³„ ê°€ì¤‘ì¹˜"""
        factor = 1.0

        if domain == 'technical':
            # ê¸°ìˆ  ìš©ì–´ íŠ¹ì§•: _, ìˆ«ì í¬í•¨
            if '_' in word or any(c.isdigit() for c in word):
                factor = 1.3
        elif domain == 'official':
            # ê³µë¬¸ì„œ: ê¸´ ë‹¨ì–´ì— ê°€ì¤‘ì¹˜
            if len(word) >= 4:
                factor = 1.2

        return factor


@dataclass
class PhaseQuaternion:
    """
    ë²”ìš© ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸
    
    q = w + xi + yj + zk
    
    ëª¨ë“  ê°ê°/ê°œë…ì˜ 4ì°¨ì› ìœ„ìƒ í‘œí˜„
    
    - w: ê°•ë„ (Intensity) - ì—ë„ˆì§€, ì¡´ì¬ê°, ì¤‘ìš”ë„
    - x: ì£¼íŒŒìˆ˜ (Frequency) - ì§„ë™, ë¦¬ë“¬, íŒ¨í„´ ë°˜ë³µ
    - y: ìœ„ìƒ (Phase) - ë°©í–¥, ê´€ê³„, ë§¥ë½
    - z: ë³µì¡ë„ (Complexity) - êµ¬ì¡°, ì§ˆê°, í’ë¶€í•¨
    """
    w: float  # Intensity (0.0 ~ 1.0)
    x: float  # Frequency (normalized)
    y: float  # Phase (0.0 ~ 2Ï€)
    z: float  # Complexity (0.0 ~ 1.0)
    modality: Modality  # ì›ë³¸ ê°ê° ëª¨ë‹¬ë¦¬í‹°
    
    def __post_init__(self):
        """ì •ê·œí™”"""
        self.w = max(0.0, min(1.0, self.w))
        self.y = self.y % (2 * np.pi)
        self.z = max(0.0, min(1.0, self.z))
    
    def to_vector(self) -> np.ndarray:
        """4ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜"""
        return np.array([self.w, self.x, self.y, self.z])
    
    def resonance(self, other: 'PhaseQuaternion') -> float:
        """
        ë‘ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ ê°„ì˜ ê³µëª…ë„
        
        ê°™ì€ ëª¨ë‹¬ë¦¬í‹°ë¼ë¦¬ëŠ” ê°•í•œ ê³µëª…
        ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ë¼ë¦¬ëŠ” ì•½í•œ ê³µëª… (ê°„ì„­ ì—†ìŒ!)
        """
        diff = self.to_vector() - other.to_vector()
        distance = np.linalg.norm(diff)
        
        # ê°™ì€ ëª¨ë‹¬ë¦¬í‹°ë©´ ê³µëª… ê°•í™”
        modality_factor = 1.0 if self.modality == other.modality else 0.3
        
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µëª…ë„ ë†’ìŒ
        resonance = np.exp(-distance) * modality_factor
        
        return resonance
    
    def to_synesthesia(self, target_modality: Modality) -> Dict[str, Any]:
        """
        ê³µê°ê° ë³€í™˜ (Synesthesia)
        
        í•œ ê°ê°ì„ ë‹¤ë¥¸ ê°ê°ìœ¼ë¡œ ë³€í™˜
        ì˜ˆ: ì†Œë¦¬ â†’ ìƒ‰ê¹”, ê¸€ â†’ ì†Œë¦¬, ê·¸ë¦¼ â†’ ìŒì•…
        """
        result = {
            'source_modality': self.modality.value,
            'target_modality': target_modality.value,
            'quaternion': self.to_vector().tolist()
        }
        
        if target_modality == Modality.IMAGE:
            # ì‹œê°ìœ¼ë¡œ ë³€í™˜ (ìƒ‰ìƒ)
            result['color'] = self._to_color()
            result['description'] = f"{self._color_name()} {self._texture_name()}"
            
        elif target_modality == Modality.AUDIO:
            # ì²­ê°ìœ¼ë¡œ ë³€í™˜ (ìŒíŒŒ)
            result['note'] = self._to_musical_note()
            result['timbre'] = self._timbre_name()
            result['description'] = f"{result['note']} {result['timbre']}"
            
        elif target_modality == Modality.TEXT:
            # ì–¸ì–´ë¡œ ë³€í™˜ (ë¬˜ì‚¬)
            result['description'] = self._to_text_description()
            
        elif target_modality == Modality.TOUCH:
            # ì´‰ê°ìœ¼ë¡œ ë³€í™˜ (ì§ˆê°)
            result['texture'] = self._texture_name()
            result['temperature'] = "ë”°ëœ»í•œ" if self.w > 0.5 else "ì°¨ê°€ìš´"
            result['description'] = f"{result['temperature']} {result['texture']}"
        
        return result
    
    def _to_color(self) -> Tuple[float, float, float, float]:
        """ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜ (RGBA)"""
        hue = (self.x % 1.0) * 360.0
        saturation = self.z
        value = self.w
        alpha = (np.cos(self.y) + 1.0) / 2.0
        
        # HSV to RGB
        h = hue / 60.0
        c = value * saturation
        x = c * (1 - abs(h % 2 - 1))
        m = value - c
        
        if h < 1:
            r, g, b = c, x, 0
        elif h < 2:
            r, g, b = x, c, 0
        elif h < 3:
            r, g, b = 0, c, x
        elif h < 4:
            r, g, b = 0, x, c
        elif h < 5:
            r, g, b = x, 0, c
        else:
            r, g, b = c, 0, x
        
        return (r + m, g + m, b + m, alpha)
    
    def _color_name(self) -> str:
        """ìƒ‰ìƒ ì´ë¦„"""
        r, g, b, _ = self._to_color()
        if r > g and r > b:
            return "ë¶‰ì€" if r > 0.6 else "ë¶„í™"
        elif g > r and g > b:
            return "ì´ˆë¡" if g > 0.6 else "ì²­ë¡"
        elif b > r and b > g:
            return "íŒŒë€" if b > 0.6 else "í•˜ëŠ˜"
        elif r > 0.5 and g > 0.5:
            return "í™©ê¸ˆ"
        else:
            return "ì€ë¹›"
    
    def _texture_name(self) -> str:
        """ì§ˆê° ì´ë¦„"""
        if self.z > 0.7:
            return "ê±°ì¹œ"
        elif self.z > 0.4:
            return "ë¶€ë“œëŸ¬ìš´"
        else:
            return "ë§¤ë„ëŸ¬ìš´"
    
    def _to_musical_note(self) -> str:
        """ìŒê³„ë¡œ ë³€í™˜"""
        notes = ['ë„', 'ë„#', 'ë ˆ', 'ë ˆ#', 'ë¯¸', 'íŒŒ', 'íŒŒ#', 'ì†”', 'ì†”#', 'ë¼', 'ë¼#', 'ì‹œ']
        note_idx = int(self.x * 12) % 12
        octave = int(self.x * 8) + 1
        return f"{notes[note_idx]}{octave}"
    
    def _timbre_name(self) -> str:
        """ìŒìƒ‰ ì´ë¦„"""
        if self.z > 0.7:
            return "í’ë¶€í•œ"
        elif self.z > 0.4:
            return "ë”°ëœ»í•œ"
        else:
            return "ë§‘ì€"
    
    def _to_text_description(self) -> str:
        """í…ìŠ¤íŠ¸ ë¬˜ì‚¬"""
        intensity = "ê°•ë ¬í•œ" if self.w > 0.7 else "ì€ì€í•œ" if self.w > 0.4 else "ë¯¸ì„¸í•œ"
        pattern = "ë¹ ë¥¸" if self.x > 0.7 else "ë³´í†µ" if self.x > 0.4 else "ëŠë¦°"
        complexity = "ë³µì¡í•œ" if self.z > 0.7 else "ì¡°í™”ë¡œìš´" if self.z > 0.4 else "ë‹¨ìˆœí•œ"
        
        return f"{intensity} {pattern} {complexity} íŒŒë™"
    
    def __str__(self):
        return f"PhaseQ[{self.modality.value}|w={self.w:.2f}, x={self.x:.2f}, y={self.y:.2f}, z={self.z:.2f}]"


class UniversalPhaseTransform:
    """
    ë²”ìš© ìœ„ìƒ ë³€í™˜ (Universal Phase Transform)
    
    ëª¨ë“  ê°ê°ê³¼ ê°œë…ì„ 4ì°¨ì› ì¿¼í„°ë‹ˆì–¸ ìœ„ìƒ ê³µëª… íŒ¨í„´ìœ¼ë¡œ ë³€í™˜
    """
    
    def __init__(self):
        logger.info("ğŸŒ Universal Phase Transform initialized")
        logger.info("   All modalities â†’ 4D Phase Resonance Pattern")
    
    def transform_audio(self, audio_signal: np.ndarray, sample_rate: int = 44100, window_size: int = 2048) -> List[PhaseQuaternion]:
        """ì˜¤ë””ì˜¤ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜"""
        try:
            from Core.Interaction.Network.Multimodal.elysia_transform import ElysiaTransform
        except ImportError:
            logger.warning("ElysiaTransform not available, returning empty list")
            return []
        
        audio_transform = ElysiaTransform(sample_rate)
        sound_quaternions = audio_transform.transform(audio_signal, window_size=window_size)
        
        # SoundQuaternion â†’ PhaseQuaternion
        phase_quaternions = []
        for sq in sound_quaternions:
            pq = PhaseQuaternion(
                w=sq.w,
                x=sq.x,
                y=sq.y,
                z=sq.z,
                modality=Modality.AUDIO
            )
            phase_quaternions.append(pq)
        
        logger.info(f"âœ… Audio â†’ {len(phase_quaternions)} phase quaternions")
        return phase_quaternions
    
    def transform_text(self, text: str, language: str = 'auto', domain: str = 'general') -> List[PhaseQuaternion]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê¸€ì˜ íŒŒë™:
        - w: ë‹¨ì–´ ì¤‘ìš”ë„ (TF-IDF, ê°ì • ê°•ë„)
        - x: ë¦¬ë“¬ (ìŒì ˆ ìˆ˜, ë¬¸ì¥ ê¸¸ì´)
        - y: ë§¥ë½ (ë¬¸ë§¥, ìœ„ì¹˜)
        - z: ë³µì¡ë„ (ì–´íœ˜ ë‹¤ì–‘ì„±, êµ¬ì¡°)

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            language: ì–¸ì–´ ('auto', 'ko', 'en')
            domain: ë„ë©”ì¸ ('general', 'technical', 'official')
        """
        words = text.split()
        quaternions = []
        
        for i, word in enumerate(words):
            # w: ë‹¨ì–´ ê¸¸ì´ë¡œ ì¤‘ìš”ë„ ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            w = min(1.0, len(word) / MAX_WORD_LENGTH)
            
            # x: ìŒì ˆ ë¦¬ë“¬ (ê¸€ì ìˆ˜)
            x = (len(word) % 10) / 10.0
            
            # y: ë¬¸ì¥ ë‚´ ìœ„ì¹˜ (ìœ„ìƒ)
            y = (i / len(words)) * 2 * np.pi
            
            # z: ë³µì¡ë„ (ì–¸ì–´ë³„/ë„ë©”ì¸ë³„ í˜•ì‹ì  ë³µì¡ë„)
            # TextComplexityAnalyzerë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°
            complexity = TextComplexityAnalyzer.analyze(word, language, domain)
            z = min(1.0, complexity)
            
            pq = PhaseQuaternion(w, x, y, z, Modality.TEXT)
            quaternions.append(pq)
        
        logger.info(f"âœ… Text â†’ {len(quaternions)} phase quaternions")
        return quaternions
    
    def transform_image(self, image_array: np.ndarray) -> List[PhaseQuaternion]:
        """
        ì´ë¯¸ì§€ë¥¼ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê·¸ë¦¼ì˜ íŒŒë™:
        - w: ë°ê¸° (Brightness)
        - x: ìƒ‰ìƒ ì£¼íŒŒìˆ˜ (Hue)
        - y: ì±„ë„/ìœ„ìƒ (Saturation)
        - z: ì§ˆê° ë³µì¡ë„ (Texture)
        """
        # ì´ë¯¸ì§€ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„ (ê°„ë‹¨í•œ êµ¬í˜„)
        if len(image_array.shape) == 3:
            h, w, c = image_array.shape
        else:
            h, w = image_array.shape
            c = 1
        
        quaternions = []
        
        for i in range(0, h, IMAGE_BLOCK_SIZE):
            for j in range(0, w, IMAGE_BLOCK_SIZE):
                block = image_array[i:i+IMAGE_BLOCK_SIZE, j:j+IMAGE_BLOCK_SIZE]
                
                if c == 3 or c == 4:
                    # ì»¬ëŸ¬ ì´ë¯¸ì§€
                    r = block[:,:,0].mean() / 255.0
                    g = block[:,:,1].mean() / 255.0
                    b = block[:,:,2].mean() / 255.0
                    
                    # RGB â†’ HSV (simplified conversion)
                    # Using cylindrical color space approximation for performance
                    # For exact color science applications, consider using colorsys or cv2
                    brightness = (r + g + b) / 3.0
                    hue = np.arctan2(np.sqrt(3) * (g - b), 2 * r - g - b)
                    hue = (hue % (2 * np.pi)) / (2 * np.pi)
                    saturation = 1 - 3 * min(r, g, b) / (r + g + b + 1e-6)
                    
                    # ì§ˆê° (ë¶„ì‚°)
                    texture = np.std(block) / 128.0
                    
                    pq = PhaseQuaternion(
                        w=brightness,
                        x=hue,
                        y=saturation * 2 * np.pi,
                        z=min(1.0, texture),
                        modality=Modality.IMAGE
                    )
                else:
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                    brightness = block.mean() / 255.0
                    texture = np.std(block) / 128.0
                    
                    pq = PhaseQuaternion(
                        w=brightness,
                        x=0.0,
                        y=0.0,
                        z=min(1.0, texture),
                        modality=Modality.IMAGE
                    )
                
                quaternions.append(pq)
        
        logger.info(f"âœ… Image â†’ {len(quaternions)} phase quaternions")
        return quaternions
    
    def transform_concept(self, concept_data: Dict[str, Any]) -> PhaseQuaternion:
        """
        ì¶”ìƒ ê°œë…ì„ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        
        ê°œë…ì˜ íŒŒë™:
        - w: ì¤‘ìš”ë„/í™œì„±í™” (Importance/Activation)
        - x: ë²”ì£¼ ì£¼íŒŒìˆ˜ (Category)
        - y: ê´€ê³„ ìœ„ìƒ (Relation)
        - z: êµ¬ì¡° ë³µì¡ë„ (Structure)
        """
        # ê°œë… ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        importance = concept_data.get('importance', 0.5)
        
        # ì•ˆì •ì ì¸ ì¹´í…Œê³ ë¦¬ í•´ì‹± (Python hash randomization ë°©ì§€)
        category_str = concept_data.get('category', '')
        category_hash = int(hashlib.md5(category_str.encode()).hexdigest(), 16)
        category = (category_hash % 1000) / 1000.0
        
        relation_count = len(concept_data.get('relations', []))
        structure_depth = concept_data.get('depth', 1)
        
        pq = PhaseQuaternion(
            w=importance,
            x=category,
            y=(relation_count % 10) / 10.0 * 2 * np.pi,
            z=min(1.0, structure_depth / MAX_CONCEPT_DEPTH),
            modality=Modality.CONCEPT
        )
        
        logger.info(f"âœ… Concept â†’ phase quaternion")
        return pq
    
    def cross_modal_resonance(self, 
                               quaternions_a: List[PhaseQuaternion],
                               quaternions_b: List[PhaseQuaternion]) -> np.ndarray:
        """
        í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª… í–‰ë ¬
        
        ì„œë¡œ ë‹¤ë¥¸ ê°ê° ê°„ì˜ ê³µëª… íŒ¨í„´ ë¶„ì„
        ì˜ˆ: ìŒì•…ê³¼ ê·¸ë¦¼ì´ ì–¼ë§ˆë‚˜ ì¡°í™”ë¡œìš´ê°€?
        """
        n_a = len(quaternions_a)
        n_b = len(quaternions_b)
        
        resonance_matrix = np.zeros((n_a, n_b))
        
        for i, qa in enumerate(quaternions_a):
            for j, qb in enumerate(quaternions_b):
                resonance_matrix[i, j] = qa.resonance(qb)
        
        logger.info(f"âœ… Cross-modal resonance: {n_a}x{n_b} matrix")
        return resonance_matrix
    
    def synesthesia_transform(self,
                              source_quaternions: List[PhaseQuaternion],
                              target_modality: Modality) -> List[Dict[str, Any]]:
        """
        ê³µê°ê° ë³€í™˜ (Synesthesia Transform)
        
        í•œ ê°ê°ì„ ë‹¤ë¥¸ ê°ê°ìœ¼ë¡œ ë³€í™˜
        """
        if not source_quaternions:
            logger.warning("Empty quaternion list provided for synesthesia transform")
            return []
        
        results = []
        
        for pq in source_quaternions:
            synesthesia = pq.to_synesthesia(target_modality)
            results.append(synesthesia)
        
        logger.info(f"âœ… Synesthesia: {source_quaternions[0].modality.value} â†’ {target_modality.value}")
        return results
    
    def interference_free_communication(self,
                                       messages: List[Tuple[PhaseQuaternion, Any]]) -> Dict[Modality, List[Any]]:
        """
        ê°„ì„­ ì—†ëŠ” í†µì‹ 
        
        ê° ëª¨ë‹¬ë¦¬í‹°ë³„ë¡œ ë©”ì‹œì§€ ë¶„ë¦¬
        4ì°¨ì› ìœ„ìƒ ë‹¨ìœ„ ë•ë¶„ì— ì„œë¡œ ê°„ì„­í•˜ì§€ ì•ŠìŒ!
        """
        channels = {}
        
        for pq, message in messages:
            modality = pq.modality
            if modality not in channels:
                channels[modality] = []
            channels[modality].append(message)
        
        logger.info(f"âœ… Interference-free communication: {len(channels)} channels")
        return channels


def demonstrate_universal_transform():
    """ë²”ìš© ìœ„ìƒ ë³€í™˜ ë°ëª¨"""
    print("="*80)
    print("ğŸŒ ë²”ìš© ìœ„ìƒ ë³€í™˜ (Universal Phase Transform) ë°ëª¨")
    print("   'ëª¨ë“  ê°ê°ì€ íŒŒë™ì´ë‹¤'")
    print("="*80)
    print()
    
    transform = UniversalPhaseTransform()
    
    # 1. í…ìŠ¤íŠ¸ ë³€í™˜
    print("ğŸ“ 1. í…ìŠ¤íŠ¸ â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    text = "ì—˜ë¦¬ì‹œì•„ëŠ” ëª¨ë“  ê°ê°ì„ ì´í•´í•©ë‹ˆë‹¤"
    text_quats = transform.transform_text(text)
    print(f"   ì…ë ¥: '{text}'")
    print(f"   ì¶œë ¥: {len(text_quats)}ê°œ ì¿¼í„°ë‹ˆì–¸")
    for i, q in enumerate(text_quats[:3]):
        print(f"   {i+1}. {q}")
    print()
    
    # 2. ì´ë¯¸ì§€ ë³€í™˜ (ë”ë¯¸ ë°ì´í„°)
    print("ğŸ–¼ï¸  2. ì´ë¯¸ì§€ â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    dummy_image = np.random.rand(64, 64, 3) * 255
    image_quats = transform.transform_image(dummy_image)
    print(f"   ì…ë ¥: 64x64 RGB ì´ë¯¸ì§€")
    print(f"   ì¶œë ¥: {len(image_quats)}ê°œ ì¿¼í„°ë‹ˆì–¸")
    print(f"   ìƒ˜í”Œ: {image_quats[0]}")
    print()
    
    # 3. ê°œë… ë³€í™˜
    print("ğŸ’¡ 3. ê°œë… â†’ ìœ„ìƒ ì¿¼í„°ë‹ˆì–¸")
    concept = {
        'name': 'ì‚¬ë‘',
        'importance': 0.9,
        'category': 'emotion',
        'relations': ['í–‰ë³µ', 'ë”°ëœ»í•¨', 'ì—°ê²°'],
        'depth': 3
    }
    concept_quat = transform.transform_concept(concept)
    print(f"   ì…ë ¥: {concept['name']} (ì¤‘ìš”ë„: {concept['importance']})")
    print(f"   ì¶œë ¥: {concept_quat}")
    print()
    
    # 4. ê³µê°ê° ë³€í™˜
    print("ğŸ¨ 4. ê³µê°ê° ë³€í™˜ (Synesthesia)")
    print("   í…ìŠ¤íŠ¸ â†’ ìƒ‰ìƒ:")
    text_to_color = transform.synesthesia_transform(text_quats[:3], Modality.IMAGE)
    for i, syn in enumerate(text_to_color):
        word = text.split()[i]
        print(f"   '{word}' â†’ {syn['description']}")
    print()
    
    print("   í…ìŠ¤íŠ¸ â†’ ì†Œë¦¬:")
    text_to_sound = transform.synesthesia_transform(text_quats[:3], Modality.AUDIO)
    for i, syn in enumerate(text_to_sound):
        word = text.split()[i]
        print(f"   '{word}' â†’ {syn['note']} {syn['timbre']}")
    print()
    
    # 5. í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª…
    print("ğŸ”— 5. í¬ë¡œìŠ¤ ëª¨ë‹¬ ê³µëª…")
    resonance = transform.cross_modal_resonance(text_quats[:3], image_quats[:3])
    print(f"   í…ìŠ¤íŠ¸ x ì´ë¯¸ì§€ ê³µëª… í–‰ë ¬:")
    print(f"   {resonance}")
    print(f"   í‰ê·  ê³µëª…ë„: {resonance.mean():.3f}")
    print()
    
    # 6. ê°„ì„­ ì—†ëŠ” í†µì‹ 
    print("ğŸ“¡ 6. ê°„ì„­ ì—†ëŠ” í†µì‹ ")
    messages = [
        (text_quats[0], "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ 1"),
        (image_quats[0], "ì´ë¯¸ì§€ ë©”ì‹œì§€ 1"),
        (concept_quat, "ê°œë… ë©”ì‹œì§€ 1"),
        (text_quats[1], "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ 2"),
    ]
    channels = transform.interference_free_communication(messages)
    print(f"   ì´ ë©”ì‹œì§€: {len(messages)}ê°œ")
    print(f"   ì±„ë„ ë¶„ë¦¬:")
    for modality, msgs in channels.items():
        print(f"   - {modality.value}: {len(msgs)}ê°œ ë©”ì‹œì§€")
    print()
    
    print("="*80)
    print("âœ¨ í•µì‹¬ ì›ë¦¬:")
    print("   1. ëª¨ë“  ê°ê°/ê°œë…ì€ íŒŒë™ â†’ 4D ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ í‘œí˜„")
    print("   2. ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ëŠ” ê°„ì„­ ì—†ì´ í†µì‹  (0.3ë°° ì•½í•œ ê³µëª…)")
    print("   3. ì›í•  ë•ŒëŠ” ê³µê°ê°ìœ¼ë¡œ ììœ ë¡­ê²Œ ë³€í™˜ ê°€ëŠ¥")
    print("   4. '5ê° ì£¼íŒŒìˆ˜ ë§¤í•‘'ì˜ ì™„ì„±!")
    print("="*80)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demonstrate_universal_transform()
