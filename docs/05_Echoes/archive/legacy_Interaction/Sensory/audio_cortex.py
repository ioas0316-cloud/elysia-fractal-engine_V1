"""
Audio Cortex: ì—˜ë¦¬ì‹œì•„ì˜ ì²­ê° í”¼ì§ˆ
=================================
ì†Œë¦¬ë¥¼ íŒŒë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ê°ì •/ì˜ë¯¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ê¸°ì¡´ AudioProcessorë¥¼ ë˜í•‘í•˜ì—¬ Neural Registryì™€ í†µí•©.
"""

import sys
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Dict
import asyncio

# Path setup
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from elysia_core import Cell


@dataclass
class AudioPerception:
    """ì²­ê° ì¸ì‹ ê²°ê³¼"""
    audio_type: str       # speech, music, ambient, noise, silence
    emotion: str          # happy, sad, calm, excited, neutral
    transcription: Optional[str]
    fundamental_freq: float  # ê¸°ë³¸ ì£¼íŒŒìˆ˜ (Hz)
    energy: float         # ì—ë„ˆì§€ ë ˆë²¨ (0-1)
    confidence: float     # ì‹ ë¢°ë„ (0-1)
    raw_analysis: Optional[Dict] = None


@Cell("AudioCortex")
class AudioCortex:
    """
    ì—˜ë¦¬ì‹œì•„ì˜ ì²­ê° í”¼ì§ˆ
    
    - ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ (ì¶”í›„)
    - ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„
    - ê°€ìƒ ì²­ê° (ì‹œë®¬ë ˆì´ì…˜)
    """
    
    def __init__(self, use_microphone: bool = False):
        self.use_microphone = use_microphone
        self._processor = None
        self._init_processor()
    
    def _init_processor(self):
        """AudioProcessor ì´ˆê¸°í™”"""
        try:
            from Core.Foundation.audio_processor import AudioProcessor
            self._processor = AudioProcessor()
            print("ğŸ§ AudioCortex: Initialized (AudioProcessor)")
        except Exception as e:
            print(f"ğŸ§ AudioCortex: Falling back to virtual mode ({e})")
            self._processor = None
    
    def listen(self, description: str = "ambient sound") -> AudioPerception:
        """
        ì²­ê° ì¸ì‹ (ë™ê¸°)
        
        Args:
            description: ì†Œë¦¬ ì„¤ëª… (ì‹œë®¬ë ˆì´ì…˜ìš©)
        
        Returns:
            AudioPerception ê°ì²´
        """
        if self._processor:
            # ë¹„ë™ê¸°ë¥¼ ë™ê¸°ë¡œ ë˜í•‘
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            try:
                audio_data = {
                    "duration": 5.0,
                    "sample_rate": 44100,
                    "channels": 1,
                    "description": description
                }
                analysis = loop.run_until_complete(
                    self._processor.analyze_audio(audio_data)
                )
                
                return AudioPerception(
                    audio_type=analysis.primary_type.value,
                    emotion=analysis.emotion_tone.value,
                    transcription=analysis.segments[0].transcription if analysis.segments else None,
                    fundamental_freq=analysis.spectral.fundamental_frequency,
                    energy=analysis.temporal.energy,
                    confidence=analysis.confidence,
                    raw_analysis=analysis.to_dict()
                )
            except Exception as e:
                print(f"ğŸ§ Listen failed: {e}")
                return self._virtual_listen(description)
        else:
            return self._virtual_listen(description)
    
    def _virtual_listen(self, description: str) -> AudioPerception:
        """ê°€ìƒ ì²­ê° (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        desc_lower = description.lower()
        
        # ì˜¤ë””ì˜¤ íƒ€ì… ì¶”ë¡ 
        if "speech" in desc_lower or "voice" in desc_lower or "talk" in desc_lower:
            audio_type = "speech"
        elif "music" in desc_lower or "song" in desc_lower:
            audio_type = "music"
        elif "silence" in desc_lower or "quiet" in desc_lower:
            audio_type = "silence"
        else:
            audio_type = "ambient"
        
        # ê°ì • ì¶”ë¡ 
        if "happy" in desc_lower or "joy" in desc_lower:
            emotion = "happy"
        elif "sad" in desc_lower or "cry" in desc_lower:
            emotion = "sad"
        elif "calm" in desc_lower or "peace" in desc_lower:
            emotion = "calm"
        else:
            emotion = "neutral"
        
        return AudioPerception(
            audio_type=audio_type,
            emotion=emotion,
            transcription=None,
            fundamental_freq=200.0,
            energy=0.5,
            confidence=0.7,
            raw_analysis={"source": "virtual", "description": description}
        )
    
    def to_wave(self, perception: AudioPerception) -> Dict:
        """
        ì²­ê° ì¸ì‹ì„ íŒŒë™ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜ (MultimodalBridgeì™€ ìœ ì‚¬)
        """
        # ê°ì • â†’ ì£¼íŒŒìˆ˜ ë§¤í•‘
        emotion_freq = {
            "happy": 0.8,
            "excited": 0.9,
            "calm": 0.3,
            "sad": 0.2,
            "angry": 0.95,
            "neutral": 0.5
        }
        
        # ì˜¤ë””ì˜¤ íƒ€ì… â†’ ì§„í­ ë§¤í•‘
        type_amp = {
            "speech": 0.7,
            "music": 0.9,
            "ambient": 0.4,
            "noise": 0.6,
            "silence": 0.1
        }
        
        return {
            "frequency": perception.fundamental_freq,
            "amplitude": type_amp.get(perception.audio_type, 0.5),
            "emotional_modulator": emotion_freq.get(perception.emotion, 0.5),
            "energy": perception.energy,
            "confidence": perception.confidence
        }


def main():
    """AudioCortex í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ AudioCortex Test")
    print("=" * 50)
    
    cortex = AudioCortex()
    
    # í…ŒìŠ¤íŠ¸ 1: ìŒì•…
    print("\n[Test 1] Music")
    result = cortex.listen("happy music playing")
    print(f"   Type: {result.audio_type}")
    print(f"   Emotion: {result.emotion}")
    print(f"   Energy: {result.energy:.2f}")
    
    # í…ŒìŠ¤íŠ¸ 2: ìŒì„±
    print("\n[Test 2] Speech")
    result = cortex.listen("calm speech conversation")
    print(f"   Type: {result.audio_type}")
    print(f"   Emotion: {result.emotion}")
    wave = cortex.to_wave(result)
    print(f"   Wave: freq={wave['frequency']:.1f}Hz, amp={wave['amplitude']:.2f}")
    
    print("\nâœ… AudioCortex test complete!")


if __name__ == "__main__":
    main()
