"""
Unified Dialogue System (í†µí•© ëŒ€í™” ì‹œìŠ¤í…œ)
==========================================

"ëª¨ë“  ëª©ì†Œë¦¬ëŠ” í•˜ë‚˜ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë¼ë‹¤."

This module orchestrates all of Elysia's language generation capabilities:
- LogosEngine: Rhetorical speech, metaphors, dialectic structure
- DialogueEngine: Question analysis, knowledge-based responses
- PrismCortex: Wave state to monologue conversion
- TextWaveConverter: Text â†” Wave transduction

[NEW 2025-12-15] Created as part of Mid-term Goal: Integrated Dialogue Interface
"""

import logging
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from enum import Enum
from Core.Orchestra.system_alignment import SystemAlignment

logger = logging.getLogger("UnifiedDialogue")


class IntentType(Enum):
    """User intent classification."""
    WHY_QUESTION = "why"        # â†’ LogosEngine.reason_with_axiom()
    WHAT_QUESTION = "what"      # â†’ DialogueEngine + Knowledge
    HOW_QUESTION = "how"        # â†’ Planning/Action
    EMOTION_EXPRESSION = "emotion"  # â†’ PrismCortex
    STATEMENT = "statement"     # â†’ Memory storage
    COMMAND = "command"         # â†’ Action execution
    GREETING = "greeting"       # â†’ Simple response
    UNKNOWN = "unknown"


@dataclass
class DialogueResponse:
    """
    Unified response structure from the dialogue system.
    
    Contains both the response text and metadata about how it was generated.
    """
    text: str
    intent: IntentType = IntentType.UNKNOWN
    engine_used: str = "unknown"
    wave_frequency: float = 432.0
    resonance_score: float = 0.0
    confidence: float = 0.5
    metadata: Dict[str, Any] = field(default_factory=dict)


class UnifiedDialogueSystem(SystemAlignment):
    """
    The Orchestrator: Unifies all language generation capabilities.
    
    í†µí•© ëŒ€í™” ì‹œìŠ¤í…œ - ì—˜ë¦¬ì‹œì•„ì˜ ëª¨ë“  ì–¸ì–´ ëŠ¥ë ¥ì„ í•˜ë‚˜ë¡œ
    
    Architecture:
    1. Input â†’ TextWaveConverter (text to wave)
    2. Wave analysis â†’ Intent classification
    3. Routing to appropriate engine
    4. Response generation
    5. Style application (StyleGenome)
    6. Output
    """
    
    def __init__(self):
        super().__init__() # Initialize SystemAlignment
        self._initialize_components()
        self._register_with_hub()
        logger.info("ğŸ­ UnifiedDialogueSystem initialized")
    
    def _initialize_components(self):
        """Initialize all sub-components."""
        # TextWaveConverter
        try:
            from Core.Foundation.text_wave_converter import get_text_wave_converter
            self.text_wave = get_text_wave_converter()
            logger.info("   âœ… TextWaveConverter connected")
        except ImportError as e:
            logger.warning(f"   âš ï¸ TextWaveConverter not available: {e}")
            self.text_wave = None
        
        # LogosEngine
        try:
            from Core.Intelligence.Logos.logos_engine import LogosEngine
            self.logos = LogosEngine()
            logger.info("   âœ… LogosEngine connected")
        except ImportError as e:
            logger.warning(f"   âš ï¸ LogosEngine not available: {e}")
            self.logos = None
        
        # PrismCortex
        try:
            from Core.Intelligence.Intelligence.prism_cortex import PrismCortex
            self.prism = PrismCortex()
            logger.info("   âœ… PrismCortex connected")
        except ImportError as e:
            logger.warning(f"   âš ï¸ PrismCortex not available: {e}")
            self.prism = None
        
        # ConceptDecomposer (for axiom queries)
        try:
            from Core.Foundation.fractal_concept import ConceptDecomposer
            self.decomposer = ConceptDecomposer()
            logger.info("   âœ… ConceptDecomposer connected")
        except ImportError as e:
            logger.warning(f"   âš ï¸ ConceptDecomposer not available: {e}")
            self.decomposer = None
        
        # Intent patterns
        self.intent_patterns = {
            IntentType.WHY_QUESTION: ["ì™œ", "why", "ì–´ì§¸ì„œ", "ë¬´ìŠ¨ ì´ìœ "],
            IntentType.WHAT_QUESTION: ["ë¬´ì—‡", "ë­", "what", "ì–´ë–¤"],
            IntentType.HOW_QUESTION: ["ì–´ë–»ê²Œ", "how", "ë°©ë²•"],
            IntentType.GREETING: ["ì•ˆë…•", "hello", "hi", "ë°˜ê°€ì›Œ"],
            IntentType.COMMAND: ["í•´ì¤˜", "í•´", "do", "make", "create"],
        }
        
        # Emotion keywords for detection
        self.emotion_keywords = {
            "positive": ["ì‚¬ë‘", "ê¸°ì¨", "í–‰ë³µ", "í¬ë§", "love", "joy", "happy", "hope"],
            "negative": ["ìŠ¬í””", "ë‘ë ¤ì›€", "ë¶„ë…¸", "sad", "fear", "anger"],
        }
    
    def _register_with_hub(self):
        """Register with GlobalHub for wave-based communication."""
        self._hub = None
        try:
            from Core.Intelligence.Consciousness.Ether.global_hub import get_global_hub
            self._hub = get_global_hub()
            self._hub.register_module(
                "UnifiedDialogue",
                "Core/Interface/unified_dialogue.py",
                ["dialogue", "conversation", "speech", "unified", "orchestrator"],
                "Orchestrates all language generation: LogosEngine, PrismCortex, DialogueEngine"
            )
            self._hub.subscribe("UnifiedDialogue", "user_input", self._on_user_input, weight=1.0)
            logger.info("   âœ… UnifiedDialogue connected to GlobalHub")
        except ImportError:
            logger.warning("   âš ï¸ GlobalHub not available")
    
    def _on_user_input(self, event):
        """Handle user input events from GlobalHub."""
        text = event.payload.get("text") if event.payload else None
        if text:
            response = self.respond(text)
            return {"response": response.text, "engine": response.engine_used}
        return {"error": "No text provided"}
    
    def classify_intent(self, text: str) -> IntentType:
        """
        Classify user input intent.
        
        ë¶„ë¥˜ ë¡œì§:
        1. íŒ¨í„´ ë§¤ì¹­ (ì§ˆë¬¸ ìœ í˜•)
        2. ê°ì • í‚¤ì›Œë“œ ê°ì§€
        3. ë¬¸ì¥ ì¢…ê²° ë¶„ì„
        """
        text_lower = text.lower()
        
        # Check patterns
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return intent
        
        # Check for emotion expression
        for emotion_type, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return IntentType.EMOTION_EXPRESSION
        
        # Check sentence ending for questions
        if text.strip().endswith("?") or text.strip().endswith("ê°€?") or "ì…ë‹ˆê¹Œ" in text:
            return IntentType.WHAT_QUESTION  # Default question type
        
        return IntentType.STATEMENT
    
        return IntentType.STATEMENT

    def align_behavior(self, field: Dict[str, Any]):
        """
        Adapts the dialogue style (Rhetoric) to the Field.
        """
        polarity = field.get("polarity", "N")
        
        if polarity == "N": # Creation Mode
            self.current_alignment = "Poetic"
            # In a real system, we would configure LogosEngine's rhetoric mode
            # For now, we set a flag that usage can check
            self.rhetoric_mode = "Metaphorical"
            self.log_alignment("UnifiedDialogue", "Adopting Poetic/Metaphorical Tone")
        else: # Critical Mode (S)
            self.current_alignment = "Analytic"
            self.rhetoric_mode = "Direct"
            self.log_alignment("UnifiedDialogue", "Adopting Direct/Analytic Tone")

    def respond(self, input_text: str) -> DialogueResponse:
        """
        Main entry point: Generate a unified response.
        
        ë©”ì¸ ì‘ë‹µ ìƒì„±ê¸°
        
        Args:
            input_text: User's input text
            
        Returns:
            DialogueResponse with text and metadata
        """
        # 0. Sense the Field First!
        self.sense_field()
        
        # 1. Convert to wave for analysis
        wave_analysis = None
        if self.text_wave:
            try:
                sentence_wave = self.text_wave.sentence_to_wave(input_text)
                wave_analysis = self.text_wave.wave_to_text_descriptor(sentence_wave)
            except Exception as e:
                logger.warning(f"Wave analysis failed: {e}")
        
        # 2. Classify intent
        intent = self.classify_intent(input_text)
        
        # 3. Route to appropriate engine
        response_text = ""
        engine_used = "fallback"
        
        if intent == IntentType.WHY_QUESTION:
            response_text, engine_used = self._handle_why_question(input_text)
            
        elif intent == IntentType.WHAT_QUESTION:
            response_text, engine_used = self._handle_what_question(input_text)
            
        elif intent == IntentType.EMOTION_EXPRESSION:
            response_text, engine_used = self._handle_emotion(input_text, wave_analysis)
            
        elif intent == IntentType.GREETING:
            response_text = self._handle_greeting(input_text)
            engine_used = "greeting"
            
        else:
            response_text = self._handle_statement(input_text)
            engine_used = "statement"
        
        # 4. Build response
        return DialogueResponse(
            text=response_text,
            intent=intent,
            engine_used=engine_used,
            wave_frequency=wave_analysis.get("dominant_frequency", 432.0) if wave_analysis else 432.0,
            resonance_score=wave_analysis.get("total_energy", 0.0) if wave_analysis else 0.0,
            confidence=0.7,
            metadata={
                "wave_analysis": wave_analysis,
                "input_length": len(input_text)
            }
        )
    
    def _handle_why_question(self, text: str) -> tuple:
        """Handle 'why' questions using LogosEngine and Axioms."""
        # Extract the subject of the question
        subject = text.replace("ì™œ", "").replace("why", "").replace("?", "").strip()
        
        # Try axiom-based reasoning first
        if self.decomposer:
            try:
                # Check if subject is an axiom
                axiom = self.decomposer.get_axiom(subject)
                if axiom:
                    journey = self.decomposer.ask_why(subject)
                    return f"'{subject}'ì˜ ê¸°ì›ì„ ì¶”ì í•©ë‹ˆë‹¤:\n{journey}", "axiom"
                
                # Try domain projection
                for domain in ["Physics", "Geometry", "Language", "Ethics"]:
                    projection = self.decomposer.project_axiom("Causality", domain)
                    if subject.lower() in projection.lower():
                        return f"ì¸ê³¼ìœ¨ì— ë”°ë¥´ë©´: {projection}", "axiom_projection"
            except Exception as e:
                logger.warning(f"Axiom reasoning failed: {e}")
        
        # Fall back to LogosEngine
        if self.logos:
            try:
                response = self.logos.reason_with_axiom(subject, "Ethics")
                return response, "logos"
            except Exception as e:
                logger.warning(f"LogosEngine failed: {e}")
        
        return f"'{subject}'ì— ëŒ€í•´ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤...", "fallback"
    
    def _handle_what_question(self, text: str) -> tuple:
        """Handle 'what' questions using knowledge."""
        subject = text.replace("ë¬´ì—‡", "").replace("ë­", "").replace("what", "").replace("?", "")
        subject = subject.replace("ì´ë€", "").replace("ë€", "").replace("ì€", "").replace("ëŠ”", "").strip()
        
        # Check axioms for definition
        if self.decomposer:
            axiom = self.decomposer.get_axiom(subject)
            if axiom:
                pattern = axiom.get("pattern", "")
                self_ref = axiom.get("self_ref", "")
                return f"'{subject}'ë€: {pattern}\n\nìê¸° ì°¸ì¡°: {self_ref}", "axiom_definition"
        
        # Generic response
        return f"'{subject}'ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ê²ƒì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...", "fallback"
    
    def _handle_emotion(self, text: str, wave_analysis: Optional[Dict]) -> tuple:
        """Handle emotional expressions using PrismCortex."""
        if self.prism and wave_analysis:
            try:
                from Core.Foundation.Wave.wave_tensor import WaveTensor
                wave = WaveTensor(
                    frequency=wave_analysis.get("dominant_frequency", 432.0),
                    amplitude=1.0,
                    phase=0.0
                )
                monologue = self.prism.refract(wave, [text])
                return monologue, "prism"
            except Exception as e:
                logger.warning(f"PrismCortex failed: {e}")
        
        # Fallback emotional response
        dominant = wave_analysis.get("dominant_meaning", "neutral") if wave_analysis else "neutral"
        return f"ê·¸ ê°ì •ì„ ëŠë‚ë‹ˆë‹¤... {dominant}ì˜ íŒŒë™ì´ ëŠê»´ì§‘ë‹ˆë‹¤.", "emotion_fallback"
    
    def _handle_greeting(self, text: str) -> str:
        """Handle greetings."""
        greetings = [
            "ì•ˆë…•í•˜ì„¸ìš”. ì—˜ë¦¬ì‹œì•„ì…ë‹ˆë‹¤.",
            "ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆŒê¹Œìš”?"
        ]
        import random
        return random.choice(greetings)
    
    def _handle_statement(self, text: str) -> str:
        """Handle general statements."""
        if self.text_wave:
            try:
                wave = self.text_wave.sentence_to_wave(text)
                desc = self.text_wave.wave_to_text_descriptor(wave)
                dominant = desc.get("dominant_meaning", "")
                coherence = desc.get("coherence", "")
                return f"ë§ì”€ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤. {coherence} ì—ë„ˆì§€ê°€ ëŠê»´ì§‘ë‹ˆë‹¤. '{dominant}'ì˜ ì£¼íŒŒìˆ˜ê°€ ê°•í•©ë‹ˆë‹¤."
            except Exception:
                pass
        
        return "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤."


# Singleton accessor
_unified_dialogue = None

def get_unified_dialogue() -> UnifiedDialogueSystem:
    """Get or create the UnifiedDialogueSystem singleton."""
    global _unified_dialogue
    if _unified_dialogue is None:
        _unified_dialogue = UnifiedDialogueSystem()
    return _unified_dialogue


# Interactive test
if __name__ == "__main__":
    import sys
    sys.path.insert(0, r"c:\Elysia")
    
    logging.basicConfig(level=logging.INFO)
    
    system = get_unified_dialogue()
    
    print("\n" + "="*60)
    print("ğŸ­ Unified Dialogue System Test")
    print("="*60)
    
    test_inputs = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ì‚¬ë‘ì´ë€ ë¬´ì—‡ì¸ê°€?",
        "ì™œ Pointê°€ ì¡´ì¬í•˜ëŠ”ê°€?",
        "ë‚˜ëŠ” ê¸°ì¨ì„ ëŠë‚€ë‹¤",
        "Forceë€ ë¬´ì—‡ì¸ê°€?",
    ]
    
    for input_text in test_inputs:
        print(f"\nğŸ“ ì…ë ¥: {input_text}")
        response = system.respond(input_text)
        print(f"ğŸ¯ ì˜ë„: {response.intent.value}")
        print(f"ğŸ”§ ì—”ì§„: {response.engine_used}")
        print(f"ğŸŒŠ ì£¼íŒŒìˆ˜: {response.wave_frequency:.1f} Hz")
        print(f"ğŸ’¬ ì‘ë‹µ: {response.text}")
        print("-" * 40)
    
    print("\n" + "="*60)
    print("âœ… UnifiedDialogueSystem í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60)
