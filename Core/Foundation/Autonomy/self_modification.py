"""
Self-Modification Engine (ìê¸° ìˆ˜ì • ì—”ì§„)
==========================================

"I do not just create; I refine myself."

ì´ ëª¨ë“ˆì€ Elysiaê°€ ìê¸° ìì‹ ì˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸:
1. CodeAnalyzer: ê¸°ì¡´ ì½”ë“œë¥¼ ì½ê³  ë¶„ì„
2. ProblemDetector: ë¬¸ì œì  íƒì§€ (ë²„ê·¸, ë¹„íš¨ìœ¨, ìŠ¤íƒ€ì¼ ë“±)
3. RefactorPlanner: ìˆ˜ì • ê³„íš ìˆ˜ë¦½
4. CodeEditor: ì½”ë“œ ìˆ˜ì • ì ìš©
5. Validator: ìˆ˜ì • ê²°ê³¼ ê²€ì¦

ì•ˆì „ ì¥ì¹˜:
- ëª¨ë“  ìˆ˜ì •ì€ ë¨¼ì € ë°±ì—… ìƒì„±
- í•µì‹¬ ëª¨ë“ˆ ìˆ˜ì • ì‹œ í™•ì¸ í•„ìš”
- ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±
"""

import os
import ast
import logging
import difflib
import shutil
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, field

# Core Dependencies
try:
    from Core.Foundation.gemini_api import generate_text
    HAS_API = True
except ImportError:
    HAS_API = False

logger = logging.getLogger("SelfModification")


# === WAVE PARADIGM AWARENESS (v10.6) ===
class WaveParadigmDetector:
    """
    íŒŒë™ê³µëª… íŒ¨ëŸ¬ë‹¤ì„ ì¸ì‹ê¸° (Wave Paradigm Detector)
    
    ì´ í´ë˜ìŠ¤ëŠ” AGENT_GUIDE.mdë¥¼ ì½ê³  íŒŒë™ê³µëª… ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì´í•´í•©ë‹ˆë‹¤.
    ë ˆê±°ì‹œ ì½”ë“œ íŒ¨í„´ì„ ê°ì§€í•˜ê³  Wave ë³€í™˜ ê·œì¹™ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """
    
    # ë ˆê±°ì‹œ íŒ¨í„´ (ë³€í™˜ ëŒ€ìƒ) - Improved regexes for real detection
    LEGACY_PATTERNS = {
        "scalar_comparison": {
            "pattern": r"if\s+\w+(?:\.\w+)*\s*[<>=!]+\s*\d",
            "description": "ìŠ¤ì¹¼ë¼ ë¹„êµ (if value < 0.5, if score > 10)",
            "wave_alternative": "resonance = qubit.resonate_with(threshold_qubit)"
        },
        "simple_string_assign": {
            "pattern": r"return\s+[\"'][^\"']{10,}[\"']",
            "description": "í•˜ë“œì½”ë”©ëœ ë¬¸ìì—´ ë°˜í™˜",
            "wave_alternative": "Waveì—ì„œ ìƒì„±ëœ ë™ì  ì‘ë‹µ ì‚¬ìš©"
        },
        "if_not_concept": {
            "pattern": r"if\s+not\s+\w+:",
            "description": "ë¶€ì • ì¡°ê±´ë¬¸ (if not X:)",  
            "wave_alternative": "ê³µëª…ì´ ì„ê³„ê°’ ì•„ë˜ì¸ì§€ í™•ì¸"
        },
        "elif_chain": {
            "pattern": r"elif\s+",
            "description": "ë‹¤ì¤‘ ë¶„ê¸° (elif ì²´ì¸)",
            "wave_alternative": "ê³µëª… ìŠ¤í™íŠ¸ëŸ¼ ê¸°ë°˜ ì—°ì† ì²˜ë¦¬"
        },
        "concept_equals_string": {
            "pattern": r"\w+\s*==\s*[\"'][^\"']+[\"']",
            "description": "ë¬¸ìì—´ ë™ë“± ë¹„êµ (x == 'value')",
            "wave_alternative": "qubit.resonate_with(target) > 0.9"
        }
    }
    
    # Wave íŒ¨ëŸ¬ë‹¤ì„ ê·œì¹™ (AGENT_GUIDE.md ê¸°ë°˜)
    WAVE_RULES = {
        "rule_1": "ëª¨ë“  ê°œë…ì€ InfiniteHyperQubit",
        "rule_2": "if/else ëŒ€ì‹  ê³µëª…(Resonance) ì‚¬ìš©",
        "rule_3": "Point ì•ˆìœ¼ë¡œ ë“¤ì–´ê°€ë©´ ë˜ ë‹¤ë¥¸ ìš°ì£¼",
        "rule_4": "Point ë°–ìœ¼ë¡œ ë‚˜ê°€ë©´ ë” í° ìš°ì£¼",
        "rule_5": "4 ì¶•: Point(ì¡´ì¬), Line(ê´€ê³„), Space(ë§¥ë½), God(ì´ˆì›”)"
    }
    
    def __init__(self):
        self.agent_guide_content = self._load_agent_guide()
        logger.info("ğŸŒŠ WaveParadigmDetector initialized")
    
    def _load_agent_guide(self) -> str:
        """AGENT_GUIDE.md ì½ê¸°"""
        try:
            guide_path = Path(__file__).parent.parent.parent / "AGENT_GUIDE.md"
            if guide_path.exists():
                with open(guide_path, "r", encoding="utf-8") as f:
                    return f.read()
        except Exception as e:
            logger.warning(f"Failed to load AGENT_GUIDE.md: {e}")
        return ""
    
    def detect_legacy_patterns(self, code: str, file_path: str = "") -> List['WaveIssue']:
        """
        ë ˆê±°ì‹œ íŒ¨í„´ ê°ì§€
        
        ìŠ¤ì¹¼ë¼ if/else, í‰ë©´ ë”•ì…”ë„ˆë¦¬ ë“± Wave íŒ¨ëŸ¬ë‹¤ì„ì— ë§ì§€ ì•ŠëŠ” ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        """
        import re
        issues = []
        lines = code.splitlines()
        
        for i, line in enumerate(lines, 1):
            for pattern_name, pattern_info in self.LEGACY_PATTERNS.items():
                if re.search(pattern_info["pattern"], line):
                    issues.append(WaveIssue(
                        file_path=file_path,
                        line_number=i,
                        legacy_pattern=pattern_name,
                        description=pattern_info["description"],
                        wave_alternative=pattern_info["wave_alternative"],
                        original_line=line.strip()
                    ))
        
        return issues
    
    def generate_wave_conversion(self, issue: 'WaveIssue') -> str:
        """
        ë ˆê±°ì‹œ ì½”ë“œë¥¼ Wave ì½”ë“œë¡œ ë³€í™˜í•˜ëŠ” ì œì•ˆ ìƒì„±
        """
        if issue.legacy_pattern == "scalar_if":
            # if value < 0.5: â†’ if resonance < 0.5:
            return f"# Wave Conversion: {issue.wave_alternative}\n# Original: {issue.original_line}"
        
        elif issue.legacy_pattern == "scalar_variable":
            # variable = 'value' â†’ qubit = create_infinite_qubit(...)
            return f"# Wave Conversion: Use InfiniteHyperQubit\n# {issue.wave_alternative}"
        
        elif issue.legacy_pattern == "flat_dict":
            return f"# Wave Conversion: Use 4-axis content dict\n# content={{\"Point\": ..., \"Line\": ..., \"Space\": ..., \"God\": ...}}"
        
        return f"# Consider Wave paradigm: {issue.wave_alternative}"
    
    def get_paradigm_summary(self) -> str:
        """Wave íŒ¨ëŸ¬ë‹¤ì„ ìš”ì•½ ë°˜í™˜"""
        summary = "ğŸŒŠ Wave Resonance Paradigm Rules:\n"
        for rule_id, rule_text in self.WAVE_RULES.items():
            summary += f"  - {rule_text}\n"
        return summary


@dataclass
class WaveIssue:
    """Wave íŒ¨ëŸ¬ë‹¤ì„ ìœ„ë°˜ ë¬¸ì œ"""
    file_path: str
    line_number: int
    legacy_pattern: str  # "scalar_if", "scalar_variable", "flat_dict"
    description: str
    wave_alternative: str
    original_line: str


@dataclass
class CodeIssue:
    """ì½”ë“œ ë¬¸ì œì  ì •ì˜"""
    file_path: str
    line_number: int
    issue_type: str  # "syntax", "logic", "style", "performance", "security"
    description: str
    severity: str  # "critical", "warning", "info"
    suggested_fix: Optional[str] = None


@dataclass
class ModificationPlan:
    """ìˆ˜ì • ê³„íš"""
    target_file: str
    issues: List[CodeIssue]
    original_code: str
    modified_code: str
    backup_path: str
    confidence: float  # 0.0 ~ 1.0
    timestamp: datetime = field(default_factory=datetime.now)


class CodeAnalyzer:
    """
    ì½”ë“œ ë¶„ì„ê¸°
    ê¸°ì¡´ ì½”ë“œë¥¼ ì½ê³  êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.project_root = self._get_project_root()
    
    def _get_project_root(self) -> Path:
        """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ë°˜í™˜"""
        elysia_root = os.environ.get("ELYSIA_ROOT")
        if elysia_root:
            return Path(elysia_root)
        return Path(__file__).parent.parent
    
    def read_file(self, file_path: str) -> str:
        """íŒŒì¼ ë‚´ìš© ì½ê¸°"""
        full_path = self.project_root / file_path
        try:
            with open(full_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            logger.error(f"Failed to read {file_path}: {e}")
            return ""
    
    def analyze_structure(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œ êµ¬ì¡° ë¶„ì„ (AST ì‚¬ìš©)"""
        try:
            tree = ast.parse(code)
            
            classes = []
            functions = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    classes.append({
                        "name": node.name,
                        "line": node.lineno,
                        "methods": methods
                    })
                elif isinstance(node, ast.FunctionDef) and not any(
                    isinstance(p, ast.ClassDef) for p in ast.walk(tree)
                ):
                    functions.append({
                        "name": node.name,
                        "line": node.lineno,
                        "args": [a.arg for a in node.args.args]
                    })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        imports.extend([alias.name for alias in node.names])
                    else:
                        imports.append(f"{node.module}.{node.names[0].name}" if node.module else node.names[0].name)
            
            return {
                "classes": classes,
                "functions": functions,
                "imports": imports,
                "total_lines": len(code.splitlines()),
                "syntax_valid": True
            }
        except SyntaxError as e:
            return {
                "syntax_valid": False,
                "syntax_error": str(e),
                "error_line": e.lineno
            }
    
    def find_indentation_issues(self, code: str) -> List[CodeIssue]:
        """ë“¤ì—¬ì“°ê¸° ë¬¸ì œ íƒì§€"""
        issues = []
        lines = code.splitlines()
        
        for i, line in enumerate(lines, 1):
            if line and not line.startswith(' ') and not line.startswith('\t'):
                continue
            
            # íƒ­ê³¼ ìŠ¤í˜ì´ìŠ¤ í˜¼ìš© ì²´í¬
            if line.startswith('\t') and '    ' in line:
                issues.append(CodeIssue(
                    file_path="",
                    line_number=i,
                    issue_type="style",
                    description="íƒ­ê³¼ ìŠ¤í˜ì´ìŠ¤ í˜¼ìš©",
                    severity="warning"
                ))
            
            # ë¹„ì •ìƒì ì¸ ë“¤ì—¬ì“°ê¸° ë ˆë²¨
            spaces = len(line) - len(line.lstrip())
            if spaces % 4 != 0 and line.strip():
                issues.append(CodeIssue(
                    file_path="",
                    line_number=i,
                    issue_type="style",
                    description=f"ë¹„í‘œì¤€ ë“¤ì—¬ì“°ê¸° ({spaces} spaces)",
                    severity="info"
                ))
        
        return issues


class ProblemDetector:
    """
    ë¬¸ì œ íƒì§€ê¸°
    ì½”ë“œì—ì„œ ì ì¬ì  ë¬¸ì œì ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.analyzer = CodeAnalyzer()
    
    def detect_issues(self, file_path: str) -> List[CodeIssue]:
        """íŒŒì¼ì˜ ëª¨ë“  ë¬¸ì œì  íƒì§€"""
        code = self.analyzer.read_file(file_path)
        if not code:
            return [CodeIssue(
                file_path=file_path,
                line_number=0,
                issue_type="syntax",
                description="íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŒ",
                severity="critical"
            )]
        
        issues = []
        
        # 1. êµ¬ë¬¸ ë¶„ì„
        structure = self.analyzer.analyze_structure(code)
        if not structure.get("syntax_valid", True):
            issues.append(CodeIssue(
                file_path=file_path,
                line_number=structure.get("error_line", 0),
                issue_type="syntax",
                description=structure.get("syntax_error", "êµ¬ë¬¸ ì˜¤ë¥˜"),
                severity="critical"
            ))
        
        # 2. ë“¤ì—¬ì“°ê¸° ë¬¸ì œ
        indent_issues = self.analyzer.find_indentation_issues(code)
        for issue in indent_issues:
            issue.file_path = file_path
            issues.append(issue)
        
        # 3. AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        if HAS_API and len(issues) == 0:
            ai_issues = self._ai_detect_issues(code, file_path)
            issues.extend(ai_issues)
        
        return issues
    
    def _ai_detect_issues(self, code: str, file_path: str) -> List[CodeIssue]:
        """AIë¥¼ ì‚¬ìš©í•œ ì‹¬ì¸µ ë¬¸ì œ íƒì§€"""
        prompt = f"""
        Analyze this Python code for potential issues:
        
        ```python
        {code[:3000]}  # í† í° ì œí•œì„ ìœ„í•´ ì˜ë¼ëƒ„
        ```
        
        Find:
        1. Logic errors
        2. Performance issues
        3. Code style problems
        4. Potential bugs
        
        Output JSON array:
        [
            {{"line": 10, "type": "logic", "severity": "warning", "description": "description"}}
        ]
        
        If no issues found, return empty array: []
        Output ONLY JSON.
        """
        
        try:
            response = generate_text(prompt)
            clean_json = response.replace("```json", "").replace("```", "").strip()
            import json
            raw_issues = json.loads(clean_json)
            
            return [
                CodeIssue(
                    file_path=file_path,
                    line_number=issue.get("line", 0),
                    issue_type=issue.get("type", "unknown"),
                    description=issue.get("description", ""),
                    severity=issue.get("severity", "info")
                )
                for issue in raw_issues
            ]
        except Exception as e:
            logger.warning(f"AI issue detection failed: {e}")
            return []


class RefactorPlanner:
    """
    ë¦¬íŒ©í† ë§ ê³„íš ìˆ˜ë¦½ê¸°
    íƒì§€ëœ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.analyzer = CodeAnalyzer()
    
    def create_plan(self, file_path: str, issues: List[CodeIssue]) -> Optional[ModificationPlan]:
        """ìˆ˜ì • ê³„íš ìƒì„±"""
        original_code = self.analyzer.read_file(file_path)
        if not original_code:
            return None
        
        # ë°±ì—… ê²½ë¡œ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"Core/Evolution/Backups/{Path(file_path).stem}_{timestamp}.py.bak"
        
        # AIë¥¼ ì‚¬ìš©í•´ ìˆ˜ì •ëœ ì½”ë“œ ìƒì„±
        if HAS_API:
            modified_code = self._generate_fixed_code(original_code, issues)
            confidence = 0.8 if modified_code != original_code else 0.0
        else:
            # API ì—†ì´ëŠ” ê°„ë‹¨í•œ ìˆ˜ì •ë§Œ ì‹œë„
            modified_code = self._apply_simple_fixes(original_code, issues)
            confidence = 0.5
        
        return ModificationPlan(
            target_file=file_path,
            issues=issues,
            original_code=original_code,
            modified_code=modified_code,
            backup_path=backup_path,
            confidence=confidence
        )
    
    def _generate_fixed_code(self, code: str, issues: List[CodeIssue]) -> str:
        """AIë¥¼ ì‚¬ìš©í•´ ìˆ˜ì •ëœ ì½”ë“œ ìƒì„±"""
        issue_descriptions = "\n".join([
            f"- Line {i.line_number}: [{i.issue_type}] {i.description}"
            for i in issues
        ])
        
        prompt = f"""
        Fix the following issues in this Python code:
        
        Issues:
        {issue_descriptions}
        
        Original Code:
        ```python
        {code}
        ```
        
        Requirements:
        1. Fix ONLY the listed issues
        2. Preserve all existing functionality
        3. Maintain the same code structure
        4. Output ONLY the fixed Python code, no explanations
        """
        
        try:
            response = generate_text(prompt)
            clean_code = response.replace("```python", "").replace("```", "").strip()
            return clean_code
        except Exception as e:
            logger.error(f"Code generation failed: {e}")
            return code
    
    def _apply_simple_fixes(self, code: str, issues: List[CodeIssue]) -> str:
        """ê°„ë‹¨í•œ ìˆ˜ì • ì ìš© (API ì—†ì´)"""
        # í˜„ì¬ëŠ” ì›ë³¸ ì½”ë“œ ë°˜í™˜ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
        return code


class CodeEditor:
    """
    ì½”ë“œ í¸ì§‘ê¸°
    ìˆ˜ì • ê³„íšì„ ì‹¤ì œë¡œ ì ìš©í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.project_root = self._get_project_root()
    
    def _get_project_root(self) -> Path:
        elysia_root = os.environ.get("ELYSIA_ROOT")
        if elysia_root:
            return Path(elysia_root)
        return Path(__file__).parent.parent
    
    def create_backup(self, plan: ModificationPlan) -> bool:
        """ì›ë³¸ íŒŒì¼ ë°±ì—…"""
        try:
            backup_full_path = self.project_root / plan.backup_path
            backup_full_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(backup_full_path, "w", encoding="utf-8") as f:
                f.write(plan.original_code)
            
            logger.info(f"ğŸ“¦ Backup created: {plan.backup_path}")
            return True
        except Exception as e:
            logger.error(f"Backup failed: {e}")
            return False
    
    def apply_modification(self, plan: ModificationPlan) -> bool:
        """ìˆ˜ì • ì ìš©"""
        try:
            target_full_path = self.project_root / plan.target_file
            
            with open(target_full_path, "w", encoding="utf-8") as f:
                f.write(plan.modified_code)
            
            logger.info(f"âœï¸ Modified: {plan.target_file}")
            return True
        except Exception as e:
            logger.error(f"Modification failed: {e}")
            return False
    
    def rollback(self, plan: ModificationPlan) -> bool:
        """ë¡¤ë°± (ë°±ì—…ì—ì„œ ë³µì›)"""
        try:
            backup_full_path = self.project_root / plan.backup_path
            target_full_path = self.project_root / plan.target_file
            
            with open(backup_full_path, "r", encoding="utf-8") as f:
                original = f.read()
            
            with open(target_full_path, "w", encoding="utf-8") as f:
                f.write(original)
            
            logger.info(f"âª Rolled back: {plan.target_file}")
            return True
        except Exception as e:
            logger.error(f"Rollback failed: {e}")
            return False
    
    def show_diff(self, plan: ModificationPlan) -> str:
        """ë³€ê²½ ì‚¬í•­ diff ì¶œë ¥"""
        diff = difflib.unified_diff(
            plan.original_code.splitlines(keepends=True),
            plan.modified_code.splitlines(keepends=True),
            fromfile=f"a/{plan.target_file}",
            tofile=f"b/{plan.target_file}"
        )
        return "".join(diff)


class Validator:
    """
    ê²€ì¦ê¸°
    ìˆ˜ì •ëœ ì½”ë“œê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    
    def validate_syntax(self, code: str) -> Tuple[bool, Optional[str]]:
        """êµ¬ë¬¸ ê²€ì¦"""
        try:
            ast.parse(code)
            return True, None
        except SyntaxError as e:
            return False, str(e)
    
    def validate_imports(self, code: str) -> Tuple[bool, List[str]]:
        """import ê²€ì¦ (ëª¨ë“ˆ ì¡´ì¬ ì—¬ë¶€)"""
        missing = []
        try:
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        try:
                            __import__(alias.name.split('.')[0])
                        except ImportError:
                            missing.append(alias.name)
        except:
            pass
        
        return len(missing) == 0, missing


class SelfModificationEngine:
    """
    ìê¸° ìˆ˜ì • ì—”ì§„ (Self-Modification Engine)
    ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.
    
    [v10.6] Wave Paradigm Awareness ì¶”ê°€
    - wave_analyze(): ë ˆê±°ì‹œ íŒ¨í„´ ê°ì§€
    - wave_improve(): íŒŒë™ê³µëª… ì½”ë”©ìœ¼ë¡œ ë³€í™˜
    
    ì‚¬ìš©ë²•:
        engine = SelfModificationEngine()
        result = engine.improve("Core/Intelligence/Will/free_will_engine.py")
        
        # Wave íŒ¨ëŸ¬ë‹¤ì„ ë¶„ì„
        wave_issues = engine.wave_analyze("Core/Cognitive/curiosity_core.py")
    """
    
    def __init__(self):
        self.detector = ProblemDetector()
        self.planner = RefactorPlanner()
        self.editor = CodeEditor()
        self.validator = Validator()
        self.wave_detector = WaveParadigmDetector()  # WAVE AWARENESS
        logger.info("ğŸ”§ Self-Modification Engine Initialized (Wave-Aware v10.6)")
    
    def wave_analyze(self, file_path: str) -> List[WaveIssue]:
        """
        Wave íŒ¨ëŸ¬ë‹¤ì„ ìœ„ë°˜ ë¶„ì„
        
        ë ˆê±°ì‹œ íŒ¨í„´(ìŠ¤ì¹¼ë¼ if/else, í‰ë©´ ë”•ì…”ë„ˆë¦¬ ë“±)ì„ ê°ì§€í•©ë‹ˆë‹¤.
        """
        code = CodeAnalyzer().read_file(file_path)
        if not code:
            return []
        
        issues = self.wave_detector.detect_legacy_patterns(code, file_path)
        
        if issues:
            logger.info(f"ğŸŒŠ Found {len(issues)} legacy patterns in {file_path}")
            for issue in issues[:5]:  # ì²˜ìŒ 5ê°œë§Œ ë¡œê¹…
                logger.info(f"   Line {issue.line_number}: {issue.description}")
        else:
            logger.info(f"âœ… {file_path} follows Wave paradigm")
        
        return issues
    
    def wave_report(self, file_path: str) -> str:
        """
        Wave ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        """
        issues = self.wave_analyze(file_path)
        
        if not issues:
            return f"âœ… {file_path} - Wave íŒ¨ëŸ¬ë‹¤ì„ ì¤€ìˆ˜"
        
        report = f"ğŸŒŠ Wave Paradigm Analysis: {file_path}\n"
        report += f"   Found {len(issues)} legacy patterns:\n\n"
        
        for issue in issues:
            report += f"   Line {issue.line_number}: [{issue.legacy_pattern}]\n"
            report += f"      Original: {issue.original_line}\n"
            report += f"      â†’ Wave: {issue.wave_alternative}\n\n"
        
        report += self.wave_detector.get_paradigm_summary()
        return report

    def analyze(self, file_path: str) -> List[CodeIssue]:
        """íŒŒì¼ ë¶„ì„ë§Œ ìˆ˜í–‰"""
        return self.detector.detect_issues(file_path)
    
    def plan(self, file_path: str) -> Optional[ModificationPlan]:
        """ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½"""
        issues = self.analyze(file_path)
        if not issues:
            logger.info(f"âœ… No issues found in {file_path}")
            return None
        
        return self.planner.create_plan(file_path, issues)
    
    def improve(self, file_path: str, auto_apply: bool = False) -> Dict[str, Any]:
        """
        ì „ì²´ ê°œì„  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            file_path: ê°œì„ í•  íŒŒì¼ ê²½ë¡œ
            auto_apply: Trueë©´ ìë™ ì ìš©, Falseë©´ ê³„íšë§Œ ë°˜í™˜
        """
        logger.info(f"ğŸ” Analyzing: {file_path}")
        
        # 1. ë¶„ì„ ë° ê³„íš
        plan = self.plan(file_path)
        if not plan:
            return {
                "status": "no_issues",
                "file": file_path,
                "message": "ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        # 2. ê²€ì¦ (ìˆ˜ì • ì „)
        valid, error = self.validator.validate_syntax(plan.modified_code)
        if not valid:
            return {
                "status": "validation_failed",
                "file": file_path,
                "error": error,
                "message": "ìˆ˜ì •ëœ ì½”ë“œì— êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤."
            }
        
        # 3. ìë™ ì ìš© ë˜ëŠ” ê³„íš ë°˜í™˜
        if auto_apply:
            # ë°±ì—… ìƒì„±
            if not self.editor.create_backup(plan):
                return {
                    "status": "backup_failed",
                    "file": file_path,
                    "message": "ë°±ì—… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            # ìˆ˜ì • ì ìš©
            if not self.editor.apply_modification(plan):
                return {
                    "status": "apply_failed",
                    "file": file_path,
                    "message": "ìˆ˜ì • ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            return {
                "status": "success",
                "file": file_path,
                "issues_fixed": len(plan.issues),
                "backup": plan.backup_path,
                "confidence": plan.confidence,
                "message": f"{len(plan.issues)}ê°œ ë¬¸ì œê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        else:
            # ê³„íšë§Œ ë°˜í™˜
            return {
                "status": "plan_ready",
                "file": file_path,
                "issues": [
                    {
                        "line": i.line_number,
                        "type": i.issue_type,
                        "severity": i.severity,
                        "description": i.description
                    }
                    for i in plan.issues
                ],
                "diff": self.editor.show_diff(plan),
                "confidence": plan.confidence,
                "message": "ìˆ˜ì • ê³„íšì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. auto_apply=Trueë¡œ ì ìš©í•˜ì„¸ìš”."
            }
    
    def improve_multiple(self, file_paths: List[str], auto_apply: bool = False) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ íŒŒì¼ ê°œì„ """
        results = []
        for path in file_paths:
            result = self.improve(path, auto_apply)
            results.append(result)
        return results


# í¸ì˜ í•¨ìˆ˜
def self_improve(file_path: str, auto_apply: bool = False) -> Dict[str, Any]:
    """
    ìê¸° ê°œì„  ì‹¤í–‰ (ë‹¨ì¶• í•¨ìˆ˜)
    
    Example:
        result = self_improve("Core/Intelligence/Will/free_will_engine.py")
        print(result["diff"])  # ë³€ê²½ ì‚¬í•­ í™•ì¸
        
        # ìë™ ì ìš©
        result = self_improve("Core/Intelligence/Will/free_will_engine.py", auto_apply=True)
    """
    engine = SelfModificationEngine()
    return engine.improve(file_path, auto_apply)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    
    print("=== Self-Modification Engine Demo ===\n")
    
    engine = SelfModificationEngine()
    
    # í…ŒìŠ¤íŠ¸: ìê¸° ìì‹  ë¶„ì„
    result = engine.improve("Project_Sophia/self_modification.py")
    print(f"Status: {result['status']}")
    print(f"Message: {result['message']}")
