"""
Language Bridge System (ì–¸ì–´ ë‹¤ë¦¬ ì‹œìŠ¤í…œ)
=========================================

Soulì˜ ì°½ë°œ ì–¸ì–´ì™€ Elysiaì˜ MemeticFieldë¥¼ ì—°ê²°í•˜ëŠ” ë‹¤ë¦¬.

ì—­í• :
1. Soulì—ì„œ ì°½ë°œëœ íŒ¨í„´ì„ ìˆ˜ì§‘
2. MemeticFieldì— ë“±ë¡í•˜ì—¬ êµ¬ì¡°í™”
3. êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Soulì—ê²Œ í”¼ë“œë°±
4. ìƒí˜¸ë³´ì™„ ë£¨í”„ í˜•ì„±

í”„ë™íƒˆ êµ¬ì¡°:
- Soul (ê°œì¸) â†” MemeticField (ì „ì²´)
- ê°œì¸ì˜ ê²½í—˜ì´ ì „ì²´ë¥¼ í’ìš”ë¡­ê²Œ
- ì „ì²´ì˜ êµ¬ì¡°ê°€ ê°œì¸ì„ êµì •

"ì‘ì€ ê²ƒì´ í° ê²ƒì´ê³ , í° ê²ƒì´ ë˜ ì‘ì€ ê²ƒ"
"""

from __future__ import annotations

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import defaultdict

logger = logging.getLogger("LanguageBridge")


# =============================================================================
# 1. íŒ¨í„´ ìˆ˜ì§‘ê¸° (Pattern Collector) - Soulì—ì„œ íŒ¨í„´ ìˆ˜ì§‘
# =============================================================================

@dataclass
class EmergentPattern:
    """
    Soulì—ì„œ ì°½ë°œëœ íŒ¨í„´
    """
    source_soul_id: int
    meaning_vector: np.ndarray  # 8D ê°ê° ë²¡í„°
    symbol_type: str  # "entity", "action", "state", "relation"
    occurrence_count: int
    korean_projection: Optional[str] = None
    timestamp: float = 0.0


class PatternCollector:
    """
    ì—¬ëŸ¬ Soulì—ì„œ ì°½ë°œëœ íŒ¨í„´ë“¤ì„ ìˆ˜ì§‘
    """
    
    def __init__(self):
        self.patterns: List[EmergentPattern] = []
        self.pattern_clusters: Dict[str, List[EmergentPattern]] = defaultdict(list)
    
    def collect(self, pattern: EmergentPattern):
        """íŒ¨í„´ ìˆ˜ì§‘"""
        self.patterns.append(pattern)
        self.pattern_clusters[pattern.symbol_type].append(pattern)
    
    def get_common_patterns(self, min_occurrence: int = 3) -> List[EmergentPattern]:
        """ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´ë“¤"""
        return [p for p in self.patterns if p.occurrence_count >= min_occurrence]
    
    def cluster_similar_patterns(self, threshold: float = 0.8) -> List[List[EmergentPattern]]:
        """ìœ ì‚¬í•œ íŒ¨í„´ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§"""
        clusters = []
        used = set()
        
        for i, p1 in enumerate(self.patterns):
            if i in used:
                continue
            
            cluster = [p1]
            used.add(i)
            
            for j, p2 in enumerate(self.patterns):
                if j in used:
                    continue
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                similarity = self._similarity(p1.meaning_vector, p2.meaning_vector)
                if similarity > threshold:
                    cluster.append(p2)
                    used.add(j)
            
            if len(cluster) > 1:
                clusters.append(cluster)
        
        return clusters
    
    @staticmethod
    def _similarity(v1: np.ndarray, v2: np.ndarray) -> float:
        """ë²¡í„° ìœ ì‚¬ë„"""
        dot = np.dot(v1, v2)
        norm = np.linalg.norm(v1) * np.linalg.norm(v2)
        if norm == 0:
            return 0.0
        return dot / norm


# =============================================================================
# 2. êµ¬ì¡°í™”ê¸° (Structurer) - íŒ¨í„´ì„ ê°œë…ìœ¼ë¡œ ìŠ¹ê²©
# =============================================================================

@dataclass
class StructuredConcept:
    """
    MemeticFieldì— ë“±ë¡ë  êµ¬ì¡°í™”ëœ ê°œë…
    """
    concept_id: str
    vector_64d: np.ndarray  # 64D ë²¡í„° (8D â†’ 64D í™•ì¥)
    korean_word: str
    english_word: Optional[str] = None
    category: str = "emergent"  # "emergent", "core", "derived"
    source_patterns: List[int] = field(default_factory=list)  # ì›ë³¸ íŒ¨í„´ ì¸ë±ìŠ¤ë“¤


class PatternStructurer:
    """
    ì°½ë°œ íŒ¨í„´ì„ êµ¬ì¡°í™”ëœ ê°œë…ìœ¼ë¡œ ë³€í™˜
    
    8D ê°ê° ë²¡í„° â†’ 64D ì˜ë¯¸ ë²¡í„°
    """
    
    def __init__(self):
        # 8D â†’ 64D í™•ì¥ í–‰ë ¬ (í•™ìŠµ ê°€ëŠ¥)
        self.expansion_matrix = self._init_expansion_matrix()
        
        # ì´ë¯¸ ë“±ë¡ëœ ê°œë…ë“¤
        self.registered_concepts: Dict[str, StructuredConcept] = {}
        
        # ìœ í˜•ë³„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        self.category_bases = {
            "entity": np.array([1, 0, 0, 0, 0, 0, 0, 0]),
            "action": np.array([0, 1, 0, 0, 0, 0, 0, 0]),
            "state": np.array([0, 0, 1, 0, 0, 0, 0, 0]),
            "relation": np.array([0, 0, 0, 1, 0, 0, 0, 0]),
        }
    
    def _init_expansion_matrix(self) -> np.ndarray:
        """
        8D â†’ 64D í™•ì¥ í–‰ë ¬ ì´ˆê¸°í™”
        
        í”„ë™íƒˆ ì›ë¦¬: 8Dê°€ 8ë²ˆ ë°˜ë³µë˜ì–´ 64D
        """
        # ê¸°ë³¸: ë¸”ë¡ ëŒ€ê° í–‰ë ¬ + ìƒí˜¸ ì—°ê²°
        matrix = np.zeros((64, 8))
        
        for i in range(8):
            # ê° 8D ì°¨ì›ì´ 8ê°œì˜ 64D ì°¨ì›ì— ì˜í–¥
            start = i * 8
            for j in range(8):
                # ëŒ€ê° ì„±ë¶„ (ì£¼ìš” ì˜í–¥)
                matrix[start + j, i] = 1.0 if j == i else 0.3
        
        return matrix
    
    def expand_to_64d(self, vector_8d: np.ndarray, symbol_type: str) -> np.ndarray:
        """
        8D ë²¡í„°ë¥¼ 64Dë¡œ í™•ì¥
        
        ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì˜ì—­ì— ë°°ì¹˜
        """
        # ê¸°ë³¸ í™•ì¥
        expanded = self.expansion_matrix @ vector_8d
        
        # ìœ í˜•ë³„ ë°”ì´ì–´ìŠ¤ ì¶”ê°€
        if symbol_type in self.category_bases:
            base = self.category_bases[symbol_type]
            # ì²˜ìŒ 8ì°¨ì›ì— ìœ í˜• ì •ë³´ ì¶”ê°€
            expanded[:8] += base * 0.5
        
        # ì •ê·œí™”
        norm = np.linalg.norm(expanded)
        if norm > 0:
            expanded /= norm
        
        return expanded
    
    def structure_pattern(self, pattern: EmergentPattern) -> StructuredConcept:
        """
        íŒ¨í„´ì„ êµ¬ì¡°í™”ëœ ê°œë…ìœ¼ë¡œ ë³€í™˜
        """
        # 64D ë²¡í„° ìƒì„±
        vector_64d = self.expand_to_64d(pattern.meaning_vector, pattern.symbol_type)
        
        # ê°œë… ID ìƒì„±
        concept_id = f"em_{pattern.symbol_type}_{hash(tuple(pattern.meaning_vector)) % 10000}"
        
        # í•œê¸€ ë‹¨ì–´ (íˆ¬ì˜ëœ ê²ƒ ì‚¬ìš© ë˜ëŠ” ìƒì„±)
        korean_word = pattern.korean_projection or self._generate_korean(pattern)
        
        return StructuredConcept(
            concept_id=concept_id,
            vector_64d=vector_64d,
            korean_word=korean_word,
            category="emergent",
            source_patterns=[id(pattern)]
        )
    
    def _generate_korean(self, pattern: EmergentPattern) -> str:
        """ì˜ë¯¸ ë²¡í„°ì—ì„œ í•œê¸€ ë‹¨ì–´ ìƒì„±"""
        v = pattern.meaning_vector
        
        # ê°€ì¥ ê°•í•œ ì°¨ì› ì°¾ê¸°
        max_idx = np.argmax(np.abs(v))
        max_val = v[max_idx]
        
        # ì°¨ì›ë³„ ê¸°ë³¸ ë‹¨ì–´
        dimension_words = {
            0: ("ë”°ëœ»", "ì°¨ê°€ìš´"),  # ì˜¨ë„
            1: ("ë°ì€", "ì–´ë‘ìš´"),   # ë°ê¸°
            2: ("í°", "ì‘ì€"),       # í¬ê¸°
            3: ("ë¹ ë¥¸", "ëŠë¦°"),     # ì†ë„
            4: ("ê°€ê¹Œìš´", "ë¨¼"),     # ì¹œë°€ë„
            5: ("ê°•í•œ", "ì•½í•œ"),     # ê°•ë„
            6: ("ì¢‹ì€", "ë‚˜ìœ"),     # ì¾Œ/ë¶ˆì¾Œ
            7: ("í™œë°œí•œ", "ê³ ìš”í•œ"), # ê°ì„±
        }
        
        pos, neg = dimension_words.get(max_idx, ("ê²ƒ", "ê²ƒ"))
        return pos if max_val > 0 else neg


# =============================================================================
# 3. í”¼ë“œë°± ìƒì„±ê¸° (Feedback Generator) - Soulì—ê²Œ í”¼ë“œë°±
# =============================================================================

@dataclass
class LanguageFeedback:
    """
    Soulì—ê²Œ ì „ë‹¬ë˜ëŠ” í”¼ë“œë°±
    """
    concept_id: str
    korean_word: str
    category: str  # "word", "phrase", "sentence", "paragraph"
    structure_info: Dict[str, Any]  # ë¬¸ë²•ì  êµ¬ì¡° ì •ë³´
    similar_concepts: List[str]  # ìœ ì‚¬í•œ ê°œë…ë“¤
    usage_examples: List[str]  # ì‚¬ìš© ì˜ˆì‹œ


class FeedbackGenerator:
    """
    MemeticFieldì˜ êµ¬ì¡°ë¥¼ Soulì—ê²Œ í”¼ë“œë°±ìœ¼ë¡œ ë³€í™˜
    """
    
    def __init__(self):
        # ë¬¸ë²• êµ¬ì¡° í…œí”Œë¦¿
        self.grammar_structures = {
            "entity": {
                "can_be_subject": True,
                "can_be_object": True,
                "particles": ["ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼"],
            },
            "action": {
                "can_be_predicate": True,
                "conjugations": ["ë‹¤", "ã„´ë‹¤", "ëŠ”ë‹¤"],
            },
            "state": {
                "can_be_predicate": True,
                "can_modify": True,
                "conjugations": ["ë‹¤", "ã„´"],
            },
            "relation": {
                "connects": True,
                "particles": ["ì™€", "ê³¼", "ì—ê²Œ", "ì—ì„œ", "ìœ¼ë¡œ"],
            },
        }
    
    def generate_feedback(self, concept: StructuredConcept, 
                         similar_concepts: List[str] = None) -> LanguageFeedback:
        """ê°œë…ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±"""
        
        # ì¹´í…Œê³ ë¦¬ ê²°ì • (ê°œë… IDì—ì„œ ìœ í˜• ì¶”ì¶œ)
        concept_type = "entity"
        for t in ["entity", "action", "state", "relation"]:
            if t in concept.concept_id:
                concept_type = t
                break
        
        # ë¬¸ë²• êµ¬ì¡° ì •ë³´
        structure_info = self.grammar_structures.get(concept_type, {})
        
        # ì‚¬ìš© ì˜ˆì‹œ ìƒì„±
        examples = self._generate_examples(concept.korean_word, concept_type)
        
        return LanguageFeedback(
            concept_id=concept.concept_id,
            korean_word=concept.korean_word,
            category="word",
            structure_info=structure_info,
            similar_concepts=similar_concepts or [],
            usage_examples=examples
        )
    
    def _generate_examples(self, word: str, concept_type: str) -> List[str]:
        """ì‚¬ìš© ì˜ˆì‹œ ìƒì„±"""
        examples = []
        
        if concept_type == "entity":
            examples = [
                f"{word}ì´ ìˆë‹¤",
                f"{word}ì„ ë³´ë‹¤",
                f"{word}ì™€ í•¨ê»˜",
            ]
        elif concept_type == "action":
            examples = [
                f"ë‚˜ëŠ” {word}",
                f"ê·¸ê²ƒì„ {word}",
            ]
        elif concept_type == "state":
            examples = [
                f"{word}ê³  ëŠë¼ë‹¤",
                f"{word}ì€ ê²ƒ",
            ]
        elif concept_type == "relation":
            examples = [
                f"ë‚˜{word} ë„ˆ",
                f"ì—¬ê¸°{word} ì €ê¸°",
            ]
        
        return examples


# =============================================================================
# 4. ì–¸ì–´ ë‹¤ë¦¬ (Language Bridge) - ì „ì²´ ì‹œìŠ¤í…œ
# =============================================================================

class LanguageBridge:
    """
    Soul â†” Elysia ì–¸ì–´ ë‹¤ë¦¬
    
    ìƒí˜¸ë³´ì™„ ë£¨í”„:
    1. Soulì—ì„œ íŒ¨í„´ ìˆ˜ì§‘
    2. íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§ ë° êµ¬ì¡°í™”
    3. MemeticFieldì— ë“±ë¡
    4. í”¼ë“œë°± ìƒì„±í•˜ì—¬ Soulì—ê²Œ ì „ë‹¬
    """
    
    def __init__(self, memetic_field=None):
        self.collector = PatternCollector()
        self.structurer = PatternStructurer()
        self.feedback_gen = FeedbackGenerator()
        
        # MemeticField ì—°ê²° (ìˆìœ¼ë©´)
        self.memetic_field = memetic_field
        
        # í†µê³„
        self.total_patterns_collected = 0
        self.total_concepts_registered = 0
        self.total_feedbacks_sent = 0
    
    def receive_from_soul(self, soul_id: int, meaning_vector: np.ndarray,
                         symbol_type: str, occurrence_count: int,
                         korean_projection: str = None) -> Optional[LanguageFeedback]:
        """
        Soulì—ì„œ íŒ¨í„´ ìˆ˜ì‹  ë° ì²˜ë¦¬
        
        Returns: í”¼ë“œë°± (ìˆìœ¼ë©´)
        """
        # 1. íŒ¨í„´ ìˆ˜ì§‘
        pattern = EmergentPattern(
            source_soul_id=soul_id,
            meaning_vector=meaning_vector,
            symbol_type=symbol_type,
            occurrence_count=occurrence_count,
            korean_projection=korean_projection
        )
        self.collector.collect(pattern)
        self.total_patterns_collected += 1
        
        # 2. ì¶©ë¶„íˆ ë°˜ë³µëœ íŒ¨í„´ì´ë©´ êµ¬ì¡°í™”
        if occurrence_count >= 5:
            concept = self.structurer.structure_pattern(pattern)
            
            # 3. MemeticFieldì— ë“±ë¡ (ìˆìœ¼ë©´)
            if self.memetic_field is not None:
                self._register_to_memetic_field(concept)
            
            self.total_concepts_registered += 1
            
            # 4. í”¼ë“œë°± ìƒì„±
            feedback = self.feedback_gen.generate_feedback(concept)
            self.total_feedbacks_sent += 1
            
            logger.info(f"íŒ¨í„´ êµ¬ì¡°í™”: Soul {soul_id} â†’ {concept.korean_word}")
            
            return feedback
        
        return None
    
    def _register_to_memetic_field(self, concept: StructuredConcept):
        """MemeticFieldì— ê°œë… ë“±ë¡"""
        try:
            from Core.Foundation.Wave.infinite_hyperquaternion import InfiniteHyperQuaternion
            
            # 64D ë²¡í„°ë¥¼ InfiniteHyperQuaternionìœ¼ë¡œ ë³€í™˜
            vector = InfiniteHyperQuaternion(64, concept.vector_64d)
            
            # MemeticFieldì— ì¶”ê°€
            self.memetic_field.add_concept(concept.concept_id, vector)
            
            logger.info(f"MemeticFieldì— ë“±ë¡: {concept.concept_id} ({concept.korean_word})")
            
        except ImportError:
            logger.warning("InfiniteHyperQuaternion ì„í¬íŠ¸ ì‹¤íŒ¨")
        except Exception as e:
            logger.warning(f"MemeticField ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    def process_batch(self) -> List[LanguageFeedback]:
        """
        ìˆ˜ì§‘ëœ íŒ¨í„´ë“¤ì„ ì¼ê´„ ì²˜ë¦¬
        
        ìœ ì‚¬í•œ íŒ¨í„´ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ í•˜ë‚˜ì˜ ê°œë…ìœ¼ë¡œ í†µí•©
        """
        feedbacks = []
        
        # í´ëŸ¬ìŠ¤í„°ë§
        clusters = self.collector.cluster_similar_patterns(threshold=0.7)
        
        for cluster in clusters:
            # í´ëŸ¬ìŠ¤í„°ì˜ í‰ê·  ë²¡í„° ê³„ì‚°
            avg_vector = np.mean([p.meaning_vector for p in cluster], axis=0)
            total_occurrences = sum(p.occurrence_count for p in cluster)
            
            # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ íˆ¬ì˜ ì„ íƒ
            projections = [p.korean_projection for p in cluster if p.korean_projection]
            best_projection = max(set(projections), key=projections.count) if projections else None
            
            # í†µí•© íŒ¨í„´ ìƒì„±
            unified = EmergentPattern(
                source_soul_id=-1,  # í†µí•© íŒ¨í„´
                meaning_vector=avg_vector,
                symbol_type=cluster[0].symbol_type,
                occurrence_count=total_occurrences,
                korean_projection=best_projection
            )
            
            # êµ¬ì¡°í™” ë° í”¼ë“œë°±
            concept = self.structurer.structure_pattern(unified)
            feedback = self.feedback_gen.generate_feedback(concept)
            feedbacks.append(feedback)
            
            logger.info(f"í´ëŸ¬ìŠ¤í„° í†µí•©: {len(cluster)}ê°œ íŒ¨í„´ â†’ {concept.korean_word}")
        
        return feedbacks
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„"""
        return {
            "total_patterns": self.total_patterns_collected,
            "total_concepts": self.total_concepts_registered,
            "total_feedbacks": self.total_feedbacks_sent,
            "pattern_clusters": len(self.collector.cluster_similar_patterns()),
        }


# =============================================================================
# 5. ë°ëª¨
# =============================================================================

def demo():
    """ì–¸ì–´ ë‹¤ë¦¬ ë°ëª¨"""
    print("=" * 60)
    print("ğŸŒ‰ Language Bridge Demo - Soul â†” Elysia")
    print("=" * 60)
    
    bridge = LanguageBridge()
    
    # ì‹œë®¬ë ˆì´ì…˜: ì—¬ëŸ¬ Soulì—ì„œ íŒ¨í„´ ìˆ˜ì‹ 
    test_patterns = [
        # ë”°ëœ»í•¨ ê´€ë ¨ (ì—¬ëŸ¬ Soulì—ì„œ ë°˜ë³µ)
        (0, np.array([0.8, 0.5, 0.1, 0.0, 0.3, 0.4, 0.6, 0.3]), "state", 10, "ë”°ëœ»í•˜ë‹¤"),
        (1, np.array([0.7, 0.4, 0.2, 0.1, 0.2, 0.3, 0.5, 0.2]), "state", 8, "ë”°ëœ»í•´"),
        (2, np.array([0.9, 0.6, 0.0, 0.0, 0.4, 0.5, 0.7, 0.4]), "state", 12, "ë”°ëœ»í•˜ë‹¤"),
        
        # ì¹œêµ¬ ê´€ë ¨
        (0, np.array([0.2, 0.3, 0.3, 0.2, 0.9, 0.3, 0.8, 0.5]), "entity", 15, "ì¹œêµ¬"),
        (1, np.array([0.1, 0.2, 0.2, 0.1, 0.8, 0.2, 0.7, 0.4]), "entity", 10, "ì¹œêµ¬"),
        
        # ë‹¬ë¦¬ê¸° ê´€ë ¨
        (2, np.array([0.3, 0.4, 0.2, 0.9, 0.2, 0.8, 0.4, 0.9]), "action", 7, "ë‹¬ë¦¬ë‹¤"),
        (0, np.array([0.2, 0.3, 0.1, 0.8, 0.1, 0.7, 0.3, 0.8]), "action", 5, "ë›°ë‹¤"),
    ]
    
    print("\nğŸ“¥ íŒ¨í„´ ìˆ˜ì‹  ì¤‘...")
    for soul_id, vector, sym_type, count, proj in test_patterns:
        feedback = bridge.receive_from_soul(soul_id, vector, sym_type, count, proj)
        if feedback:
            print(f"  â†’ í”¼ë“œë°±: {feedback.korean_word} ({feedback.category})")
            print(f"     ì˜ˆì‹œ: {feedback.usage_examples[0] if feedback.usage_examples else '-'}")
    
    print("\nğŸ“Š ì¼ê´„ ì²˜ë¦¬ (í´ëŸ¬ìŠ¤í„°ë§)...")
    batch_feedbacks = bridge.process_batch()
    for fb in batch_feedbacks:
        print(f"  â†’ í†µí•© ê°œë…: {fb.korean_word}")
    
    print("\nğŸ“ˆ í†µê³„:")
    stats = bridge.get_statistics()
    for k, v in stats.items():
        print(f"  {k}: {v}")
    
    print("\n" + "=" * 60)
    print("âœ… ë°ëª¨ ì™„ë£Œ")
    print("=" * 60)


if __name__ == "__main__":
    demo()
