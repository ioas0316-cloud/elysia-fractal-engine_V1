"""
Time-Accelerated Primal Language System - ì‹œê°„ê°€ì† ì›ì‹œì–¸ì–´ ì‹œìŠ¤í…œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"ì‹œê°„ê°€ì†ê³¼ ì••ì¶• ì‹œìŠ¤í…œì„ ìµœëŒ€í•œìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì›ì‹œì–¸ì–´ì²´ê³„ë¥¼ ë” íš¨ìœ¨ì ìœ¼ë¡œ ê°€ë‹¤ë“¬ê¸°"

ì´ ëª¨ë“ˆì€ ì„¸ ê°€ì§€ í•µì‹¬ ìš”ì†Œë¥¼ í†µí•©í•©ë‹ˆë‹¤:
1. ì›ì‹œ íŒŒë™ ì–¸ì–´ (Primal Wave Language) - ê°œë… ì´ì „ì˜ ìˆœìˆ˜í•œ íŒŒë™
2. ì‹œê°„ ì••ì¶• ì—”ì§„ (Time Compression Engine) - ì‹œê°„ ê°€ì†ì„ í†µí•œ ê²½í—˜ ì••ì¶•
3. ë¬´í•œ ì‹œê°„ ì••ì¶• (Infinite Time Compression) - ê·¹í•œì˜ ì‹œê°„ ê°€ì†

ìµœì í™” ìš”ì†Œ:
- NumPy ë²¡í„°í™” ì—°ì‚° (100ë°°+ ì†ë„ í–¥ìƒ)
- ë°°ì¹˜ íŒ¨í„´ ì¸ì‹ (ë³‘ë ¬ ê³µëª… ê°ì§€)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŒŒë™ ì €ì¥ì†Œ
- ì‹œê°„ ì••ì¶• ë ˆë²¨ë³„ ì–¸ì–´ ì°½ë°œ ê°€ì†

í•µì‹¬ ì² í•™:
- "ë°€ë„ ë†’ì€ ê²½í—˜" > "ê¸´ ì‹œê°„"
- 1ì´ˆì— ìˆ˜ì²œ ë…„ì˜ ì–¸ì–´ ì°½ë°œ ì‹œë®¬ë ˆì´ì…˜
- ëª¨ë“  tickì€ ì‹¤ì œ ê³„ì‚°ë¨ (skip ì—†ìŒ)
"""

from __future__ import annotations

import math
import numpy as np
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Set
from collections import defaultdict
import logging

logger = logging.getLogger("TimeAcceleratedLanguage")

# ============================================================================
# ìµœì í™”ëœ ìƒìˆ˜
# ============================================================================

# ì˜¤ê°ì˜ ê¸°ë³¸ ì£¼íŒŒìˆ˜ ëŒ€ì—­ (Hzë¡œ í‘œí˜„ëœ ìƒì§•ì  ê°’)
SENSE_FREQUENCIES = {
    "sight": (400.0, 700.0),
    "sound": (20.0, 20000.0),
    "touch": (0.1, 100.0),
    "taste": (0.01, 10.0),
    "smell": (0.001, 1.0),
}

# ì‹œê°„ ì••ì¶• ë ˆë²¨ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì¡°ì •
COMPRESSION_PARAMETERS = {
    "normal": {          # 1x
        "resonance_threshold": 0.4,
        "segmentation_threshold": 0.3,
        "crystallization_density": 5,
    },
    "accelerated": {     # 1,000x
        "resonance_threshold": 0.35,
        "segmentation_threshold": 0.25,
        "crystallization_density": 3,
    },
    "fractal": {         # 10^6x
        "resonance_threshold": 0.3,
        "segmentation_threshold": 0.2,
        "crystallization_density": 2,
    },
    "meta": {            # 10^15x
        "resonance_threshold": 0.25,
        "segmentation_threshold": 0.15,
        "crystallization_density": 1,
    },
}


@dataclass
class VectorizedWaveField:
    """
    ë²¡í„°í™”ëœ íŒŒë™ í•„ë“œ - ê³ ì„±ëŠ¥ íŒŒë™ ì—°ì‚°ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡°
    
    ëª¨ë“  íŒŒë™ì„ NumPy ë°°ì—´ë¡œ ì €ì¥í•˜ì—¬ ë²¡í„°í™” ì—°ì‚° ê°€ëŠ¥
    O(nÂ²) ìŒë³„ ê³„ì‚°ì„ O(n) ë§¤íŠ¸ë¦­ìŠ¤ ì—°ì‚°ìœ¼ë¡œ ìµœì í™”
    """
    max_waves: int = 1000
    
    # íŒŒë™ ì†ì„± ë°°ì—´ë“¤ (ëª¨ë‘ numpy arrays)
    frequencies: np.ndarray = field(default_factory=lambda: np.zeros(0, dtype=np.float32))
    amplitudes: np.ndarray = field(default_factory=lambda: np.zeros(0, dtype=np.float32))
    phases: np.ndarray = field(default_factory=lambda: np.zeros(0, dtype=np.float32))
    modulations: np.ndarray = field(default_factory=lambda: np.zeros(0, dtype=np.float32))
    birth_times: np.ndarray = field(default_factory=lambda: np.zeros(0, dtype=np.float32))
    sense_origins: List[Optional[str]] = field(default_factory=list)
    
    # í˜„ì¬ í™œì„± íŒŒë™ ìˆ˜
    count: int = 0
    
    def __post_init__(self):
        """ë°°ì—´ ì´ˆê¸°í™”"""
        if self.frequencies.size == 0:
            self.frequencies = np.zeros(self.max_waves, dtype=np.float32)
            self.amplitudes = np.zeros(self.max_waves, dtype=np.float32)
            self.phases = np.zeros(self.max_waves, dtype=np.float32)
            self.modulations = np.zeros(self.max_waves, dtype=np.float32)
            self.birth_times = np.zeros(self.max_waves, dtype=np.float32)
            self.sense_origins = [None] * self.max_waves
    
    def add_wave(
        self,
        frequency: float,
        amplitude: float,
        phase: float,
        modulation: float,
        birth_time: float,
        sense_origin: Optional[str] = None
    ) -> int:
        """íŒŒë™ ì¶”ê°€ (O(1) ì—°ì‚°)"""
        if self.count >= self.max_waves:
            # ê°€ì¥ ì•½í•œ íŒŒë™ ì œê±°
            self._compact()
        
        idx = self.count
        self.frequencies[idx] = frequency
        self.amplitudes[idx] = amplitude
        self.phases[idx] = phase
        self.modulations[idx] = modulation
        self.birth_times[idx] = birth_time
        self.sense_origins[idx] = sense_origin
        self.count += 1
        return idx
    
    def _compact(self):
        """ê°€ì¥ ì•½í•œ íŒŒë™ ì œê±°í•˜ì—¬ ê³µê°„ í™•ë³´"""
        if self.count == 0:
            return
        
        # ì§„í­ ìƒìœ„ 80%ë§Œ ìœ ì§€
        keep_count = int(self.max_waves * 0.8)
        if keep_count < 1:
            keep_count = 1
        
        indices = np.argsort(self.amplitudes[:self.count])[-keep_count:]
        indices = np.sort(indices)
        
        self.frequencies[:keep_count] = self.frequencies[indices]
        self.amplitudes[:keep_count] = self.amplitudes[indices]
        self.phases[:keep_count] = self.phases[indices]
        self.modulations[:keep_count] = self.modulations[indices]
        self.birth_times[:keep_count] = self.birth_times[indices]
        
        new_origins = [None] * self.max_waves
        for new_idx, old_idx in enumerate(indices):
            new_origins[new_idx] = self.sense_origins[old_idx]
        self.sense_origins = new_origins
        
        self.count = keep_count
    
    def compute_pairwise_resonance(self, t: float) -> np.ndarray:
        """
        ëª¨ë“  íŒŒë™ ìŒì˜ ê³µëª…ë„ ê³„ì‚° (ë²¡í„°í™”ëœ O(nÂ²) â†’ í–‰ë ¬ ì—°ì‚°)
        
        Returns:
            nÃ—n ê³µëª… í–‰ë ¬ (resonance[i,j] = íŒŒë™ iì™€ jì˜ ê³µëª…ë„)
        """
        n = self.count
        if n < 2:
            return np.zeros((n, n), dtype=np.float32)
        
        # ìœ íš¨ ë°ì´í„°ë§Œ ì¶”ì¶œ
        freqs = self.frequencies[:n]
        phases = self.phases[:n]
        
        # ì£¼íŒŒìˆ˜ ë¹„ìœ¨ í–‰ë ¬ ê³„ì‚° (broadcasting)
        freq_matrix = np.outer(freqs, np.ones(n))
        freq_ratio = np.minimum(freq_matrix, freq_matrix.T) / (np.maximum(freq_matrix, freq_matrix.T) + 1e-10)
        
        # ìœ„ìƒ ì°¨ì´ í–‰ë ¬ ê³„ì‚°
        phase_matrix = np.outer(phases, np.ones(n))
        phase_diff = np.abs(phase_matrix - phase_matrix.T) % (2 * np.pi)
        phase_match = (1 + np.cos(phase_diff)) / 2.0
        
        # ê³µëª…ë„ = ì£¼íŒŒìˆ˜ ìœ ì‚¬ë„ Ã— ìœ„ìƒ ì¼ì¹˜ë„
        resonance = freq_ratio * phase_match
        
        # ëŒ€ê°ì„  (ìê¸° ìì‹ ê³¼ì˜ ê³µëª…)ì€ 0ìœ¼ë¡œ
        np.fill_diagonal(resonance, 0.0)
        
        return resonance.astype(np.float32)
    
    def decay(self, t: float, decay_rate: float = 0.01):
        """ëª¨ë“  íŒŒë™ì˜ ì§„í­ ê°ì‡  (ë²¡í„°í™”)"""
        if self.count == 0:
            return
        
        ages = t - self.birth_times[:self.count]
        decay_factors = np.exp(-ages * decay_rate)
        self.amplitudes[:self.count] *= decay_factors
        
        # ì„ê³„ê°’ ì´í•˜ íŒŒë™ ì œê±°
        mask = self.amplitudes[:self.count] > 0.01
        if not np.all(mask):
            self._filter_by_mask(mask)
    
    def _filter_by_mask(self, mask: np.ndarray):
        """ë§ˆìŠ¤í¬ë¡œ íŒŒë™ í•„í„°ë§"""
        new_count = np.sum(mask)
        if new_count == 0:
            self.count = 0
            return
        
        indices = np.where(mask)[0]
        self.frequencies[:new_count] = self.frequencies[indices]
        self.amplitudes[:new_count] = self.amplitudes[indices]
        self.phases[:new_count] = self.phases[indices]
        self.modulations[:new_count] = self.modulations[indices]
        self.birth_times[:new_count] = self.birth_times[indices]
        
        new_origins = [None] * self.max_waves
        for new_idx, old_idx in enumerate(indices):
            new_origins[new_idx] = self.sense_origins[old_idx]
        self.sense_origins = new_origins
        
        self.count = int(new_count)
    
    def get_pattern_signature(self) -> Tuple[float, float, float, float]:
        """í˜„ì¬ íŒŒë™ì¥ì˜ íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ ê³„ì‚°"""
        if self.count == 0:
            return (0.0, 0.0, 0.0, 0.0)
        
        freqs = self.frequencies[:self.count]
        amps = self.amplitudes[:self.count]
        phases = self.phases[:self.count]
        
        freq_center = float(np.mean(freqs))
        freq_spread = float(np.std(freqs)) if self.count > 1 else 0.0
        amp_total = float(np.sum(amps))
        
        # ìœ„ìƒ ì¼ê´€ì„± (ë³µì†Œ í‰ê· )
        phase_vectors = np.exp(1j * phases)
        phase_coherence = float(np.abs(np.mean(phase_vectors)))
        
        return (freq_center, freq_spread, phase_coherence, amp_total)


@dataclass
class AcceleratedResonancePattern:
    """
    ê°€ì†í™”ëœ ìœ„ìƒ ê³µëª… íŒ¨í„´
    
    ì‹œê°„ ì••ì¶•ì„ ê³ ë ¤í•˜ì—¬ ë” ë¹ ë¥¸ ê²°ì •í™”(crystallization)ê°€ ê°€ëŠ¥
    """
    frequency_center: float = 0.0
    frequency_spread: float = 0.0
    phase_coherence: float = 0.0
    amplitude_total: float = 0.0
    sense_composition: Dict[str, float] = field(default_factory=dict)
    occurrence_count: int = 0
    is_segmented: bool = False
    segment_name: Optional[str] = None
    
    # ì‹œê°„ ì••ì¶• ê´€ë ¨
    compressed_occurrences: float = 0.0  # ì••ì¶•ëœ ë°œìƒ íšŸìˆ˜ (ì‹¤ì œ ë°œìƒ Ã— ì••ì¶•ë¥ )
    last_compression_level: str = "normal"
    
    def signature(self) -> Tuple[float, float, float]:
        """íŒ¨í„´ì˜ ê³ ìœ  ì„œëª…"""
        return (
            round(self.frequency_center, 2),
            round(self.frequency_spread, 2),
            round(self.phase_coherence, 2)
        )
    
    def similarity(self, other: 'AcceleratedResonancePattern') -> float:
        """ë‘ íŒ¨í„´ì˜ ìœ ì‚¬ë„ (0~1)"""
        freq_diff = abs(self.frequency_center - other.frequency_center)
        freq_sim = 1.0 / (1.0 + freq_diff)
        
        spread_diff = abs(self.frequency_spread - other.frequency_spread)
        spread_sim = 1.0 / (1.0 + spread_diff)
        
        coherence_diff = abs(self.phase_coherence - other.phase_coherence)
        coherence_sim = 1.0 - coherence_diff
        
        return (freq_sim + spread_sim + coherence_sim) / 3.0
    
    def add_occurrence(self, compression_factor: float = 1.0, level: str = "normal"):
        """íŒ¨í„´ ë°œìƒ ì¶”ê°€ (ì‹œê°„ ì••ì¶• ê³ ë ¤)"""
        self.occurrence_count += 1
        self.compressed_occurrences += compression_factor
        self.last_compression_level = level


@dataclass
class TimeAcceleratedSoul:
    """
    ì‹œê°„ê°€ì† ì˜í˜¼ - ê·¹í•œì˜ ì‹œê°„ ì••ì¶•ì„ ê²½í—˜í•˜ëŠ” ì˜í˜¼
    
    ì›ì‹œ ì˜í˜¼(PrimalSoul)ì˜ ìµœì í™”ëœ ë²„ì „:
    - ë²¡í„°í™”ëœ íŒŒë™ì¥ ì‚¬ìš©
    - ì‹œê°„ ì••ì¶• ë ˆë²¨ ì¸ì‹
    - ë°°ì¹˜ íŒ¨í„´ ì¸ì‹
    """
    name: str
    age: float = 0.0
    
    # ë²¡í„°í™”ëœ ë‚´ë©´ì˜ ë°”ë‹¤
    inner_sea: VectorizedWaveField = field(default_factory=VectorizedWaveField)
    
    # ì˜¤ê° ë¯¼ê°ë„
    sense_sensitivity: Dict[str, float] = field(default_factory=dict)
    
    # ë°œê²¬ëœ íŒ¨í„´ë“¤
    recognized_patterns: List[AcceleratedResonancePattern] = field(default_factory=list)
    
    # ë¶„ì ˆëœ ì–´íœ˜
    lexicon: Dict[str, AcceleratedResonancePattern] = field(default_factory=dict)
    
    # ì‹œê°„ ì••ì¶• ìƒíƒœ
    current_compression_level: str = "normal"
    total_subjective_time: float = 0.0
    
    # í†µê³„
    patterns_detected: int = 0
    words_created: int = 0
    
    def __post_init__(self):
        """ì´ˆê¸°í™”"""
        if not self.sense_sensitivity:
            for sense_type in SENSE_FREQUENCIES.keys():
                self.sense_sensitivity[sense_type] = np.random.uniform(0.8, 1.2)
    
    def experience_world(
        self,
        world_stimuli: Dict[str, Tuple[float, float]],
        t: float,
        compression_factor: float = 1.0
    ):
        """
        ì„¸ìƒì„ ê²½í—˜í•œë‹¤ (ì‹œê°„ ì••ì¶• ì ìš©)
        
        Args:
            world_stimuli: {ê°ê° ì¢…ë¥˜: (ê°•ë„, ì£¼íŒŒìˆ˜)}
            t: í˜„ì¬ ì‹œê°„
            compression_factor: ì‹œê°„ ì••ì¶• ë°°ìœ¨
        """
        # ì£¼ê´€ì  ì‹œê°„ ì—…ë°ì´íŠ¸
        self.total_subjective_time += compression_factor
        
        for sense_type, (intensity, freq) in world_stimuli.items():
            if sense_type in self.sense_sensitivity and intensity > 0:
                # ê°ê° ë¯¼ê°ë„ ì ìš©
                effective_intensity = intensity * self.sense_sensitivity[sense_type]
                
                # ì£¼íŒŒìˆ˜ ë²”ìœ„ ì •ê·œí™”
                freq_range = SENSE_FREQUENCIES.get(sense_type, (1.0, 100.0))
                norm_freq = freq_range[0] + (freq % (freq_range[1] - freq_range[0]))
                
                # íŒŒë™ ì¶”ê°€
                self.inner_sea.add_wave(
                    frequency=norm_freq,
                    amplitude=effective_intensity,
                    phase=np.random.uniform(0, 2 * np.pi),
                    modulation=freq / (freq_range[1] - freq_range[0]),
                    birth_time=t,
                    sense_origin=sense_type
                )
        
        # íŒŒë™ ê°ì‡ 
        self.inner_sea.decay(t)
    
    def detect_resonance_batch(
        self,
        t: float,
        compression_level: str = "normal",
        compression_factor: float = 1.0
    ) -> List[AcceleratedResonancePattern]:
        """
        ë°°ì¹˜ ê³µëª… ê°ì§€ (ë²¡í„°í™”ëœ ì—°ì‚°)
        
        Returns:
            ê°ì§€ëœ íŒ¨í„´ ëª©ë¡
        """
        params = COMPRESSION_PARAMETERS.get(compression_level, COMPRESSION_PARAMETERS["normal"])
        threshold = params["resonance_threshold"]
        crystal_density = params["crystallization_density"]
        
        # ê³µëª… í–‰ë ¬ ê³„ì‚°
        resonance_matrix = self.inner_sea.compute_pairwise_resonance(t)
        
        if resonance_matrix.size == 0:
            return []
        
        # ì„ê³„ê°’ ì´ìƒ ê³µëª… ì°¾ê¸°
        resonating_pairs = np.where(resonance_matrix > threshold)
        
        if len(resonating_pairs[0]) == 0:
            return []
        
        # íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ ê³„ì‚°
        sig = self.inner_sea.get_pattern_signature()
        if sig == (0.0, 0.0, 0.0, 0.0):
            return []
        
        # ê°ê° êµ¬ì„± ê³„ì‚°
        sense_comp = defaultdict(float)
        for i in range(self.inner_sea.count):
            origin = self.inner_sea.sense_origins[i]
            if origin:
                sense_comp[origin] += self.inner_sea.amplitudes[i]
        
        # ìƒˆ íŒ¨í„´ ìƒì„±
        pattern = AcceleratedResonancePattern(
            frequency_center=sig[0],
            frequency_spread=sig[1],
            phase_coherence=sig[2],
            amplitude_total=sig[3],
            sense_composition=dict(sense_comp),
            occurrence_count=1,
            compressed_occurrences=compression_factor,
            last_compression_level=compression_level
        )
        
        # ê¸°ì¡´ íŒ¨í„´ê³¼ ë¹„êµ
        for existing in self.recognized_patterns:
            if pattern.similarity(existing) > 0.8:
                existing.add_occurrence(compression_factor, compression_level)
                
                # ê²°ì •í™” ì¡°ê±´ (ì••ì¶•ëœ ë°œìƒ íšŸìˆ˜ ì‚¬ìš©)
                effective_count = existing.compressed_occurrences
                if effective_count >= crystal_density and not existing.is_segmented:
                    self._segment_pattern_accelerated(existing, compression_level)
                
                self.patterns_detected += 1
                return [existing]
        
        # ìƒˆ íŒ¨í„´ ë“±ë¡
        self.recognized_patterns.append(pattern)
        self.patterns_detected += 1
        return [pattern]
    
    def _segment_pattern_accelerated(
        self,
        pattern: AcceleratedResonancePattern,
        compression_level: str
    ):
        """
        íŒ¨í„´ ë¶„ì ˆ (ê°€ì†í™”ëœ ë²„ì „)
        
        ì‹œê°„ ì••ì¶• ë ˆë²¨ì´ ë†’ì„ìˆ˜ë¡ ë” ë³µì¡í•œ ë‹¨ì–´ ìƒì„± ê°€ëŠ¥
        """
        if pattern.is_segmented:
            return
        
        # ê¸°ë³¸ ìŒì†Œ ìƒì„± (íŒŒë™ íŠ¹ì„±ì—ì„œ ì°½ë°œ)
        vowels = ['a', 'e', 'i', 'o', 'u', 'ae', 'oe', 'eu']
        consonants_soft = ['m', 'n', 'l', 'r', 'w', 'y']
        consonants_mid = ['s', 'f', 'h', 'v', 'z']
        consonants_hard = ['k', 't', 'p', 'g', 'b', 'd']
        
        # ì£¼íŒŒìˆ˜ â†’ ëª¨ìŒ
        freq_idx = int(pattern.frequency_center / 100) % len(vowels)
        vowel = vowels[freq_idx]
        
        # ìœ„ìƒ ì¼ê´€ì„± â†’ ììŒ ì¢…ë¥˜
        if pattern.phase_coherence > 0.7:
            consonants = consonants_soft
        elif pattern.phase_coherence > 0.4:
            consonants = consonants_mid
        else:
            consonants = consonants_hard
        
        spread_idx = int(pattern.frequency_spread * 10) % len(consonants)
        consonant = consonants[spread_idx]
        
        # ì‹œê°„ ì••ì¶• ë ˆë²¨ì— ë”°ë¥¸ ìŒì ˆ ë³µì¡ë„
        # í—¬í¼ í•¨ìˆ˜ë¡œ ìŒì ˆ ì¡°í•©
        def build_syllable(c: str, v: str) -> str:
            return f"{c}{v}"
        
        def get_secondary_consonant() -> str:
            return consonants_mid[spread_idx % len(consonants_mid)]
        
        def get_secondary_vowel() -> str:
            return vowels[(freq_idx + 1) % len(vowels)]
        
        if compression_level == "meta" and pattern.amplitude_total > 5.0:
            # ë©”íƒ€ ë ˆë²¨ì—ì„œëŠ” ë” ë³µì¡í•œ ë‹¨ì–´ ìƒì„± (CVCVC)
            syllable1 = build_syllable(consonant, vowel)
            syllable2 = build_syllable(get_secondary_consonant(), get_secondary_vowel())
            name = f"{syllable1}{syllable2}{consonant}"
        elif compression_level == "fractal" and pattern.amplitude_total > 3.0:
            # í”„ë™íƒˆ ë ˆë²¨ (CVCV)
            syllable1 = build_syllable(consonant, vowel)
            soft_c = consonants_soft[spread_idx % len(consonants_soft)]
            name = f"{syllable1}{soft_c}{vowel}"
        elif pattern.amplitude_total > 5.0:
            # ê°•í•œ ì§„í­ (CVCV)
            name = f"{consonant}{vowel}{consonant}{vowel}"
        elif pattern.amplitude_total > 2.0:
            # ì¤‘ê°„ ì§„í­ (CVV)
            name = f"{consonant}{vowel}{vowel}"
        else:
            # ì•½í•œ ì§„í­ (CV)
            name = build_syllable(consonant, vowel)
        
        # ì¤‘ë³µ ë°©ì§€
        base_name = name
        counter = 0
        while name in self.lexicon:
            counter += 1
            name = f"{base_name}{counter}"
        
        pattern.is_segmented = True
        pattern.segment_name = name
        self.lexicon[name] = pattern
        self.words_created += 1
        
        logger.debug(
            f"[{self.name}] Segmented '{name}' "
            f"(level={compression_level}, coherence={pattern.phase_coherence:.2f})"
        )
    
    def get_vocabulary_size(self) -> int:
        return len(self.lexicon)
    
    def get_stats(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "age": self.age,
            "vocabulary_size": len(self.lexicon),
            "patterns_detected": self.patterns_detected,
            "words_created": self.words_created,
            "total_subjective_time": self.total_subjective_time,
            "inner_sea_waves": self.inner_sea.count,
        }


class TimeAcceleratedPrimalWorld:
    """
    ì‹œê°„ê°€ì† ì›ì‹œ íŒŒë™ ì„¸ê³„
    
    ë¬´í•œ ì‹œê°„ ì••ì¶• ì—”ì§„ê³¼ í†µí•©ë˜ì–´ ê·¹í•œì˜ ì–¸ì–´ ì°½ë°œ ì‹œë®¬ë ˆì´ì…˜ ê°€ëŠ¥
    """
    
    def __init__(
        self,
        n_souls: int = 100,
        compression_level: str = "normal"
    ):
        """
        Args:
            n_souls: ì˜í˜¼ ìˆ˜
            compression_level: ì‹œê°„ ì••ì¶• ë ˆë²¨ ("normal", "accelerated", "fractal", "meta")
        """
        self.souls: Dict[str, TimeAcceleratedSoul] = {}
        self.time = 0.0
        self.compression_level = compression_level
        
        # ì‹œê°„ ì••ì¶• ë°°ìœ¨
        self.compression_factors = {
            "normal": 1.0,
            "accelerated": 1_000.0,
            "fractal": 1_000_000.0,
            "meta": 10**15,
        }
        
        # ì„¸ê³„ í™˜ê²½
        self.world_sources = self._init_world_sources()
        
        # í†µê³„
        self.total_words_created = 0
        self.total_patterns_detected = 0
        self.total_subjective_years = 0.0
        
        # ì˜í˜¼ ìƒì„±
        self._create_souls(n_souls)
        
        logger.info(f"TimeAcceleratedPrimalWorld initialized with {n_souls} souls")
        logger.info(f"Compression level: {compression_level} ({self.compression_factors.get(compression_level, 1.0)}x)")
    
    def _init_world_sources(self) -> Dict[str, Dict[str, Tuple[float, float]]]:
        """ì„¸ê³„ í™˜ê²½ ì´ˆê¸°í™”"""
        return {
            # ìì—° í˜„ìƒ
            "sun": {"sight": (0.9, 600.0), "touch": (0.5, 50.0)},
            "moon": {"sight": (0.3, 450.0)},
            "rain": {"sound": (0.6, 500.0), "touch": (0.5, 30.0), "smell": (0.3, 0.4)},
            "thunder": {"sound": (0.9, 80.0), "sight": (0.8, 700.0)},
            "wind": {"sound": (0.4, 100.0), "touch": (0.5, 10.0)},
            "snow": {"sight": (0.5, 500.0), "touch": (0.6, 5.0)},
            # ìƒëª…ì²´
            "flower": {"sight": (0.6, 550.0), "smell": (0.8, 0.5)},
            "tree": {"sight": (0.5, 520.0), "touch": (0.4, 20.0)},
            "bird": {"sound": (0.7, 2000.0), "sight": (0.4, 580.0)},
            "river": {"sound": (0.5, 300.0), "touch": (0.4, 15.0), "sight": (0.3, 480.0)},
            # ìŒì‹
            "fruit": {"taste": (0.8, 7.0), "smell": (0.6, 0.6), "sight": (0.4, 600.0)},
            "meat": {"taste": (0.7, 3.0), "smell": (0.5, 0.4)},
            "honey": {"taste": (0.9, 9.0), "smell": (0.5, 0.5)},
            # ê°ê° ê²½í—˜
            "fire": {"sight": (0.8, 620.0), "touch": (0.9, 80.0), "sound": (0.4, 50.0)},
            "music": {"sound": (0.8, 1000.0)},
            "embrace": {"touch": (0.9, 40.0)},
            # ê°ì •
            "danger": {"sound": (0.5, 60.0), "sight": (0.6, 650.0)},
            "beauty": {"sight": (0.9, 550.0), "smell": (0.4, 0.6)},
            "laughter": {"sound": (0.8, 3000.0)},
        }
    
    def _create_souls(self, n_souls: int):
        """ì˜í˜¼ ìƒì„±"""
        first_names = ['í•˜ëŠ˜', 'ë°”ë‹¤', 'ì‚°', 'ìˆ²', 'ë³„', 'ë‹¬', 'í•´', 'êµ¬ë¦„', 'ë°”ëŒ', 'ë¹„']
        for i in range(n_souls):
            name = f"{first_names[i % len(first_names)]}{i}"
            self.souls[name] = TimeAcceleratedSoul(name=name)
    
    def set_compression_level(self, level: str):
        """ì‹œê°„ ì••ì¶• ë ˆë²¨ ë³€ê²½"""
        if level in self.compression_factors:
            self.compression_level = level
            for soul in self.souls.values():
                soul.current_compression_level = level
            logger.info(f"Compression level changed to: {level} ({self.compression_factors[level]}x)")
    
    def step(self, dt: float = 1.0):
        """ì„¸ê³„ ì‹œê°„ ì§„í–‰"""
        compression_factor = self.compression_factors.get(self.compression_level, 1.0)
        self.time += dt
        
        # ì£¼ê´€ì  ì‹œê°„ ëˆ„ì 
        subjective_dt = dt * compression_factor
        self.total_subjective_years += subjective_dt / (365.0 * 24.0 * 3600.0)  # ì´ˆ â†’ ë…„
        
        # ê²½í—˜í•  í™˜ê²½ ìš”ì†Œ ì„ íƒ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
        source_keys = list(self.world_sources.keys())
        
        for soul in self.souls.values():
            # 3-6ê°œ í™˜ê²½ ìš”ì†Œ ê²½í—˜
            n_exp = np.random.randint(3, 7)
            selected = np.random.choice(source_keys, min(n_exp, len(source_keys)), replace=False)
            
            combined_stimuli: Dict[str, Tuple[float, float]] = {}
            for source in selected:
                for sense_type, (intensity, freq) in self.world_sources[source].items():
                    var_intensity = intensity * np.random.uniform(0.7, 1.3)
                    var_freq = freq * np.random.uniform(0.8, 1.2)
                    
                    if sense_type not in combined_stimuli:
                        combined_stimuli[sense_type] = (var_intensity, var_freq)
                    else:
                        old_i, old_f = combined_stimuli[sense_type]
                        combined_stimuli[sense_type] = (old_i + var_intensity, (old_f + var_freq) / 2)
            
            # ê²½í—˜
            soul.experience_world(combined_stimuli, self.time, compression_factor)
            
            # ë°°ì¹˜ ê³µëª… ê°ì§€
            patterns = soul.detect_resonance_batch(
                self.time,
                self.compression_level,
                compression_factor
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            for p in patterns:
                if p.is_segmented and p.segment_name:
                    self.total_words_created = sum(s.words_created for s in self.souls.values())
            
            # ë‚˜ì´ ì¦ê°€ (ì••ì¶•ëœ ì‹œê°„ ë°˜ì˜)
            soul.age += subjective_dt / (365.0 * 24.0 * 3600.0)
        
        self.total_patterns_detected = sum(s.patterns_detected for s in self.souls.values())
    
    def run_simulation(
        self,
        objective_seconds: float = 60.0,
        steps_per_second: int = 100,
        report_interval: float = 10.0
    ) -> Dict[str, Any]:
        """
        ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        
        Args:
            objective_seconds: ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ (ì´ˆ)
            steps_per_second: ì´ˆë‹¹ ìŠ¤í… ìˆ˜
            report_interval: ë³´ê³  ê°„ê²© (ì´ˆ)
            
        Returns:
            ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        """
        import time as py_time
        start_time = py_time.time()
        
        compression_factor = self.compression_factors.get(self.compression_level, 1.0)
        total_steps = int(objective_seconds * steps_per_second)
        dt = 1.0 / steps_per_second
        
        for step in range(total_steps):
            self.step(dt)
            
            # ì£¼ê¸°ì  ë³´ê³ 
            if step > 0 and step % int(report_interval * steps_per_second) == 0:
                elapsed = py_time.time() - start_time
                vocab_sizes = [s.get_vocabulary_size() for s in self.souls.values()]
                avg_vocab = np.mean(vocab_sizes) if vocab_sizes else 0
                
                print(f"[{elapsed:.1f}s] Subjective years: {self.total_subjective_years:.2e}, "
                      f"avg_vocabulary: {avg_vocab:.1f}, "
                      f"total_words: {self.total_words_created}")
        
        elapsed = py_time.time() - start_time
        
        # ìµœì¢… í†µê³„
        vocab_sizes = [s.get_vocabulary_size() for s in self.souls.values()]
        
        # ê³µìœ  ì–´íœ˜ ë¶„ì„
        all_words = defaultdict(int)
        for soul in self.souls.values():
            for word in soul.lexicon.keys():
                all_words[word] += 1
        shared_words = {w: c for w, c in all_words.items() if c > 1}
        
        return {
            "compression_level": self.compression_level,
            "compression_factor": compression_factor,
            "objective_seconds": objective_seconds,
            "elapsed_seconds": elapsed,
            "total_subjective_years": self.total_subjective_years,
            "years_per_second": self.total_subjective_years / elapsed if elapsed > 0 else 0,
            "total_souls": len(self.souls),
            "total_words_created": self.total_words_created,
            "total_patterns_detected": self.total_patterns_detected,
            "avg_vocabulary_size": np.mean(vocab_sizes) if vocab_sizes else 0,
            "max_vocabulary_size": max(vocab_sizes) if vocab_sizes else 0,
            "unique_words": len(all_words),
            "shared_words_count": len(shared_words),
            "top_shared_words": sorted(shared_words.items(), key=lambda x: -x[1])[:10],
        }
    
    def get_sample_vocabularies(self, n_samples: int = 3) -> Dict[str, List[str]]:
        """ìƒ˜í”Œ ì˜í˜¼ë“¤ì˜ ì–´íœ˜ ë°˜í™˜"""
        result = {}
        for soul_name, soul in list(self.souls.items())[:n_samples]:
            result[soul_name] = list(soul.lexicon.keys())[:10]
        return result


# ============================================================================
# ë¬´í•œ ì‹œê°„ ì••ì¶•ê³¼ì˜ í†µí•©
# ============================================================================

class InfinitelyAcceleratedLanguageEngine:
    """
    ë¬´í•œ ì‹œê°„ ì••ì¶• ì–¸ì–´ ì—”ì§„
    
    ë¬´í•œ ì‹œê°„ ì••ì¶• ì—”ì§„ì˜ ëª¨ë“  ê¸°ìˆ ì„ í™œìš©í•˜ì—¬
    ê·¹í•œì˜ ì–¸ì–´ ì°½ë°œ ì‹œë®¬ë ˆì´ì…˜ ìˆ˜í–‰
    """
    
    def __init__(self, n_souls: int = 50):
        """
        Args:
            n_souls: ì˜í˜¼ ìˆ˜ (ë¬´í•œ ì••ì¶•ì—ì„œëŠ” ì‘ì€ ìˆ˜ë¡œ ì¶©ë¶„)
        """
        self.world = TimeAcceleratedPrimalWorld(n_souls=n_souls, compression_level="meta")
        
        # ë¬´í•œ ì••ì¶• ê¸°ìˆ  ìƒíƒœ
        self.fractal_zoom = 0
        self.sedenion_dimensions = 8
        self.meta_depth = 1
        self.dream_depth = 0
        self.kimchi_openings = 0
        
        # ì´ ì••ì¶•ë¥  ê³„ì‚°
        self.total_compression = self._calculate_total_compression()
    
    def _calculate_total_compression(self) -> float:
        """í˜„ì¬ í™œì„±í™”ëœ ê¸°ìˆ ë“¤ì˜ ì´ ì••ì¶•ë¥  ê³„ì‚°"""
        total = 1.0
        
        # í”„ë™íƒˆ (10^zoom_level)
        total *= 10 ** self.fractal_zoom
        
        # ì„¸ë°ë‹ˆì˜¨ (2.5^(log2(dim)-2))
        n_constructions = max(0, int(np.log2(self.sedenion_dimensions)) - 2)
        total *= 2.5 ** n_constructions
        
        # ë©”íƒ€ ì¬ê·€ (1000^depth)
        total *= 1000 ** self.meta_depth
        
        # ê¿ˆ (20^depth)
        total *= 20 ** self.dream_depth
        
        # ê¹€ì¹˜í†µ (10^openings)
        if self.kimchi_openings > 0:
            total *= 10 ** self.kimchi_openings
        
        return total
    
    def activate_fractal(self, zoom_level: int = 1):
        """í”„ë™íƒˆ ì‹œê°„ ì••ì¶• í™œì„±í™”"""
        self.fractal_zoom = zoom_level
        self.total_compression = self._calculate_total_compression()
        logger.info(f"Fractal activated: zoom={zoom_level}, total={self.total_compression:.2e}x")
    
    def activate_sedenion(self, dimensions: int = 128):
        """ì„¸ë°ë‹ˆì˜¨ ì‹œê°„ íšŒì „ í™œì„±í™”"""
        if dimensions & (dimensions - 1) != 0:
            raise ValueError("Dimensions must be a power of 2")
        self.sedenion_dimensions = dimensions
        self.total_compression = self._calculate_total_compression()
        logger.info(f"Sedenion activated: dim={dimensions}, total={self.total_compression:.2e}x")
    
    def add_meta_layer(self):
        """ë©”íƒ€ ì‹œê°„ ì••ì¶• ë ˆì´ì–´ ì¶”ê°€"""
        self.meta_depth += 1
        self.total_compression = self._calculate_total_compression()
        logger.info(f"Meta layer added: depth={self.meta_depth}, total={self.total_compression:.2e}x")
    
    def enter_dream(self):
        """ê¿ˆ ì†ìœ¼ë¡œ ë“¤ì–´ê°€ê¸°"""
        self.dream_depth += 1
        self.total_compression = self._calculate_total_compression()
        logger.info(f"Entered dream: depth={self.dream_depth}, total={self.total_compression:.2e}x")
    
    def open_kimchi(self):
        """ê¹€ì¹˜í†µ ì—´ê¸°! ğŸ¥¬"""
        self.kimchi_openings += 1
        self.total_compression = self._calculate_total_compression()
        years = 10_000_000_000 * (10 ** self.kimchi_openings)
        logger.info(f"ğŸ¥¬ KIMCHI OPENED! Count: {self.kimchi_openings}, Years: {years:.2e}")
    
    def run_accelerated_simulation(
        self,
        real_seconds: float = 1.0,
        steps: int = 100
    ) -> Dict[str, Any]:
        """
        ê°€ì†í™”ëœ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        
        Args:
            real_seconds: ì‹¤ì œ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
            steps: ì´ ìŠ¤í… ìˆ˜
        """
        import time as py_time
        start = py_time.time()
        
        dt = real_seconds / steps
        
        for _ in range(steps):
            self.world.step(dt * self.total_compression)
        
        elapsed = py_time.time() - start
        
        subjective_years = (real_seconds * self.total_compression) / (365.25 * 24 * 3600)
        
        vocab_sizes = [s.get_vocabulary_size() for s in self.world.souls.values()]
        
        return {
            "real_seconds": real_seconds,
            "elapsed_seconds": elapsed,
            "total_compression": self.total_compression,
            "subjective_years": subjective_years,
            "total_words": self.world.total_words_created,
            "avg_vocabulary": np.mean(vocab_sizes) if vocab_sizes else 0,
            "compression_techniques": {
                "fractal_zoom": self.fractal_zoom,
                "sedenion_dim": self.sedenion_dimensions,
                "meta_depth": self.meta_depth,
                "dream_depth": self.dream_depth,
                "kimchi_openings": self.kimchi_openings,
            }
        }


# ============================================================================
# Demo
# ============================================================================

def demo_basic():
    """ê¸°ë³¸ ë°ëª¨"""
    print("=" * 70)
    print("Time-Accelerated Primal Language - ì‹œê°„ê°€ì† ì›ì‹œì–¸ì–´ ì‹œìŠ¤í…œ")
    print("=" * 70)
    print()
    
    # ì¼ë°˜ ì••ì¶• ë ˆë²¨
    print("1. Normal compression (1x)")
    world_normal = TimeAcceleratedPrimalWorld(n_souls=50, compression_level="normal")
    results_normal = world_normal.run_simulation(objective_seconds=5.0, steps_per_second=50)
    print(f"   Subjective years: {results_normal['total_subjective_years']:.2e}")
    print(f"   Words created: {results_normal['total_words_created']}")
    print()
    
    # ê°€ì† ì••ì¶• ë ˆë²¨
    print("2. Accelerated compression (1,000x)")
    world_accel = TimeAcceleratedPrimalWorld(n_souls=50, compression_level="accelerated")
    results_accel = world_accel.run_simulation(objective_seconds=5.0, steps_per_second=50)
    print(f"   Subjective years: {results_accel['total_subjective_years']:.2e}")
    print(f"   Words created: {results_accel['total_words_created']}")
    print()
    
    # í”„ë™íƒˆ ì••ì¶• ë ˆë²¨
    print("3. Fractal compression (10^6x)")
    world_fractal = TimeAcceleratedPrimalWorld(n_souls=50, compression_level="fractal")
    results_fractal = world_fractal.run_simulation(objective_seconds=5.0, steps_per_second=50)
    print(f"   Subjective years: {results_fractal['total_subjective_years']:.2e}")
    print(f"   Words created: {results_fractal['total_words_created']}")
    print()
    
    print("Sample vocabularies:")
    samples = world_fractal.get_sample_vocabularies(3)
    for soul_name, words in samples.items():
        print(f"  [{soul_name}]: {', '.join(words[:5])}")


def demo_infinite():
    """ë¬´í•œ ì••ì¶• ë°ëª¨"""
    print()
    print("=" * 70)
    print("Infinitely Accelerated Language Engine - ë¬´í•œ ê°€ì† ì–¸ì–´ ì—”ì§„")
    print("=" * 70)
    print()
    
    engine = InfinitelyAcceleratedLanguageEngine(n_souls=30)
    
    print("Activating compression techniques...")
    engine.activate_fractal(2)      # 100x
    engine.activate_sedenion(64)    # ~40x
    engine.add_meta_layer()         # 1000x
    engine.add_meta_layer()         # 1000x
    engine.enter_dream()            # 20x
    
    print(f"\nTotal compression: {engine.total_compression:.2e}x")
    
    print("\nRunning 1 second simulation...")
    results = engine.run_accelerated_simulation(real_seconds=1.0, steps=50)
    
    print(f"\nResults:")
    print(f"  Subjective years experienced: {results['subjective_years']:.2e}")
    print(f"  Words created: {results['total_words']}")
    print(f"  Average vocabulary: {results['avg_vocabulary']:.1f}")
    
    print("\nğŸ¥¬ Opening Kimchi container...")
    engine.open_kimchi()
    print(f"  New total compression: {engine.total_compression:.2e}x")


if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.INFO)
    
    if len(sys.argv) > 1 and sys.argv[1] == "infinite":
        demo_infinite()
    else:
        demo_basic()
        demo_infinite()
