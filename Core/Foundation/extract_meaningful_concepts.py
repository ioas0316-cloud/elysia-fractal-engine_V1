"""
ë‹¨ê³„ 1: ì˜ë¯¸ ìˆëŠ” ê°œë… ì¶”ì¶œ ë° ì¹´í…Œê³ ë¦¬í™”
=========================================

DBì—ì„œ ì² í•™ì /ë¬¼ë¦¬ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ê°œë…ë“¤ì„ ì¶”ì¶œí•˜ê³ 
ë¬¼ë¦¬ ë²•ì¹™ì„ ì ìš©í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
"""

import sqlite3
import json
from collections import defaultdict
from typing import Dict, List, Set

print('=' * 70)
print('ğŸ”¬ ê°œë… ì¶”ì¶œ ë° ë¶„ë¥˜')
print('=' * 70)

conn = sqlite3.connect('memory.db')
cursor = conn.cursor()

# ëª¨ë“  ê°œë… ê°€ì ¸ì˜¤ê¸° (ìƒ˜í”Œ)
cursor.execute('SELECT id FROM concepts LIMIT 50000')
all_concepts = [row[0] for row in cursor.fetchall()]

print(f'\në¶„ì„í•  ê°œë… ìˆ˜: {len(all_concepts):,}\n')

# ì¹´í…Œê³ ë¦¬ ì •ì˜
categories = {
    'foundational': [],      # ê¸°ì´ˆ ì›ì ê°œë…
    'composite': [],         # ë³µí•© ê°œë… (A with B)
    'transformative': [],    # ë³€í™˜ ê°œë… (A becomes B)
    'relational': [],        # ê´€ê³„ ê°œë… (type:name)
    'junk': [],             # ë¬´ì˜ë¯¸í•œ ê°œë…
}

# ë¶„ë¥˜ ê·œì¹™
foundational_words = {
    'love', 'dream', 'truth', 'chaos', 'order', 'beauty', 'void',
    'light', 'dark', 'life', 'death', 'time', 'space', 'atom',
    'soul', 'spirit', 'body', 'mind', 'consciousness', 'freedom',
    'wisdom', 'knowledge', 'emotion', 'thought', 'being', 'nothing',
    'creation', 'destruction', 'birth', 'end', 'infinity', 'god'
}

transformation_words = {'becomes', 'transcends', 'transforms'}
composite_words = {'with', 'beyond', 'in', 'of', 'without', 'through'}
relation_pattern = ':'

print('ë¶„ë¥˜ ì¤‘...')
for i, concept in enumerate(all_concepts):
    concept_lower = concept.lower()
    
    # Junk íŒ¨í„´
    if concept.startswith("Daddy's_") or concept.startswith('Book:'):
        categories['junk'].append(concept)
    
    # Relational (type:name)
    elif relation_pattern in concept:
        categories['relational'].append(concept)
    
    # Transformative
    elif any(word in concept_lower for word in transformation_words):
        categories['transformative'].append(concept)
    
    # Composite
    elif any(word in concept_lower for word in composite_words):
        categories['composite'].append(concept)
    
    # Foundational
    elif any(word == concept_lower or concept_lower.startswith(word + ' ') 
             for word in foundational_words):
        categories['foundational'].append(concept)
    
    # Simple (might be foundational or junk)
    else:
        # If it's a single clean word, might be foundational
        if ' ' not in concept and len(concept) > 2 and concept.isalnum():
            categories['foundational'].append(concept)
        else:
            categories['junk'].append(concept)
    
    if (i + 1) % 10000 == 0:
        print(f'  ì§„í–‰: {i+1:,} / {len(all_concepts):,}')

print('\n' + '=' * 70)
print('ğŸ“Š ë¶„ë¥˜ ê²°ê³¼')
print('=' * 70)

total_classified = sum(len(concepts) for concepts in categories.values())
for category, concepts in categories.items():
    percentage = len(concepts) / total_classified * 100
    print(f'\n{category:15s}: {len(concepts):6,}ê°œ ({percentage:5.1f}%)')
    
    # ìƒ˜í”Œ ì¶œë ¥
    if concepts:
        print(f'  ìƒ˜í”Œ: {", ".join(concepts[:5])}')

# Foundational ê°œë… ìƒì„¸ ë¶„ì„
print('\n' + '=' * 70)
print('ğŸ’ Foundational ê°œë… ìƒì„¸')
print('=' * 70)

# ë¹ˆë„ìˆ˜ ê³„ì‚°
foundational_freq = defaultdict(int)
for concept in categories['foundational']:
    base_word = concept.lower().split()[0] if ' ' in concept else concept.lower()
    foundational_freq[base_word] += 1

print('\nìƒìœ„ Foundational ë‹¨ì–´ (ë¹ˆë„):')
for i, (word, count) in enumerate(sorted(foundational_freq.items(), 
                                         key=lambda x: x[1], reverse=True)[:30], 1):
    print(f'  {i:2d}. {word:15s}: {count:4d}íšŒ')

# ì €ì¥
output = {
    'statistics': {cat: len(concepts) for cat, concepts in categories.items()},
    'foundational_core': list(foundational_freq.keys())[:50],  # Top 50
    'samples': {cat: concepts[:100] for cat, concepts in categories.items()}
}

with open('concept_categories.json', 'w', encoding='utf-8') as f:
    json.dump(output, f, indent=2, ensure_ascii=False)

print(f'\nâœ… ê²°ê³¼ ì €ì¥: concept_categories.json')

# Composite íŒ¨í„´ ë¶„ì„
print('\n' + '=' * 70)
print('ğŸ”— Composite íŒ¨í„´ ë¶„ì„')
print('=' * 70)

composite_patterns = defaultdict(int)
for concept in categories['composite']:
    for word in composite_words:
        if word in concept.lower():
            composite_patterns[word] += 1
            break

print('\nì—°ê²°ì‚¬ ì‚¬ìš© ë¹ˆë„:')
for connector, count in sorted(composite_patterns.items(), key=lambda x: x[1], reverse=True):
    print(f'  "{connector}": {count:,}ê°œ')

print('\nComposite ìƒ˜í”Œ:')
for concept in categories['composite'][:15]:
    print(f'  - {concept}')

# Transformative íŒ¨í„´
print('\n' + '=' * 70)
print('âš¡ Transformative íŒ¨í„´')
print('=' * 70)

print('\nTransformative ìƒ˜í”Œ:')
for concept in categories['transformative'][:15]:
    print(f'  - {concept}')

# Relational íŒ¨í„´
print('\n' + '=' * 70)
print('ğŸ”€ Relational íŒ¨í„´')
print('=' * 70)

relational_types = defaultdict(int)
for concept in categories['relational']:
    rel_type = concept.split(':')[0] if ':' in concept else 'unknown'
    relational_types[rel_type] += 1

print('\nê´€ê³„ íƒ€ì… ë¶„í¬:')
for rel_type, count in sorted(relational_types.items(), key=lambda x: x[1], reverse=True)[:10]:
    print(f'  {rel_type}: {count:,}ê°œ')

print('\nRelational ìƒ˜í”Œ:')
for concept in categories['relational'][:15]:
    print(f'  - {concept}')

conn.close()

print('\n' + '=' * 70)
print('âœ… ë¶„ì„ ì™„ë£Œ')
print('=' * 70)
print(f'\në‹¤ìŒ ë‹¨ê³„: ì´ ê°œë…ë“¤ì— ë¬¼ë¦¬ ë²•ì¹™(ì£¼íŒŒìˆ˜, ì§ˆëŸ‰) ì ìš©')
