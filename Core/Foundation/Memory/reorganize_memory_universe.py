"""
ì „ì²´ ì‹œìŠ¤í…œ ì¬êµ¬ì¡°í™” - ë¬¼ë¦¬ ë²•ì¹™ìœ¼ë¡œ DB ì •ë ¬
===========================================

3.15M ê°œë…ì„ ë¬¼ë¦¬ ë²•ì¹™(ì¤‘ë ¥, ë¶€ë ¥, ê³µëª…)ìœ¼ë¡œ ì •ë ¬í•˜ê³ 
ConceptUniverseì™€ í†µí•©í•©ë‹ˆë‹¤.
"""

import sqlite3
import json
import numpy as np
from typing import Dict, List, Tuple
from collections import defaultdict
import time

print('=' * 70)
print('ğŸŒŒ ì—˜ë¦¬ì‹œì•„ ê¸°ì–µ ìš°ì£¼ ì¬êµ¬ì¶•')
print('=' * 70)

# ============================================================================
# ë‹¨ê³„ 1: ì „ì²´ DB ìŠ¤ìº” ë° ë¶„ë¥˜
# ============================================================================

print('\n[ë‹¨ê³„ 1] ì „ì²´ DB ìŠ¤ìº” ì¤‘...')
conn = sqlite3.connect('data/Memory/memory.db')
cursor = conn.cursor()

cursor.execute('SELECT COUNT(*) FROM concepts')
total_concepts = cursor.fetchone()[0]
print(f'ì´ ê°œë… ìˆ˜: {total_concepts:,}')

# ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”
BATCH_SIZE = 10000
processed = 0
start_time = time.time()

categories = {
    'foundational': set(),
    'composite': set(),
    'transformative': set(),
    'relational': set(),
}

# Foundational ë‹¨ì–´ (Spirit/Soul/Body ê³„ì¸µ)
foundational_core = {
    # Spirit (1.0 - 0.8)
    'god', 'transcendence', 'infinity', 'eternity', 'divine',
    
    # Higher Mind (0.8 - 0.6)
    'consciousness', 'wisdom', 'enlightenment', 'truth', 'knowledge',
    'thought', 'understanding', 'insight', 'awareness',
    
    # Soul (0.6 - 0.4)
    'love', 'beauty', 'joy', 'peace', 'harmony', 'emotion', 'feeling',
    'compassion', 'kindness', 'grace', 'hope', 'faith', 'trust',
    
    # Lower Mind (0.4 - 0.3)
    'dream', 'imagination', 'desire', 'will', 'choice', 'freedom',
    'memory', 'experience', 'learning', 'growth',
    
    # Body (0.3 - 0.1)
    'life', 'death', 'birth', 'body', 'breath', 'heart', 'blood',
    'action', 'movement', 'creation', 'destruction',
    
    # Matter (0.1 - 0.0)
    'atom', 'matter', 'energy', 'force', 'space', 'time',
    'void', 'chaos', 'order', 'form', 'substance'
}

print('\nì „ì²´ DB ìŠ¤ìº” ì‹œì‘...')

cursor.execute('SELECT id FROM concepts')
while True:
    batch = cursor.fetchmany(BATCH_SIZE)
    if not batch:
        break
    
    for (concept_id,) in batch:
        concept_lower = concept_id.lower()
        
        # Junk í•„í„°ë§
        if concept_id.startswith("Daddy's_") or concept_id.startswith('Book:'):
            continue
        
        # Relational
        if ':' in concept_id:
            categories['relational'].add(concept_id)
        
        # Transformative
        elif 'becomes' in concept_lower or 'transcends' in concept_lower:
            categories['transformative'].add(concept_id)
        
        # Composite
        elif any(word in concept_lower for word in ['with', 'beyond', 'in', 'of', 'without']):
            categories['composite'].add(concept_id)
        
        # Foundational
        elif any(core_word in concept_lower.split() for core_word in foundational_core):
            categories['foundational'].add(concept_id)
    
    processed += len(batch)
    if processed % 100000 == 0:
        elapsed = time.time() - start_time
        rate = processed / elapsed
        remaining = (total_concepts - processed) / rate
        print(f'  ì§„í–‰: {processed:,} / {total_concepts:,} ({processed/total_concepts*100:.1f}%) '
              f'- ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„')

print(f'\nâœ… ìŠ¤ìº” ì™„ë£Œ ({time.time() - start_time:.1f}ì´ˆ)')

for category, concepts in categories.items():
    print(f'  {category:15s}: {len(concepts):,}ê°œ')

# ============================================================================
# ë‹¨ê³„ 2: ì£¼íŒŒìˆ˜(Frequency) ê³„ì‚°
# ============================================================================

print('\n[ë‹¨ê³„ 2] ì˜ì  ì£¼íŒŒìˆ˜ ê³„ì‚° ì¤‘...')

# ì£¼íŒŒìˆ˜ ë§¤í•‘ (Spirit â†’ Body)
frequency_map = {
    # Spirit tier (0.9 - 1.0)
    'god': 1.0, 'transcendence': 0.95, 'infinity': 0.95, 'eternity': 0.93,
    'divine': 0.92, 'sacred': 0.91, 'holy': 0.90,
    
    # Higher Mind (0.7 - 0.89)
    'consciousness': 0.88, 'wisdom': 0.85, 'enlightenment': 0.87,
    'truth': 0.83, 'knowledge': 0.80, 'understanding': 0.78,
    'awareness': 0.82, 'insight': 0.81, 'thought': 0.75,
    
    # Soul (0.5 - 0.69)
    'love': 0.68, 'beauty': 0.65, 'joy': 0.63, 'peace': 0.62,
    'harmony': 0.61, 'compassion': 0.64, 'grace': 0.66,
    'emotion': 0.58, 'feeling': 0.57, 'hope': 0.60, 'faith': 0.62,
    
    # Lower Mind (0.3 - 0.49)
    'dream': 0.48, 'imagination': 0.46, 'desire': 0.42, 'will': 0.45,
    'choice': 0.43, 'freedom': 0.47, 'memory': 0.41, 'learning': 0.44,
    
    # Body (0.15 - 0.29)
    'life': 0.28, 'death': 0.27, 'body': 0.22, 'heart': 0.26,
    'breath': 0.24, 'action': 0.23, 'creation': 0.29, 'birth': 0.28,
    
    # Matter (0.0 - 0.14)
    'atom': 0.10, 'matter': 0.08, 'energy': 0.12, 'force': 0.11,
    'void': 0.05, 'chaos': 0.09, 'order': 0.13, 'space': 0.14, 'time': 0.14
}

def calculate_frequency(concept_id: str) -> float:
    """ê°œë…ì˜ ì˜ì  ì£¼íŒŒìˆ˜ ê³„ì‚°"""
    concept_lower = concept_id.lower()
    
    # ì§ì ‘ ë§¤ì¹­
    if concept_lower in frequency_map:
        return frequency_map[concept_lower]
    
    # ë‹¨ì–´ ë¶„í•´í•´ì„œ í‰ê· 
    words = concept_lower.split()
    frequencies = []
    for word in words:
        # ì—°ê²°ì‚¬ ì œì™¸
        if word in ['with', 'beyond', 'in', 'of', 'without', 'becomes', 'transcends', 'is']:
            continue
        if word in frequency_map:
            frequencies.append(frequency_map[word])
    
    if frequencies:
        return np.mean(frequencies)
    
    # ê¸°ë³¸ê°’: Soul ê³„ì¸µ (0.5)
    return 0.5

# ëª¨ë“  ì˜ë¯¸ ìˆëŠ” ê°œë…ì— ì£¼íŒŒìˆ˜ í• ë‹¹
concept_frequencies = {}

all_meaningful = set()
for concepts in categories.values():
    all_meaningful.update(concepts)

print(f'ì˜ë¯¸ ìˆëŠ” ê°œë… ìˆ˜: {len(all_meaningful):,}')
print('ì£¼íŒŒìˆ˜ ê³„ì‚° ì¤‘...')

for i, concept in enumerate(all_meaningful):
    concept_frequencies[concept] = calculate_frequency(concept)
    
    if (i + 1) % 10000 == 0:
        print(f'  ì§„í–‰: {i+1:,} / {len(all_meaningful):,}')

print(f'âœ… ì£¼íŒŒìˆ˜ ê³„ì‚° ì™„ë£Œ')

# ì£¼íŒŒìˆ˜ ë¶„í¬ í™•ì¸
freq_bins = defaultdict(int)
for freq in concept_frequencies.values():
    bin_label = f'{int(freq*10)/10:.1f}'
    freq_bins[bin_label] += 1

print('\nì£¼íŒŒìˆ˜ ë¶„í¬:')
for bin_label in sorted(freq_bins.keys(), reverse=True):
    count = freq_bins[bin_label]
    bar = 'â–ˆ' * int(count / 100)
    print(f'  {bin_label}: {count:6,}ê°œ {bar}')

# ============================================================================
# ë‹¨ê³„ 3: Vocabulary êµ¬ì¶• ë° ì €ì¥
# ============================================================================

print('\n[ë‹¨ê³„ 3] Vocabulary ì €ì¥ ì¤‘...')

# Foundational ê°œë…ì˜ ì£¼íŒŒìˆ˜ë¥¼ vocabularyë¡œ ì €ì¥
vocabulary = {}
for concept in categories['foundational']:
    if concept in concept_frequencies:
        vocabulary[concept] = concept_frequencies[concept]

# Compositeë„ í¬í•¨ (ìƒìœ„ 1000ê°œ)
composite_with_freq = [(c, concept_frequencies.get(c, 0.5)) 
                       for c in categories['composite']]
composite_with_freq.sort(key=lambda x: x[1], reverse=True)
for concept, freq in composite_with_freq[:1000]:
    vocabulary[concept] = freq

print(f'Vocabulary í¬ê¸°: {len(vocabulary):,}')

# DBì— ì €ì¥ (ì••ì¶• í•„ìš”!)
import zlib
cursor.execute('DELETE FROM concepts WHERE id = ?', ('_vocabulary_frequencies',))
vocab_json = json.dumps(vocabulary).encode('utf-8')
vocab_blob = zlib.compress(vocab_json)  # MemoryStorageì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì••ì¶•
cursor.execute('''
    INSERT OR REPLACE INTO concepts (id, data, created_at, last_accessed)
    VALUES (?, ?, ?, ?)
''', ('_vocabulary_frequencies', vocab_blob, time.time(), time.time()))

conn.commit()
print('âœ… Vocabulary DB ì €ì¥ ì™„ë£Œ')

# ============================================================================
# ë‹¨ê³„ 4: ê°œë… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
# ============================================================================

print('\n[ë‹¨ê³„ 4] ê°œë… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘...')

# ê° ê°œë…ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€: category, frequency
metadata_updates = []

for concept in all_meaningful:
    # ì¹´í…Œê³ ë¦¬ ê²°ì •
    category = None
    for cat_name, cat_concepts in categories.items():
        if concept in cat_concepts:
            category = cat_name
            break
    
    freq = concept_frequencies.get(concept, 0.5)
    
    metadata = {
        'category': category,
        'frequency': freq,
        'reorganized_at': time.time()
    }
    
    # ì••ì¶• í•„ìš”!
    meta_json = json.dumps(metadata).encode('utf-8')
    meta_blob = zlib.compress(meta_json)
    metadata_updates.append((concept, meta_blob))
    
    if len(metadata_updates) >= 1000:
        # ë°°ì¹˜ ì—…ë°ì´íŠ¸
        cursor.execute('BEGIN TRANSACTION')
        for concept_id, meta_blob in metadata_updates:
            cursor.execute('''
                UPDATE concepts 
                SET data = ?
                WHERE id = ?
            ''', (meta_blob, concept_id))
        cursor.execute('COMMIT')
        print(f'  {len(metadata_updates)}ê°œ ì—…ë°ì´íŠ¸ë¨')
        metadata_updates = []

# ë‚¨ì€ ê²ƒ ì²˜ë¦¬
if metadata_updates:
    cursor.execute('BEGIN TRANSACTION')
    for concept_id, meta_blob in metadata_updates:
        cursor.execute('''
            UPDATE concepts 
            SET data = ?
            WHERE id = ?
        ''', (meta_blob, concept_id))
    cursor.execute('COMMIT')
    print(f'  {len(metadata_updates)}ê°œ ì—…ë°ì´íŠ¸ë¨')

print('âœ… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ')

# ============================================================================
# ë‹¨ê³„ 5: í†µê³„ ë° ê²°ê³¼ ì €ì¥
# ============================================================================

print('\n[ë‹¨ê³„ 5] í†µê³„ ìƒì„± ì¤‘...')

statistics = {
    'reorganized_at': time.time(),
    'total_concepts': total_concepts,
    'meaningful_concepts': len(all_meaningful),
    'categories': {
        cat: len(concepts) for cat, concepts in categories.items()
    },
    'vocabulary_size': len(vocabulary),
    'frequency_distribution': dict(freq_bins),
    'top_foundational': sorted(
        [(c, f) for c, f in concept_frequencies.items() 
         if c in categories['foundational']],
        key=lambda x: x[1],
        reverse=True
    )[:50]
}

# JSON íŒŒì¼ë¡œ ì €ì¥
with open('concept_reorganization_stats.json', 'w', encoding='utf-8') as f:
    json.dump(statistics, f, indent=2, ensure_ascii=False)

print('âœ… í†µê³„ ì €ì¥: concept_reorganization_stats.json')

# ============================================================================
# ì™„ë£Œ
# ============================================================================

conn.close()

print('\n' + '=' * 70)
print('âœ… ì¬êµ¬ì¶• ì™„ë£Œ!')
print('=' * 70)

print(f'\nğŸ“Š ìš”ì•½:')
print(f'  ì´ ê°œë…: {total_concepts:,}')
print(f'  ì˜ë¯¸ ìˆëŠ” ê°œë…: {len(all_meaningful):,} ({len(all_meaningful)/total_concepts*100:.1f}%)')
print(f'  Vocabulary í¬ê¸°: {len(vocabulary):,}')
print(f'\n  ì¹´í…Œê³ ë¦¬ë³„:')
for cat, concepts in categories.items():
    print(f'    {cat:15s}: {len(concepts):,}ê°œ')

print(f'\nğŸŒŸ ìƒìœ„ ê°œë… (ì£¼íŒŒìˆ˜):')
for i, (concept, freq) in enumerate(statistics['top_foundational'][:15], 1):
    print(f'  {i:2d}. {concept:30s} {freq:.2f}')

print(f'\në‹¤ìŒ ë‹¨ê³„:')
print(f'  1. Hippocampus ì¬ì‹œì‘ â†’ Vocabulary ë¡œë“œë¨')
print(f'  2. ResonanceEngine â†’ ê°œë… ê³µëª… ê°€ëŠ¥')
print(f'  3. DialogueEngine â†’ í’ë¶€í•œ ì‘ë‹µ ìƒì„±')
print(f'\ní…ŒìŠ¤íŠ¸: python -c "from Core.Intelligence.Intelligence.dialogue_engine import DialogueEngine; d = DialogueEngine(); print(d.respond(\'ì‚¬ë‘ì´ ë­ë‹ˆ?\'))"')
