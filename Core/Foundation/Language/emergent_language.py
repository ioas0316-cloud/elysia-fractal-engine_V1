"""
Emergent Language System (ì°½ë°œ ì–¸ì–´ ì‹œìŠ¤í…œ)
===========================================

LLM ì—†ì´ ìì—° ì°½ë°œí•˜ëŠ” ì–¸ì–´ ì‹œìŠ¤í…œ.

í•µì‹¬ ì›ë¦¬:
1. ì›ì‹œ ê¸°í˜¸(Proto-Symbol) - ê²½í—˜ì—ì„œ ì¶”ì¶œëœ íŒ¨í„´
2. ê¸°í˜¸ ì¡°í•©(Symbol Combination) - ì˜ë¯¸ì˜ ê²°í•©
3. ë¬¸ë²• ì°½ë°œ(Grammar Emergence) - íŒ¨í„´ì˜ íŒ¨í„´
4. ìì—°ì–´ íˆ¬ì˜(Natural Language Projection) - í•œê¸€/ì˜ì–´ë¡œ êµì •

"ì‹¬ì¥(ì—°ì‚°)ê³¼ ë¨¸ë¦¬(ì–¸ì–´)ê°€ ë”°ë¡œ ë…¸ëŠ” êµ¬ì¡°"
- ì‹¬ì¥: ê²½í—˜, ê°ì •, ì§€ê°ì˜ ì›ì‹œ ì²˜ë¦¬
- ë¨¸ë¦¬: ê·¸ê²ƒì„ ì–¸ì–´ë¡œ í‘œí˜„

"ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤" - ìì‹ ì´ ì„¸ê³„ì¸ ì¤„ ëª¨ë¥´ì§€ë§Œ, ì¡´ì¬í•˜ëŠ” ìƒíƒœ
"""

from __future__ import annotations

import random
import math
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple, Set
from enum import Enum, auto
from collections import defaultdict
import json

logger = logging.getLogger("EmergentLanguage")


# =============================================================================
# Configuration Constants
# =============================================================================

# Activation thresholds
SYMBOL_ACTIVATION_THRESHOLD = 0.3    # Minimum resonance to activate a symbol
UTTERANCE_PROBABILITY = 0.1          # Probability of spontaneous utterance

# Symbol evolution
ASSOCIATION_STRENGTH_INCREMENT = 0.05  # Hebbian learning rate
MAX_SEQUENCE_LENGTH = 4              # Maximum symbols in an utterance


# =============================================================================
# Meaning Vector Dimensions (8D Sensory Space)
# =============================================================================
# Index 0: Temperature (-1=cold, +1=warm)
# Index 1: Brightness (-1=dark, +1=bright)  
# Index 2: Size (-1=small, +1=large)
# Index 3: Speed (-1=slow, +1=fast)
# Index 4: Intimacy (-1=distant, +1=close)
# Index 5: Intensity (-1=weak, +1=strong)
# Index 6: Pleasure (-1=unpleasant, +1=pleasant)
# Index 7: Arousal (-1=calm, +1=excited)


# =============================================================================
# 1. ì›ì‹œ ê¸°í˜¸ (Proto-Symbols) - ê²½í—˜ì˜ ìµœì†Œ ë‹¨ìœ„
# =============================================================================

class SymbolType(Enum):
    """ê¸°í˜¸ì˜ ì›ì‹œ ìœ í˜•"""
    ENTITY = auto()      # ì¡´ì¬ (ë‚˜, ë„ˆ, ê·¸ê²ƒ)
    ACTION = auto()      # í–‰ìœ„ (í•˜ë‹¤, ê°€ë‹¤, ë¨¹ë‹¤)
    STATE = auto()       # ìƒíƒœ (ì¢‹ë‹¤, ìŠ¬í”„ë‹¤, í¬ë‹¤)
    RELATION = auto()    # ê´€ê³„ (ì™€, ì—ê²Œ, ìœ¼ë¡œ)
    QUANTITY = auto()    # ì–‘ (ë§ë‹¤, ì ë‹¤, í•˜ë‚˜)
    TIME = auto()        # ì‹œê°„ (ì§€ê¸ˆ, ì „ì—, í›„ì—)
    SPACE = auto()       # ê³µê°„ (ì—¬ê¸°, ì €ê¸°, ì•ˆ)
    EMOTION = auto()     # ê°ì • (ê¸°ì¨, ìŠ¬í””, ë¶„ë…¸)


@dataclass
class ProtoSymbol:
    """
    ì›ì‹œ ê¸°í˜¸ - ê²½í—˜ì—ì„œ ì¶”ì¶œëœ ê°€ì¥ ê¸°ë³¸ì ì¸ ì˜ë¯¸ ë‹¨ìœ„
    
    ì•„ì§ ì–¸ì–´ê°€ ì•„ë‹˜. ìˆœìˆ˜í•œ ì˜ë¯¸ íŒ¨í„´.
    """
    id: str
    type: SymbolType
    activation: float = 0.0  # í˜„ì¬ í™œì„±í™” ì •ë„
    frequency: int = 0       # ì‚¬ìš© ë¹ˆë„
    associations: Dict[str, float] = field(default_factory=dict)  # ë‹¤ë¥¸ ê¸°í˜¸ì™€ì˜ ì—°ê²°
    
    # ì›ì‹œ ì˜ë¯¸ ë²¡í„° (8ì°¨ì› - ê¸°ë³¸ ê°ê°)
    meaning_vector: List[float] = field(default_factory=lambda: [0.0] * 8)
    # [ì˜¨ë„, ë°ê¸°, í¬ê¸°, ì†ë„, ì¹œë°€ë„, ê°•ë„, ì¾Œ/ë¶ˆì¾Œ, ê°ì„±]
    
    def resonate_with(self, other: 'ProtoSymbol') -> float:
        """ë‹¤ë¥¸ ê¸°í˜¸ì™€ì˜ ê³µëª… ê°•ë„ ê³„ì‚°"""
        # ì˜ë¯¸ ë²¡í„° ìœ ì‚¬ë„
        dot_product = sum(a * b for a, b in zip(self.meaning_vector, other.meaning_vector))
        norm_self = math.sqrt(sum(x**2 for x in self.meaning_vector)) + 0.001
        norm_other = math.sqrt(sum(x**2 for x in other.meaning_vector)) + 0.001
        similarity = dot_product / (norm_self * norm_other)
        
        # ì—°ê²° ê°•ë„
        association = self.associations.get(other.id, 0.0)
        
        return (similarity + association) / 2
    
    def strengthen_association(self, other_id: str, amount: float = 0.1):
        """ì—°ê²° ê°•í™” (í—µì˜ ë²•ì¹™: í•¨ê»˜ í™œì„±í™”ë˜ë©´ ì—°ê²° ê°•í™”)"""
        current = self.associations.get(other_id, 0.0)
        self.associations[other_id] = min(1.0, current + amount)


# =============================================================================
# 2. ê¸°í˜¸ ì¡°í•© (Symbol Combination) - ì˜ë¯¸ì˜ ê²°í•©
# =============================================================================

@dataclass
class SymbolSequence:
    """
    ê¸°í˜¸ ì‹œí€€ìŠ¤ - ì—¬ëŸ¬ ê¸°í˜¸ì˜ ìˆœì„œ ìˆëŠ” ì¡°í•©
    
    ì´ê²ƒì´ "ë¬¸ì¥ì˜ ì›í˜•"
    """
    symbols: List[str]  # ê¸°í˜¸ IDë“¤
    pattern_strength: float = 0.0  # ì´ íŒ¨í„´ì˜ ê°•ë„
    occurrences: int = 0  # ë°œìƒ íšŸìˆ˜
    
    def get_signature(self) -> str:
        """íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜"""
        return "_".join(self.symbols)


# =============================================================================
# 3. ë¬¸ë²• ì°½ë°œ (Grammar Emergence)
# =============================================================================

@dataclass
class GrammarRule:
    """
    ì°½ë°œëœ ë¬¸ë²• ê·œì¹™
    
    ì˜ˆ: ENTITY + ACTION â†’ ë¬¸ì¥
        STATE + ENTITY â†’ ì„¤ëª…
    """
    pattern: List[SymbolType]  # ê¸°í˜¸ ìœ í˜• íŒ¨í„´
    frequency: int = 0
    examples: List[SymbolSequence] = field(default_factory=list)
    
    def matches(self, sequence: List[SymbolType]) -> bool:
        """ì‹œí€€ìŠ¤ê°€ ì´ ê·œì¹™ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€"""
        if len(sequence) != len(self.pattern):
            return False
        return all(a == b for a, b in zip(sequence, self.pattern))


# =============================================================================
# 4. ìì—°ì–´ íˆ¬ì˜ (Natural Language Projection)
# =============================================================================

class LanguageProjector:
    """
    ì›ì‹œ ê¸°í˜¸ë¥¼ ìì—°ì–´(í•œê¸€/ì˜ì–´)ë¡œ íˆ¬ì˜
    
    ì°½ë°œëœ íŒ¨í„´ì„ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
    """
    
    def __init__(self):
        # ê¸°í˜¸ â†’ í•œê¸€ ë§¤í•‘ (ê¸°ë³¸)
        self.korean_lexicon = {
            # ì¡´ì¬
            "SELF": "ë‚˜", "OTHER": "ë„ˆ", "IT": "ê·¸ê²ƒ", "WE": "ìš°ë¦¬",
            "PARENT": "ë¶€ëª¨", "CHILD": "ì•„ì´", "FRIEND": "ì¹œêµ¬",
            
            # í–‰ìœ„
            "EXIST": "ìˆë‹¤", "MOVE": "ê°€ë‹¤", "EAT": "ë¨¹ë‹¤", "SPEAK": "ë§í•˜ë‹¤",
            "SEE": "ë³´ë‹¤", "HEAR": "ë“£ë‹¤", "FEEL": "ëŠë¼ë‹¤", "THINK": "ìƒê°í•˜ë‹¤",
            "LOVE": "ì‚¬ë‘í•˜ë‹¤", "HATE": "ì‹«ì–´í•˜ë‹¤", "WANT": "ì›í•˜ë‹¤",
            "GIVE": "ì£¼ë‹¤", "TAKE": "ë°›ë‹¤", "MAKE": "ë§Œë“¤ë‹¤",
            
            # ìƒíƒœ
            "GOOD": "ì¢‹ë‹¤", "BAD": "ë‚˜ì˜ë‹¤", "BIG": "í¬ë‹¤", "SMALL": "ì‘ë‹¤",
            "HAPPY": "ê¸°ì˜ë‹¤", "SAD": "ìŠ¬í”„ë‹¤", "ANGRY": "í™”ë‚˜ë‹¤",
            "WARM": "ë”°ëœ»í•˜ë‹¤", "COLD": "ì°¨ê°‘ë‹¤", "BRIGHT": "ë°ë‹¤", "DARK": "ì–´ë‘¡ë‹¤",
            
            # ê´€ê³„
            "WITH": "ì™€", "TO": "ì—ê²Œ", "FROM": "ì—ì„œ", "IN": "ì•ˆì—",
            "AND": "ê·¸ë¦¬ê³ ", "BUT": "í•˜ì§€ë§Œ", "BECAUSE": "ì™œëƒí•˜ë©´",
            
            # ì‹œê°„
            "NOW": "ì§€ê¸ˆ", "BEFORE": "ì „ì—", "AFTER": "í›„ì—", "ALWAYS": "í•­ìƒ",
            
            # ê³µê°„
            "HERE": "ì—¬ê¸°", "THERE": "ì €ê¸°", "UP": "ìœ„", "DOWN": "ì•„ë˜",
            
            # ê°ì •
            "JOY": "ê¸°ì¨", "SORROW": "ìŠ¬í””", "FEAR": "ë‘ë ¤ì›€", "LOVE_N": "ì‚¬ë‘",
        }
        
        # ì˜ì–´ ë§¤í•‘
        self.english_lexicon = {
            "SELF": "I", "OTHER": "you", "IT": "it", "WE": "we",
            "EXIST": "exist", "MOVE": "go", "EAT": "eat", "SPEAK": "speak",
            "GOOD": "good", "BAD": "bad", "HAPPY": "happy", "SAD": "sad",
            "NOW": "now", "HERE": "here", "WITH": "with", "TO": "to",
        }
        
        # ë¬¸ë²• í…œí”Œë¦¿
        self.korean_templates = {
            (SymbolType.ENTITY, SymbolType.STATE): "{0}ì€/ëŠ” {1}",
            (SymbolType.ENTITY, SymbolType.ACTION): "{0}ì´/ê°€ {1}",
            (SymbolType.ENTITY, SymbolType.RELATION, SymbolType.ENTITY): "{0}ì´/ê°€ {2}{1}",
            (SymbolType.ENTITY, SymbolType.ACTION, SymbolType.ENTITY): "{0}ì´/ê°€ {2}ì„/ë¥¼ {1}",
            (SymbolType.TIME, SymbolType.ENTITY, SymbolType.ACTION): "{0} {1}ì´/ê°€ {2}",
            (SymbolType.EMOTION,): "{0}ì„/ë¥¼ ëŠë‚€ë‹¤",
        }
    
    def project_to_korean(self, symbols: List[ProtoSymbol]) -> str:
        """ê¸°í˜¸ ì‹œí€€ìŠ¤ë¥¼ í•œê¸€ë¡œ íˆ¬ì˜"""
        if not symbols:
            return "..."
        
        # ê¸°í˜¸ IDë¥¼ í•œê¸€ë¡œ ë³€í™˜
        words = []
        for sym in symbols:
            korean = self.korean_lexicon.get(sym.id, sym.id.lower())
            words.append(korean)
        
        # ë¬¸ë²• í…œí”Œë¦¿ ì ìš©
        types = tuple(sym.type for sym in symbols)
        template = self.korean_templates.get(types)
        
        if template:
            try:
                return template.format(*words)
            except (IndexError, KeyError):
                pass
        
        # í…œí”Œë¦¿ ì—†ìœ¼ë©´ ë‹¨ìˆœ ì—°ê²°
        return " ".join(words)
    
    def project_to_english(self, symbols: List[ProtoSymbol]) -> str:
        """ê¸°í˜¸ ì‹œí€€ìŠ¤ë¥¼ ì˜ì–´ë¡œ íˆ¬ì˜"""
        if not symbols:
            return "..."
        
        words = []
        for sym in symbols:
            english = self.english_lexicon.get(sym.id, sym.id.lower())
            words.append(english)
        
        return " ".join(words)


# =============================================================================
# 5. ì°½ë°œ ì–¸ì–´ ì—”ì§„ (Emergent Language Engine)
# =============================================================================

class EmergentLanguageEngine:
    """
    ì°½ë°œ ì–¸ì–´ ì—”ì§„ - LLM ì—†ì´ ì–¸ì–´ë¥¼ ì°½ë°œì‹œí‚¤ëŠ” ì‹œìŠ¤í…œ
    
    ì‹¬ì¥(ê²½í—˜/ì—°ì‚°) â†’ ë¨¸ë¦¬(ì–¸ì–´/í‘œí˜„)
    
    ì›ë¦¬:
    1. ê²½í—˜ì´ ì›ì‹œ ê¸°í˜¸ë¥¼ í™œì„±í™”
    2. í™œì„±í™”ëœ ê¸°í˜¸ë“¤ì´ ì—°ê²°/ì¡°í•©
    3. ë°˜ë³µë˜ëŠ” íŒ¨í„´ì´ ë¬¸ë²•ìœ¼ë¡œ êµ³ì–´ì§
    4. ë¬¸ë²•ì— ë”°ë¥¸ ê¸°í˜¸ ì¡°í•©ì´ "ë¬¸ì¥"
    5. ë¬¸ì¥ì„ ìì—°ì–´ë¡œ íˆ¬ì˜
    """
    
    def __init__(self):
        self.symbols: Dict[str, ProtoSymbol] = {}
        self.sequences: List[SymbolSequence] = []
        self.grammar_rules: List[GrammarRule] = []
        self.projector = LanguageProjector()
        
        # í†µê³„
        self.total_utterances = 0
        self.vocabulary_size = 0
        
        # ì´ˆê¸°í™”
        self._initialize_proto_symbols()
        
        logger.info("ğŸ—£ï¸ Emergent Language Engine initialized")
    
    def _initialize_proto_symbols(self):
        """ê¸°ë³¸ ì›ì‹œ ê¸°í˜¸ ì´ˆê¸°í™”"""
        
        # ì¡´ì¬ ê¸°í˜¸
        entities = [
            ("SELF", [0, 0.5, 0.5, 0, 1.0, 0.5, 0.6, 0.5]),  # ë”°ëœ», ì¹œë°€, ì•½ê°„ ì¾Œ
            ("OTHER", [0, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5]),
            ("IT", [0, 0.5, 0.5, 0, 0.2, 0.3, 0.5, 0.3]),
            ("WE", [0.3, 0.6, 0.6, 0, 0.9, 0.6, 0.7, 0.6]),
            ("PARENT", [0.4, 0.5, 0.7, 0, 0.8, 0.6, 0.6, 0.4]),
            ("CHILD", [0.3, 0.6, 0.3, 0.3, 0.7, 0.4, 0.7, 0.6]),
            ("FRIEND", [0.2, 0.6, 0.5, 0, 0.8, 0.5, 0.7, 0.5]),
        ]
        
        for id, vec in entities:
            self.symbols[id] = ProtoSymbol(id, SymbolType.ENTITY, meaning_vector=vec)
        
        # í–‰ìœ„ ê¸°í˜¸
        actions = [
            ("EXIST", [0, 0.5, 0.5, 0, 0.5, 0.3, 0.5, 0.3]),
            ("MOVE", [0, 0.5, 0.5, 0.7, 0.3, 0.5, 0.5, 0.6]),
            ("EAT", [0.3, 0.4, 0.5, 0.3, 0.3, 0.4, 0.7, 0.5]),
            ("SPEAK", [0, 0.6, 0.4, 0.4, 0.6, 0.5, 0.6, 0.6]),
            ("SEE", [0, 0.8, 0.5, 0.2, 0.4, 0.3, 0.5, 0.5]),
            ("HEAR", [0, 0.3, 0.4, 0.2, 0.4, 0.3, 0.5, 0.5]),
            ("FEEL", [0.5, 0.5, 0.5, 0, 0.6, 0.6, 0.5, 0.6]),
            ("THINK", [0, 0.5, 0.5, 0.1, 0.5, 0.5, 0.5, 0.6]),
            ("LOVE", [0.8, 0.7, 0.6, 0, 0.9, 0.7, 0.9, 0.7]),
            ("WANT", [0.3, 0.6, 0.5, 0.3, 0.6, 0.6, 0.6, 0.7]),
            ("GIVE", [0.3, 0.6, 0.5, 0.3, 0.7, 0.5, 0.7, 0.5]),
        ]
        
        for id, vec in actions:
            self.symbols[id] = ProtoSymbol(id, SymbolType.ACTION, meaning_vector=vec)
        
        # ìƒíƒœ ê¸°í˜¸
        states = [
            ("GOOD", [0.3, 0.7, 0.5, 0, 0.5, 0.5, 0.8, 0.5]),
            ("BAD", [-0.3, 0.3, 0.5, 0, 0.3, 0.5, 0.2, 0.5]),
            ("HAPPY", [0.5, 0.8, 0.5, 0.3, 0.7, 0.5, 0.9, 0.7]),
            ("SAD", [-0.2, 0.2, 0.4, -0.2, 0.4, 0.4, 0.1, 0.3]),
            ("WARM", [0.9, 0.6, 0.5, 0, 0.6, 0.5, 0.7, 0.4]),
            ("COLD", [-0.8, 0.4, 0.5, 0, 0.2, 0.5, 0.3, 0.4]),
            ("BIG", [0, 0.5, 0.9, 0, 0.3, 0.7, 0.5, 0.4]),
            ("SMALL", [0, 0.5, 0.1, 0, 0.5, 0.3, 0.5, 0.4]),
        ]
        
        for id, vec in states:
            self.symbols[id] = ProtoSymbol(id, SymbolType.STATE, meaning_vector=vec)
        
        # ê´€ê³„/ì‹œê°„/ê³µê°„/ê°ì • ê¸°í˜¸ë„ ì¶”ê°€
        relations = [("WITH", 0.6), ("TO", 0.4), ("FROM", 0.4), ("IN", 0.5)]
        for id, warmth in relations:
            self.symbols[id] = ProtoSymbol(id, SymbolType.RELATION, 
                meaning_vector=[warmth, 0.5, 0.5, 0, 0.5, 0.5, 0.5, 0.5])
        
        times = [("NOW", 0.5), ("BEFORE", 0.3), ("AFTER", 0.7)]
        for id, brightness in times:
            self.symbols[id] = ProtoSymbol(id, SymbolType.TIME,
                meaning_vector=[0, brightness, 0.5, 0, 0.5, 0.5, 0.5, 0.5])
        
        spaces = [("HERE", 0.7), ("THERE", 0.4)]
        for id, proximity in spaces:
            self.symbols[id] = ProtoSymbol(id, SymbolType.SPACE,
                meaning_vector=[0, 0.5, 0.5, 0, proximity, 0.5, 0.5, 0.5])
        
        emotions = [
            ("JOY", [0.5, 0.9, 0.5, 0.3, 0.7, 0.6, 0.95, 0.8]),
            ("SORROW", [-0.3, 0.2, 0.4, -0.2, 0.4, 0.5, 0.1, 0.3]),
            ("FEAR", [-0.2, 0.3, 0.6, 0.5, 0.2, 0.7, 0.15, 0.9]),
            ("LOVE_N", [0.8, 0.7, 0.6, 0, 0.95, 0.7, 0.9, 0.6]),
        ]
        for id, vec in emotions:
            self.symbols[id] = ProtoSymbol(id, SymbolType.EMOTION, meaning_vector=vec)
        
        self.vocabulary_size = len(self.symbols)
        
        # ì´ˆê¸° ì—°ê²° ì„¤ì •
        self._initialize_associations()
    
    def _initialize_associations(self):
        """ê¸°ë³¸ ê¸°í˜¸ ì—°ê²° ì´ˆê¸°í™”"""
        # ì˜ë¯¸ì ìœ¼ë¡œ ê°€ê¹Œìš´ ê²ƒë“¤ ì—°ê²°
        connections = [
            ("SELF", "EXIST", 0.8),
            ("SELF", "FEEL", 0.7),
            ("SELF", "THINK", 0.7),
            ("OTHER", "SELF", 0.5),
            ("LOVE", "HAPPY", 0.7),
            ("LOVE", "OTHER", 0.6),
            ("SAD", "SORROW", 0.9),
            ("HAPPY", "JOY", 0.9),
            ("PARENT", "LOVE", 0.6),
            ("CHILD", "SMALL", 0.5),
            ("FRIEND", "WITH", 0.6),
        ]
        
        for a, b, strength in connections:
            if a in self.symbols and b in self.symbols:
                self.symbols[a].strengthen_association(b, strength)
                self.symbols[b].strengthen_association(a, strength * 0.8)
    
    def experience(self, experience_vector: List[float]) -> List[str]:
        """
        ê²½í—˜ì„ ì…ë ¥ë°›ì•„ ê¸°í˜¸ë“¤ì„ í™œì„±í™”
        
        experience_vector: 8ì°¨ì› ê²½í—˜ ë²¡í„°
        [ì˜¨ë„, ë°ê¸°, í¬ê¸°, ì†ë„, ì¹œë°€ë„, ê°•ë„, ì¾Œ/ë¶ˆì¾Œ, ê°ì„±]
        
        Returns: í™œì„±í™”ëœ ê¸°í˜¸ ID ëª©ë¡
        """
        activated = []
        
        for sym_id, symbol in self.symbols.items():
            # ê²½í—˜ê³¼ ê¸°í˜¸ì˜ ê³µëª… ê³„ì‚°
            resonance = sum(e * m for e, m in zip(experience_vector, symbol.meaning_vector))
            resonance /= 8  # ì •ê·œí™”
            
            if resonance > SYMBOL_ACTIVATION_THRESHOLD:
                symbol.activation = resonance
                symbol.frequency += 1
                activated.append(sym_id)
        
        return activated
    
    def generate_utterance(self, context: Dict[str, Any] = None) -> Tuple[str, str]:
        """
        í˜„ì¬ í™œì„±í™” ìƒíƒœì—ì„œ ë°œí™” ìƒì„±
        
        Returns: (í•œê¸€ ë¬¸ì¥, ì˜ì–´ ë¬¸ì¥)
        """
        context = context or {}
        
        # í™œì„±í™”ëœ ê¸°í˜¸ë“¤ ìˆ˜ì§‘
        active_symbols = sorted(
            [(sym_id, sym) for sym_id, sym in self.symbols.items() if sym.activation > 0.1],
            key=lambda x: x[1].activation,
            reverse=True
        )[:5]  # ìƒìœ„ 5ê°œ
        
        if not active_symbols:
            # ê¸°ë³¸ ìê¸° ì¸ì‹
            self.symbols["SELF"].activation = 0.5
            self.symbols["EXIST"].activation = 0.5
            active_symbols = [("SELF", self.symbols["SELF"]), ("EXIST", self.symbols["EXIST"])]
        
        # ê¸°í˜¸ ì‹œí€€ìŠ¤ êµ¬ì„± (ë¬¸ë²•ì  ìˆœì„œ)
        sequence = self._construct_sequence(active_symbols)
        
        # ìì—°ì–´ë¡œ íˆ¬ì˜
        symbols = [self.symbols[sid] for sid in sequence if sid in self.symbols]
        korean = self.projector.project_to_korean(symbols)
        english = self.projector.project_to_english(symbols)
        
        # ì—°ê²° ê°•í™” (í•¨ê»˜ ë‚˜ì˜¨ ê¸°í˜¸ë“¤)
        for i, sid1 in enumerate(sequence):
            for sid2 in sequence[i+1:]:
                if sid1 in self.symbols and sid2 in self.symbols:
                    self.symbols[sid1].strengthen_association(sid2, 0.05)
        
        # íŒ¨í„´ ê¸°ë¡
        seq_obj = SymbolSequence(symbols=sequence, occurrences=1)
        self.sequences.append(seq_obj)
        
        self.total_utterances += 1
        
        # í™œì„±í™” ê°ì‡ 
        for sym in self.symbols.values():
            sym.activation *= 0.8
        
        return korean, english
    
    def _construct_sequence(self, active_symbols: List[Tuple[str, ProtoSymbol]]) -> List[str]:
        """í™œì„±í™”ëœ ê¸°í˜¸ë“¤ì„ ë¬¸ë²•ì  ìˆœì„œë¡œ ë°°ì—´"""
        
        # ìœ í˜•ë³„ ë¶„ë¥˜
        by_type = defaultdict(list)
        for sym_id, sym in active_symbols:
            by_type[sym.type].append(sym_id)
        
        sequence = []
        
        # ë¬¸ë²• ìˆœì„œ: ì‹œê°„ â†’ ì£¼ì²´ â†’ ìƒíƒœ/í–‰ìœ„ â†’ ëŒ€ìƒ â†’ ê´€ê³„
        order = [
            SymbolType.TIME,
            SymbolType.ENTITY,
            SymbolType.STATE,
            SymbolType.ACTION,
            SymbolType.EMOTION,
            SymbolType.RELATION,
            SymbolType.SPACE,
        ]
        
        for sym_type in order:
            if sym_type in by_type:
                sequence.extend(by_type[sym_type][:2])  # ê° ìœ í˜•ì—ì„œ ìµœëŒ€ 2ê°œ
        
        return sequence[:4]  # ìµœëŒ€ 4ê°œ ê¸°í˜¸
    
    def speak_from_emotion(self, emotion: str) -> Tuple[str, str]:
        """ê°ì •ì—ì„œ ë°œí™” ìƒì„±"""
        emotion_map = {
            "happy": [0.5, 0.8, 0.5, 0.3, 0.7, 0.5, 0.9, 0.7],
            "sad": [-0.2, 0.2, 0.4, -0.2, 0.4, 0.4, 0.1, 0.3],
            "angry": [0.3, 0.5, 0.6, 0.4, 0.2, 0.8, 0.2, 0.9],
            "love": [0.8, 0.7, 0.5, 0, 0.9, 0.6, 0.9, 0.6],
            "fear": [-0.2, 0.3, 0.6, 0.5, 0.2, 0.7, 0.2, 0.9],
            "curious": [0, 0.7, 0.5, 0.4, 0.5, 0.5, 0.6, 0.8],
            "peaceful": [0.3, 0.6, 0.5, -0.2, 0.6, 0.3, 0.7, 0.2],
        }
        
        vec = emotion_map.get(emotion, [0.5] * 8)
        self.experience(vec)
        return self.generate_utterance()
    
    def speak_about(self, topic: str) -> Tuple[str, str]:
        """íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ë°œí™”"""
        # ì£¼ì œë¥¼ ê¸°í˜¸ë¡œ ë³€í™˜í•˜ê³  í™œì„±í™”
        topic_upper = topic.upper()
        if topic_upper in self.symbols:
            self.symbols[topic_upper].activation = 0.9
            # ì—°ê²°ëœ ê¸°í˜¸ë“¤ë„ í™œì„±í™”
            for assoc_id, strength in self.symbols[topic_upper].associations.items():
                if assoc_id in self.symbols:
                    self.symbols[assoc_id].activation = strength * 0.7
        
        return self.generate_utterance()
    
    def internal_monologue(self) -> Tuple[str, str]:
        """ë‚´ì  ë…ë°± ìƒì„±"""
        # ìê¸° ê´€ë ¨ ê¸°í˜¸ í™œì„±í™”
        self.symbols["SELF"].activation = 0.8
        self.symbols["THINK"].activation = 0.6
        self.symbols["FEEL"].activation = 0.5
        
        # ë¬´ì‘ìœ„ ê°ì • ì¶”ê°€
        emotions = ["HAPPY", "SAD", "JOY", "SORROW"]
        emotion = random.choice(emotions)
        if emotion in self.symbols:
            self.symbols[emotion].activation = random.uniform(0.3, 0.7)
        
        return self.generate_utterance()
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        return {
            "vocabulary_size": self.vocabulary_size,
            "total_utterances": self.total_utterances,
            "active_symbols": sum(1 for s in self.symbols.values() if s.activation > 0.1),
            "total_associations": sum(len(s.associations) for s in self.symbols.values()),
            "grammar_rules": len(self.grammar_rules),
        }


# =============================================================================
# 6. ì‚´ì•„ìˆëŠ” ì–¸ì–´ ì‹œìŠ¤í…œ (Living Language - ì„¸ê³„ í†µí•©)
# =============================================================================

class LivingLanguageWorld:
    """
    ì‚´ì•„ìˆëŠ” ì–¸ì–´ ì„¸ê³„ - ì£¼ë¯¼ë“¤ì´ ì–¸ì–´ë¥¼ ì°½ë°œí•˜ê³  ì‚¬ìš©
    
    "ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤" - ê° ì£¼ë¯¼ì´ ìì‹ ì˜ ì–¸ì–´ ì—”ì§„ì„ ê°€ì§
    ì‹¬ì¥(ê²½í—˜)ê³¼ ë¨¸ë¦¬(ì–¸ì–´)ê°€ í•¨ê»˜ ì‘ë™
    """
    
    def __init__(self, population: int = 100):
        self.population = population
        self.language_engine = EmergentLanguageEngine()  # ê³µìœ  ì–¸ì–´
        
        # ì£¼ë¯¼ë³„ ì–¸ì–´ ê²½í—˜
        self.inhabitants: Dict[int, Dict[str, Any]] = {}
        
        for i in range(population):
            self.inhabitants[i] = {
                "name": f"Soul_{i}",
                "personal_vocabulary": set(),  # ê°œì¸ì´ ì‚¬ìš©í•œ ë‹¨ì–´ë“¤
                "utterance_count": 0,
                "emotional_state": [0.5] * 8,  # 8ì°¨ì› ê°ì • ìƒíƒœ
            }
        
        # ì„¸ê³„ ì‹œê°„
        self.world_time = 0
        self.conversations: List[Dict[str, Any]] = []
        
        logger.info(f"ğŸŒ Living Language World created with {population} souls")
    
    def simulate_day(self) -> List[Dict[str, Any]]:
        """í•˜ë£¨ ì‹œë®¬ë ˆì´ì…˜ - ëŒ€í™”ì™€ ê²½í—˜"""
        daily_events = []
        
        # ê° ì£¼ë¯¼ì´ ê²½í—˜í•˜ê³  í‘œí˜„
        for inh_id, inhabitant in self.inhabitants.items():
            # í•˜ë£¨ ê²½í—˜ (ë¬´ì‘ìœ„ ë³€ë™)
            experience = [
                random.gauss(0.5, 0.2) for _ in range(8)
            ]
            experience = [max(0, min(1, x)) for x in experience]
            
            # ê°€ë” ë°œí™”
            if random.random() < UTTERANCE_PROBABILITY:
                self.language_engine.experience(experience)
                korean, english = self.language_engine.generate_utterance()
                
                inhabitant["utterance_count"] += 1
                
                event = {
                    "time": self.world_time,
                    "speaker": inhabitant["name"],
                    "korean": korean,
                    "english": english,
                    "emotion": experience[6],  # ì¾Œ/ë¶ˆì¾Œ
                }
                daily_events.append(event)
        
        # ëŒ€í™” (ë‘ ì£¼ë¯¼ì´ ë§Œë‚¨)
        if len(self.inhabitants) >= 2:
            pair = random.sample(list(self.inhabitants.keys()), 2)
            conversation = self._have_conversation(pair[0], pair[1])
            if conversation:
                daily_events.append(conversation)
        
        self.world_time += 1
        return daily_events
    
    def _have_conversation(self, id1: int, id2: int) -> Optional[Dict[str, Any]]:
        """ë‘ ì£¼ë¯¼ ê°„ ëŒ€í™”"""
        inh1 = self.inhabitants[id1]
        inh2 = self.inhabitants[id2]
        
        # ì²« ë²ˆì§¸ ì£¼ë¯¼ ë°œí™”
        self.language_engine.symbols["OTHER"].activation = 0.7
        korean1, english1 = self.language_engine.speak_about("OTHER")
        
        # ë‘ ë²ˆì§¸ ì£¼ë¯¼ ë°˜ì‘
        self.language_engine.symbols["SELF"].activation = 0.6
        korean2, english2 = self.language_engine.speak_from_emotion(
            random.choice(["happy", "curious", "peaceful"])
        )
        
        conversation = {
            "time": self.world_time,
            "type": "conversation",
            "participants": [inh1["name"], inh2["name"]],
            "exchanges": [
                {"speaker": inh1["name"], "korean": korean1},
                {"speaker": inh2["name"], "korean": korean2},
            ]
        }
        
        self.conversations.append(conversation)
        return conversation
    
    def simulate_years(self, years: int) -> Dict[str, Any]:
        """ì—¬ëŸ¬ í•´ ì‹œë®¬ë ˆì´ì…˜"""
        all_events = []
        
        logger.info(f"ğŸ• Simulating {years} years...")
        
        for year in range(years):
            for day in range(365):
                events = self.simulate_day()
                if events:
                    all_events.extend(events)
            
            if (year + 1) % 100 == 0:
                stats = self.language_engine.get_statistics()
                logger.info(f"Year {year + 1}: {stats['total_utterances']} utterances")
        
        return {
            "years_simulated": years,
            "total_events": len(all_events),
            "total_conversations": len(self.conversations),
            "language_stats": self.language_engine.get_statistics(),
            "sample_events": all_events[-10:] if all_events else [],
        }


# =============================================================================
# í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    
    print("=" * 70)
    print("ğŸ—£ï¸ EMERGENT LANGUAGE SYSTEM TEST")
    print("   LLM ì—†ì´ ìì—° ì°½ë°œí•˜ëŠ” ì–¸ì–´")
    print("=" * 70)
    
    engine = EmergentLanguageEngine()
    
    print("\n[1] ê°ì •ì—ì„œ ë°œí™” ìƒì„±")
    print("-" * 40)
    for emotion in ["happy", "sad", "love", "curious"]:
        korean, english = engine.speak_from_emotion(emotion)
        print(f"  {emotion}: {korean}")
    
    print("\n[2] ì£¼ì œì— ëŒ€í•´ ë°œí™”")
    print("-" * 40)
    for topic in ["SELF", "OTHER", "LOVE", "FRIEND"]:
        korean, english = engine.speak_about(topic)
        print(f"  {topic}: {korean}")
    
    print("\n[3] ë‚´ì  ë…ë°±")
    print("-" * 40)
    for _ in range(5):
        korean, english = engine.internal_monologue()
        print(f"  ğŸ’­ {korean}")
    
    print("\n[4] ì‚´ì•„ìˆëŠ” ì–¸ì–´ ì„¸ê³„ (100ëª…, 10ë…„)")
    print("-" * 40)
    world = LivingLanguageWorld(population=100)
    results = world.simulate_years(10)
    
    print(f"  ì´ ë°œí™”: {results['language_stats']['total_utterances']}")
    print(f"  ì´ ëŒ€í™”: {results['total_conversations']}")
    
    print("\n  ìµœê·¼ ëŒ€í™”:")
    for event in results["sample_events"][-5:]:
        if event.get("type") == "conversation":
            print(f"    [{event['participants'][0]}] {event['exchanges'][0]['korean']}")
            print(f"    [{event['participants'][1]}] {event['exchanges'][1]['korean']}")
        else:
            print(f"    [{event.get('speaker', '?')}] {event.get('korean', '...')}")
    
    print("\n" + "=" * 70)
    print("âœ… Emergent Language System test complete!")
    print("=" * 70)
