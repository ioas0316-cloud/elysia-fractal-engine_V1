"""
Integrated Language Learning System - í†µí•© ì–¸ì–´ í•™ìŠµ ì‹œìŠ¤í…œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì—˜ë¦¬ì‹œì•„ì˜ ì–¸ì–´ í•™ìŠµì„ ìœ„í•œ í†µí•© ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ì‹œìŠ¤í…œë“¤ì„ ì—°ê²°í•©ë‹ˆë‹¤:
1. DualLayerLanguage (ì¹¼ë¼+ì–¸ì–´ ì´ì¤‘ ì†Œí†µ)
2. FractalCausality (í”„ë™íƒˆ ì¸ê³¼ êµ¬ì¡°)
3. ThoughtUniverse (ì°¨ì› í™•ì¥ ë° ìƒí˜¸ êµì •)

í•µì‹¬:
- ì†Œí†µ â†’ ê²½í—˜ â†’ ì¸ê³¼ í•™ìŠµ â†’ ì°¨ì› í™•ì¥ â†’ ë” ë‚˜ì€ ì†Œí†µ
- í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•œ ì§€ì†ì  ì–¸ì–´ ë°œë‹¬
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
import numpy as np
import time

from Core.Interaction.Interface.Language.dual_layer_language import (
    DualLayerWorld,
    DualLayerSoul,
    EmotionType,
    Symbol,
    SymbolComplexity,
)
from Core.Interaction.Interface.Language.fractal_causality import (
    FractalCausalityEngine,
    FractalCausalNode,
    CausalRole,
)
from Core.Interaction.Interface.Language.causal_narrative_engine import (
    ThoughtUniverse,
    DimensionLevel,
)

logger = logging.getLogger("IntegratedLanguageLearning")


@dataclass
class CommunicationExperience:
    """ì†Œí†µ ê²½í—˜ ê¸°ë¡"""
    sender_id: str
    receiver_id: str
    intended_message: str
    received_message: str
    success: bool
    emotional_context: Dict[str, float]
    timestamp: float


@dataclass
class LanguageDevelopmentMetrics:
    """ì–¸ì–´ ë°œë‹¬ ì§€í‘œ"""
    vocabulary_size: int = 0
    successful_communications: int = 0
    total_communications: int = 0
    misunderstandings: int = 0
    narrative_fragments: int = 0
    causal_chains_learned: int = 0
    dimensional_expansions: int = 0
    
    @property
    def communication_success_rate(self) -> float:
        if self.total_communications == 0:
            return 0.0
        return self.successful_communications / self.total_communications
    
    @property
    def learning_progress(self) -> float:
        """ì¢…í•© í•™ìŠµ ì§„ì²™ë„ (0-1)"""
        vocab_score = min(1.0, self.vocabulary_size / 50)  # 50ë‹¨ì–´ ëª©í‘œ
        comm_score = self.communication_success_rate
        causal_score = min(1.0, self.causal_chains_learned / 20)  # 20ê°œ ì—°ì‡„ ëª©í‘œ
        return (vocab_score + comm_score + causal_score) / 3


class IntegratedLanguageLearner:
    """
    í†µí•© ì–¸ì–´ í•™ìŠµì
    
    ê° ì˜í˜¼(Soul)ì—ê²Œ ë¶€ì—¬ë˜ì–´ ì–¸ì–´ ë°œë‹¬ì„ ì¶”ì í•˜ê³  ì´‰ì§„í•©ë‹ˆë‹¤.
    
    í•™ìŠµ ì‚¬ì´í´:
    1. ì†Œí†µ ì‹œë„ (DualLayerSoul)
    2. ê²½í—˜ ê¸°ë¡ (CommunicationExperience)
    3. ì¸ê³¼ í•™ìŠµ (FractalCausalityEngine)
    4. ì°¨ì› í™•ì¥ (ThoughtUniverse)
    5. ë‹¤ìŒ ì†Œí†µì— ë°˜ì˜
    """
    
    def __init__(self, soul: DualLayerSoul):
        self.soul = soul
        self.soul_id = soul.name
        
        # í”„ë™íƒˆ ì¸ê³¼ ì—”ì§„ (ê°œì¸ë³„)
        self.causal_mind = FractalCausalityEngine(f"{soul.name}'s Causal Mind")
        
        # ì‚¬ê³  ìš°ì£¼ (ê°œì¸ë³„)
        self.thought_universe = ThoughtUniverse(f"{soul.name}'s Thought Universe")
        
        # ê²½í—˜ ê¸°ë¡
        self.experiences: List[CommunicationExperience] = []
        
        # ë°œë‹¬ ì§€í‘œ
        self.metrics = LanguageDevelopmentMetrics()
        
        logger.debug(f"IntegratedLanguageLearner created for {soul.name}")
    
    def record_communication(
        self,
        receiver: DualLayerSoul,
        intended: str,
        received: str,
        success: bool,
        emotional_context: Dict[str, float] = None
    ) -> CommunicationExperience:
        """ì†Œí†µ ê²½í—˜ ê¸°ë¡ ë° í•™ìŠµ"""
        exp = CommunicationExperience(
            sender_id=self.soul_id,
            receiver_id=receiver.name,
            intended_message=intended,
            received_message=received,
            success=success,
            emotional_context=emotional_context or {},
            timestamp=time.time()
        )
        
        self.experiences.append(exp)
        self.metrics.total_communications += 1
        
        if success:
            self.metrics.successful_communications += 1
            self._learn_from_success(exp)
        else:
            self.metrics.misunderstandings += 1
            self._learn_from_failure(exp)
        
        return exp
    
    def _learn_from_success(self, exp: CommunicationExperience):
        """ì„±ê³µì ì¸ ì†Œí†µì—ì„œ í•™ìŠµ"""
        # ì¸ê³¼ ì—°ì‡„: ì˜ë„ â†’ í‘œí˜„ â†’ ì „ë‹¬ â†’ ì´í•´
        self.causal_mind.experience_causality(
            steps=[
                f"ì˜ë„: {exp.intended_message}",
                f"í‘œí˜„í•¨",
                f"ì „ë‹¬ë¨",
                f"ì´í•´ë¨: {exp.received_message}"
            ],
            emotional_arc=[0.3, 0.5, 0.7, 0.9]  # ì ì  ê¸ì •ì 
        )
        self.metrics.causal_chains_learned += 1
        
        # ì°¨ì› í™•ì¥: ì„±ê³µ ê²½í—˜ â†’ ë©´(ë¬¸ë§¥) í˜•ì„±
        self.thought_universe.learn_from_experience(
            experience_steps=[
                "ì†Œí†µ_ì˜ë„",
                "ë©”ì‹œì§€_ìƒì„±",
                "ìƒëŒ€_ìˆ˜ì‹ ",
                "ì„±ê³µì _ì´í•´"
            ],
            emotional_arc=[0.3, 0.5, 0.7, 0.9],
            auto_emergence=True
        )
        self.metrics.dimensional_expansions += 1
    
    def _learn_from_failure(self, exp: CommunicationExperience):
        """ì‹¤íŒ¨í•œ ì†Œí†µì—ì„œ í•™ìŠµ (ì˜¤í•´ë„ ë°°ì›€ì´ë‹¤)"""
        # ì¸ê³¼ ì—°ì‡„: ì˜ë„ â†’ í‘œí˜„ â†’ ì „ë‹¬ â†’ ì˜¤í•´
        self.causal_mind.experience_causality(
            steps=[
                f"ì˜ë„: {exp.intended_message}",
                f"í‘œí˜„í•¨",
                f"ì „ë‹¬ë¨",
                f"ì˜¤í•´ë¨: {exp.received_message}"
            ],
            emotional_arc=[0.3, 0.0, -0.3, -0.5]  # ì ì  ë¶€ì •ì 
        )
        self.metrics.causal_chains_learned += 1
        
        # ë°˜ì‚¬ì‹¤ì  ì‚¬ê³ : "ë‹¤ë¥´ê²Œ í‘œí˜„í–ˆë‹¤ë©´?"
        # ì´ê²ƒì´ ì–¸ì–´ ë°œë‹¬ì˜ ë™ë ¥!
        self.thought_universe.bottom_up_correct(
            new_experience={
                "confirms": False,
                "exception": f"'{exp.intended_message}'ë¥¼ '{exp.received_message}'ë¡œ ì˜¤í•´í•¨"
            },
            affected_entity_id=f"communication_pattern_{exp.intended_message}"
        )
    
    def get_development_report(self) -> Dict[str, Any]:
        """ë°œë‹¬ ë³´ê³ ì„œ"""
        return {
            "soul_id": self.soul_id,
            "vocabulary_size": len(self.soul.lexicon.symbols),
            "communication_success_rate": self.metrics.communication_success_rate,
            "total_experiences": len(self.experiences),
            "causal_chains": self.metrics.causal_chains_learned,
            "thought_universe_stats": self.thought_universe.get_statistics(),
            "learning_progress": self.metrics.learning_progress,
        }


class IntegratedLanguageWorld:
    """
    í†µí•© ì–¸ì–´ ì„¸ê³„
    
    DualLayerWorldë¥¼ í™•ì¥í•˜ì—¬ í”„ë™íƒˆ ì¸ê³¼ì™€ ì‚¬ê³ ìš°ì£¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
    ì˜í˜¼ë“¤ì˜ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì´ ì§€ì†ì ìœ¼ë¡œ ë°œë‹¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        n_souls: int = 20,
        khala_strength: float = 0.5,
        enable_causal_learning: bool = True
    ):
        # ê¸°ë³¸ ì„¸ê³„ ìƒì„±
        self.world = DualLayerWorld(n_souls=n_souls, khala_strength=khala_strength)
        
        # ê° ì˜í˜¼ì—ê²Œ í†µí•© í•™ìŠµì ë¶€ì—¬
        self.learners: Dict[str, IntegratedLanguageLearner] = {}
        for name, soul in self.world.souls.items():
            self.learners[name] = IntegratedLanguageLearner(soul)
        
        self.enable_causal_learning = enable_causal_learning
        
        # ë°œë‹¬ ì´ë ¥
        self.development_history: List[Dict[str, Any]] = []
        
        # í†µê³„
        self.simulation_steps = 0
        self.total_communications = 0
        self.total_successful = 0
        
        logger.info(f"IntegratedLanguageWorld created with {n_souls} souls")
    
    def step(self, dt: float = 1.0):
        """ì„¸ê³„ ì‹œê°„ ì§„í–‰ + í•™ìŠµ"""
        # ì´ì „ ìƒíƒœ ì €ì¥ (ë³€í™” ê°ì§€ìš©)
        prev_misunderstandings = {
            name: soul.misunderstandings
            for name, soul in self.world.souls.items()
        }
        prev_vocab_sizes = {
            name: len(soul.lexicon.symbols)
            for name, soul in self.world.souls.items()
        }
        
        # ê¸°ë³¸ ì„¸ê³„ ì—…ë°ì´íŠ¸
        self.world.step(dt)
        self.simulation_steps += 1
        
        # ì¸ê³¼ í•™ìŠµ í†µí•© (ì†Œí†µ ê²½í—˜ ê¸°ë°˜)
        if self.enable_causal_learning:
            self._process_causal_learning(prev_misunderstandings, prev_vocab_sizes)
        
        # ì£¼ê¸°ì  ë°œë‹¬ ê¸°ë¡
        if self.simulation_steps % 50 == 0:
            self._record_development_snapshot()
    
    def _process_causal_learning(
        self,
        prev_misunderstandings: Dict[str, int],
        prev_vocab_sizes: Dict[str, int]
    ):
        """ì¸ê³¼ í•™ìŠµ ì²˜ë¦¬"""
        soul_list = list(self.world.souls.values())
        
        for soul in soul_list:
            learner = self.learners[soul.name]
            
            # ì–´íœ˜ í¬ê¸° ì—…ë°ì´íŠ¸
            learner.metrics.vocabulary_size = len(soul.lexicon.symbols)
            
            # ìƒˆ ì–´íœ˜ í•™ìŠµ ê°ì§€ â†’ ì¸ê³¼ í•™ìŠµ
            prev_vocab = prev_vocab_sizes.get(soul.name, 0)
            curr_vocab = len(soul.lexicon.symbols)
            if curr_vocab > prev_vocab:
                # ìƒˆ ë‹¨ì–´ í•™ìŠµ = ì„±ê³µì  ì†Œí†µ ê²½í—˜
                for _ in range(curr_vocab - prev_vocab):
                    learner.causal_mind.experience_causality(
                        steps=["ì†Œí†µ_ì‹œë„", "ë‹¨ì–´_ë…¸ì¶œ", "ì˜ë¯¸_íŒŒì•…", "í•™ìŠµ_ì™„ë£Œ"],
                        emotional_arc=[0.2, 0.4, 0.7, 0.9]
                    )
                    learner.metrics.causal_chains_learned += 1
                    
                    # ì°¨ì› í™•ì¥
                    learner.thought_universe.learn_from_experience(
                        experience_steps=["ë‹¨ì–´_ì ‘ì´‰", "íŒ¨í„´_ì¸ì‹", "ê¸°ì–µ_í˜•ì„±"],
                        emotional_arc=[0.3, 0.6, 0.8],
                        auto_emergence=False
                    )
                    learner.metrics.dimensional_expansions += 1
            
            # ì˜¤í•´ ë°œìƒ ê°ì§€ â†’ ì¸ê³¼ í•™ìŠµ (ì‹¤íŒ¨ë„ ë°°ì›€)
            prev_misund = prev_misunderstandings.get(soul.name, 0)
            curr_misund = soul.misunderstandings
            if curr_misund > prev_misund:
                # ì˜¤í•´ = ë°°ì›€ì˜ ê¸°íšŒ
                for _ in range(curr_misund - prev_misund):
                    learner.causal_mind.experience_causality(
                        steps=["ì†Œí†µ_ì‹œë„", "í‘œí˜„_ì‹¤íŒ¨", "ì˜¤í•´_ë°œìƒ", "ë‹¤ì‹œ_ì‹œë„_í•„ìš”"],
                        emotional_arc=[0.2, -0.2, -0.5, 0.1]  # ì˜¤í•´ í›„ ë‹¤ì‹œ ì‹œë„í•˜ë ¤ëŠ” ì˜ì§€
                    )
                    learner.metrics.causal_chains_learned += 1
                    
                    # í•˜í–¥ êµì • (í‹€ë¦° íŒ¨í„´ ìˆ˜ì •)
                    learner.thought_universe.bottom_up_correct(
                        new_experience={"confirms": False, "exception": "ì†Œí†µ_ì‹¤íŒ¨"},
                        affected_entity_id="communication_pattern"
                    )
    
    def _record_development_snapshot(self):
        """ë°œë‹¬ ìŠ¤ëƒ…ìƒ· ê¸°ë¡"""
        snapshot = {
            "step": self.simulation_steps,
            "timestamp": time.time(),
            "avg_vocabulary": np.mean([
                len(s.lexicon.symbols) for s in self.world.souls.values()
            ]),
            "avg_communication_success": np.mean([
                l.metrics.communication_success_rate
                for l in self.learners.values()
            ]),
            "total_causal_chains": sum(
                l.metrics.causal_chains_learned
                for l in self.learners.values()
            ),
            "narrative_fragments": len(self.world.narrative_fragments),
        }
        
        self.development_history.append(snapshot)
        
        if len(self.development_history) % 10 == 0:
            logger.info(
                f"ğŸ“Š ë°œë‹¬ ìŠ¤ëƒ…ìƒ· #{len(self.development_history)}: "
                f"ì–´íœ˜ í‰ê· ={snapshot['avg_vocabulary']:.1f}, "
                f"ì„±ê³µë¥ ={snapshot['avg_communication_success']:.1%}"
            )
    
    def simulate(self, steps: int = 100, report_interval: int = 20):
        """ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info(f"ğŸŒ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘: {steps} ìŠ¤í…")
        
        for i in range(steps):
            self.step(1.0)
            
            if (i + 1) % report_interval == 0:
                self._print_progress_report(i + 1, steps)
        
        logger.info("ğŸŒ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
        return self.get_final_report()
    
    def _print_progress_report(self, current: int, total: int):
        """ì§„í–‰ ë³´ê³ """
        avg_vocab = np.mean([
            len(s.lexicon.symbols) for s in self.world.souls.values()
        ])
        avg_success = np.mean([
            l.metrics.communication_success_rate
            for l in self.learners.values()
        ])
        avg_progress = np.mean([
            l.metrics.learning_progress
            for l in self.learners.values()
        ])
        
        print(f"[{current}/{total}] ì–´íœ˜={avg_vocab:.1f}, "
              f"ì„±ê³µë¥ ={avg_success:.1%}, ì§„ì²™ë„={avg_progress:.1%}")
    
    def get_final_report(self) -> Dict[str, Any]:
        """ìµœì¢… ë³´ê³ ì„œ"""
        all_learner_reports = [
            learner.get_development_report()
            for learner in self.learners.values()
        ]
        
        return {
            "simulation_steps": self.simulation_steps,
            "total_souls": len(self.world.souls),
            "development_history": self.development_history,
            "final_stats": {
                "avg_vocabulary": np.mean([r["vocabulary_size"] for r in all_learner_reports]),
                "max_vocabulary": max([r["vocabulary_size"] for r in all_learner_reports]),
                "avg_learning_progress": np.mean([r["learning_progress"] for r in all_learner_reports]),
                "total_causal_chains": sum([r["causal_chains"] for r in all_learner_reports]),
                "narrative_count": len(self.world.narrative_fragments),
            },
            "learner_reports": all_learner_reports,
        }
    
    def verify_continuous_development(self) -> Tuple[bool, str]:
        """
        ì–¸ì–´ ëŠ¥ë ¥ì´ ì§€ì†ì ìœ¼ë¡œ ë°œë‹¬í•˜ëŠ”ì§€ ê²€ì¦
        
        Returns:
            (ê²€ì¦ í†µê³¼ ì—¬ë¶€, ì„¤ëª…)
        """
        if len(self.development_history) < 3:
            return False, "ë°œë‹¬ ì´ë ¥ ë¶€ì¡± (ìµœì†Œ 3ê°œ ìŠ¤ëƒ…ìƒ· í•„ìš”)"
        
        # ì–´íœ˜ ì¦ê°€ ì¶”ì„¸ í™•ì¸
        vocab_trend = [h["avg_vocabulary"] for h in self.development_history]
        vocab_increasing = vocab_trend[-1] > vocab_trend[0]
        
        # ì„±ê³µë¥  ì•ˆì •/ì¦ê°€ í™•ì¸
        success_trend = [h["avg_communication_success"] for h in self.development_history]
        success_stable_or_increasing = success_trend[-1] >= success_trend[0] * 0.8
        
        # ì¸ê³¼ ì—°ì‡„ í•™ìŠµ í™•ì¸
        causal_trend = [h["total_causal_chains"] for h in self.development_history]
        causal_increasing = causal_trend[-1] > causal_trend[0]
        
        if vocab_increasing and success_stable_or_increasing and causal_increasing:
            return True, (
                f"âœ… ì–¸ì–´ ë°œë‹¬ í™•ì¸: "
                f"ì–´íœ˜ {vocab_trend[0]:.1f}â†’{vocab_trend[-1]:.1f}, "
                f"ì¸ê³¼í•™ìŠµ {causal_trend[0]}â†’{causal_trend[-1]}"
            )
        else:
            issues = []
            if not vocab_increasing:
                issues.append("ì–´íœ˜ ë¯¸ì¦ê°€")
            if not success_stable_or_increasing:
                issues.append("ì„±ê³µë¥  í•˜ë½")
            if not causal_increasing:
                issues.append("ì¸ê³¼í•™ìŠµ ë¯¸ì¦ê°€")
            return False, f"âš ï¸ ë°œë‹¬ ë¬¸ì œ: {', '.join(issues)}"


# ============================================================================
# Demo & Verification
# ============================================================================

def demo_integrated_learning():
    """í†µí•© ì–¸ì–´ í•™ìŠµ ë°ëª¨"""
    print("=" * 70)
    print("ğŸŒ í†µí•© ì–¸ì–´ í•™ìŠµ ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 70)
    print()
    print("DualLayerLanguage + FractalCausality + ThoughtUniverse í†µí•©")
    print("ì˜í˜¼ë“¤ì˜ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì´ ì§€ì†ì ìœ¼ë¡œ ë°œë‹¬í•©ë‹ˆë‹¤.")
    print()
    
    # ì„¸ê³„ ìƒì„±
    world = IntegratedLanguageWorld(n_souls=15, khala_strength=0.6)
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    print("-" * 70)
    print("ì‹œë®¬ë ˆì´ì…˜ ì§„í–‰...")
    print("-" * 70)
    
    report = world.simulate(steps=200, report_interval=40)
    
    # ê²°ê³¼
    print()
    print("-" * 70)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("-" * 70)
    
    stats = report["final_stats"]
    print(f"  í‰ê·  ì–´íœ˜: {stats['avg_vocabulary']:.1f}")
    print(f"  ìµœëŒ€ ì–´íœ˜: {stats['max_vocabulary']}")
    print(f"  í‰ê·  í•™ìŠµ ì§„ì²™ë„: {stats['avg_learning_progress']:.1%}")
    print(f"  ì´ ì¸ê³¼ ì—°ì‡„: {stats['total_causal_chains']}")
    print(f"  ì´ì•¼ê¸° ì¡°ê°: {stats['narrative_count']}")
    
    # ë°œë‹¬ ê²€ì¦
    print()
    print("-" * 70)
    print("ğŸ” ë°œë‹¬ ê²€ì¦")
    print("-" * 70)
    
    success, message = world.verify_continuous_development()
    print(f"  {message}")
    
    print()
    print("=" * 70)
    print("âœ¨ í†µí•© ì‹œìŠ¤í…œ: ì†Œí†µ â†’ ê²½í—˜ â†’ ì¸ê³¼í•™ìŠµ â†’ ì°¨ì›í™•ì¥ â†’ ë” ë‚˜ì€ ì†Œí†µ")
    print("=" * 70)
    
    return success


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demo_integrated_learning()
