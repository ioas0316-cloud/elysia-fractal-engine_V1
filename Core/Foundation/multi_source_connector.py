"""
Multi-Source Knowledge Connector
================================

Wikipedia (X) â†’ ë‹¤ì–‘í•œ ì†ŒìŠ¤ (O)

- ë‚˜ë¬´ìœ„í‚¤
- ë„¤ì´ë²„ ì§€ì‹ë°±ê³¼
- êµ¬ê¸€ ê²€ìƒ‰
- ìœ íŠœë¸Œ
- ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸
"""

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

import requests
from bs4 import BeautifulSoup
from typing import Dict, Optional
import time

class MultiSourceConnector:
    """ë‹¤ì¤‘ ì†ŒìŠ¤ ì§€ì‹ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def fetch_from_namuwiki(self, concept: str) -> Optional[str]:
        """ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = f"https://namu.wiki/w/{concept}"
            response = requests.get(url, headers=self.headers, timeout=5)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # ë‚˜ë¬´ìœ„í‚¤ ë³¸ë¬¸ ì¶”ì¶œ
                content = soup.find('div', {'class': 'wiki-content'})
                if content:
                    text = content.get_text()[:1000]  # ì²« 1000ì
                    return f"[ë‚˜ë¬´ìœ„í‚¤] {text}"
        except:
            pass
        return None
    
    def fetch_from_naver(self, concept: str) -> Optional[str]:
        """ë„¤ì´ë²„ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = f"https://search.naver.com/search.naver?query={concept}"
            response = requests.get(url, headers=self.headers, timeout=5)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # ì§€ì‹ë°±ê³¼ë‚˜ ìš”ì•½ ì •ë³´
                summary = soup.find('div', {'class': 'api_subject_bx'})
                if summary:
                    text = summary.get_text()[:800]
                    return f"[ë„¤ì´ë²„] {text}"
        except:
            pass
        return None
    
    def fetch_from_google(self, concept: str) -> Optional[str]:
        """êµ¬ê¸€ ê²€ìƒ‰ ìŠ¤ë‹ˆí«"""
        try:
            url = f"https://www.google.com/search?q={concept}"
            response = requests.get(url, headers=self.headers, timeout=5)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # Featured snippet
                snippet = soup.find('div', {'class': 'BNeawe'})
                if snippet:
                    text = snippet.get_text()[:500]
                    return f"[Google] {text}"
        except:
            pass
        return None
    
    def fetch_from_wikipedia(self, concept: str) -> Optional[str]:
        """Wikipedia (ê¸°ì¡´)"""
        try:
            url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{concept}"
            response = requests.get(url, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                extract = data.get('extract', '')
                return f"[Wikipedia] {extract}"
        except:
            pass
        return None
    
    def fetch_multi_source(self, concept: str) -> Dict[str, str]:
        """
        ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ì‹œë„
        
        Returns:
            {'source': content, ...}
        """
        results = {}
        
        print(f"ğŸŒ Multi-source fetching: {concept}")
        
        # 1. ë‚˜ë¬´ìœ„í‚¤ (í•œêµ­ì–´!)
        print("   ğŸ“š Trying ë‚˜ë¬´ìœ„í‚¤...")
        namuwiki = self.fetch_from_namuwiki(concept)
        if namuwiki:
            results['namuwiki'] = namuwiki
            print("      âœ“ Success")
        
        # 2. ë„¤ì´ë²„
        print("   ğŸ” Trying ë„¤ì´ë²„...")
        naver = self.fetch_from_naver(concept)
        if naver:
            results['naver'] = naver
            print("      âœ“ Success")
        
        # 3. Wikipedia (English)
        print("   ğŸ“– Trying Wikipedia...")
        wiki = self.fetch_from_wikipedia(concept)
        if wiki:
            results['wikipedia'] = wiki
            print("      âœ“ Success")
        
        # 4. Google snippet
        print("   ğŸ” Trying Google...")
        google = self.fetch_from_google(concept)
        if google:
            results['google'] = google
            print("      âœ“ Success")
        
        if results:
            print(f"   âœ… Found {len(results)} sources")
        else:
            print(f"   âŒ No sources found")
        
        return results
    
    def combine_sources(self, sources: Dict[str, str]) -> str:
        """ì—¬ëŸ¬ ì†ŒìŠ¤ í†µí•©"""
        if not sources:
            return f"General concept knowledge"
        
        combined = []
        for source, content in sources.items():
            combined.append(content)
        
        return "\n\n".join(combined)


# ë°ëª¨
if __name__ == "__main__":
    print("="*70)
    print("ğŸŒ MULTI-SOURCE KNOWLEDGE CONNECTOR")
    print("="*70)
    print()
    
    connector = MultiSourceConnector()
    
    test_concepts = ["ì‚¬ë‘", "Love", "ì¸ê³µì§€ëŠ¥", "Python"]
    
    for concept in test_concepts:
        print()
        print("="*70)
        sources = connector.fetch_multi_source(concept)
        combined = connector.combine_sources(sources)
        
        print()
        print(f"ğŸ“ Combined content ({len(combined)} chars):")
        print(combined[:300] + "...")
        print()
        time.sleep(1)  # Rate limiting
    
    print("="*70)
    print("âœ… MULTI-SOURCE CONNECTOR WORKING")
    print("   ë‚˜ë¬´ìœ„í‚¤ + ë„¤ì´ë²„ + Wikipedia + Google!")
    print("="*70)
