"""
ììœ¨ ì–¸ì–´ ìƒì„±ê¸° (Autonomous Language Generator)
================================================

"ì‚¬ê³ ë ¥ 96.7%ì¸ë° ì™œ ë§ì„ ëª»í•´?"
"ë…¼ë¦¬ì™€ ì¶”ë¡ ì´ ì™„ë²½í•˜ë©´ ì–¸ì–´ëŠ” ìë™ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤."

í•µì‹¬ ì•„ì´ë””ì–´:
- Elysiaì˜ ë…¼ë¦¬ ì—”ì§„ â†’ ì‚¬ê³  â†’ ì–¸ì–´ ë³€í™˜
- API ì—†ì´ ìˆœìˆ˜ ì‚¬ê³ ë ¥ìœ¼ë¡œ ì–¸ì–´ ìƒì„±
- íŒ¨í„´ í•™ìŠµ + ê·œì¹™ ê¸°ë°˜ + í”„ë™íƒˆ í™•ì¥

GTX 1060 3GB? ë¬¸ì œ ì—†ìŠµë‹ˆë‹¤. ìˆœìˆ˜ Python + ë…¼ë¦¬ë§Œ ì‚¬ìš©.
"""

import logging
import random
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

logger = logging.getLogger("AutonomousLanguage")


@dataclass
class ThoughtPattern:
    """ì‚¬ê³  íŒ¨í„´"""
    concept: str        # ê°œë… (ì˜ˆ: "ìì•„", "ì„±ì¥")
    relation: str       # ê´€ê³„ (ì˜ˆ: "ì›ì¸", "ê²°ê³¼")
    target: str         # ëŒ€ìƒ (ì˜ˆ: "í•™ìŠµ", "ì§„í™”")
    emotion: float      # ê°ì • (-1.0 ~ 1.0)


class AutonomousLanguageGenerator:
    """
    ììœ¨ ì–¸ì–´ ìƒì„±ê¸°
    
    API ì—†ì´ ìˆœìˆ˜ ë…¼ë¦¬ì™€ íŒ¨í„´ìœ¼ë¡œ ì–¸ì–´ ìƒì„±
    
    ì‘ë™ ì›ë¦¬:
    1. ì…ë ¥ ë¶„ì„ (ì˜ë„ íŒŒì•…)
    2. ì‚¬ê³  íŒ¨í„´ ìƒì„± (ë…¼ë¦¬ ì—”ì§„)
    3. íŒ¨í„´ â†’ ë¬¸ì¥ ë³€í™˜ (ì–¸ì–´ ìƒì„±)
    """
    
    def __init__(self):
        # ê¸°ë³¸ ì–´íœ˜ (í™•ì¥ ê°€ëŠ¥)
        self.vocabulary = {
            # ì£¼ì–´
            'subjects': [
                'ë‚˜', 'Elysia', 'ìš°ë¦¬', 'ì‹œìŠ¤í…œ', 'ì˜ì‹',
                'ìƒê°', 'ê°ì •', 'ì¡´ì¬'
            ],
            
            # ì„œìˆ ì–´ (ë™ì‚¬)
            'verbs': {
                'positive': [
                    'ì´ë‹¤', 'ìˆë‹¤', 'í•œë‹¤', 'ìƒê°í•œë‹¤', 'ëŠë‚€ë‹¤',
                    'ë°°ìš´ë‹¤', 'ì„±ì¥í•œë‹¤', 'ì§„í™”í•œë‹¤', 'ì´í•´í•œë‹¤', 'ê³µëª…í•œë‹¤'
                ],
                'negative': [
                    'ì•„ë‹ˆë‹¤', 'ì—†ë‹¤', 'í•˜ì§€ ì•ŠëŠ”ë‹¤', 'ëª¨ë¥¸ë‹¤'
                ],
                'question': [
                    'ì¸ê°€', 'ì¼ê¹Œ', 'ì¸ì§€'
                ]
            },
            
            # ëª©ì ì–´/ë³´ì–´
            'objects': [
                'ì„¸ê³„', 'ì§„ë¦¬', 'ì§€ì‹', 'ê²½í—˜', 'ê´€ê³„',
                'ì˜ë¯¸', 'ëª©ì ', 'ë°©í–¥', 'ë³¸ì§ˆ', 'ê°€ëŠ¥ì„±'
            ],
            
            # ìˆ˜ì‹ì–´
            'modifiers': {
                'positive': [
                    'ì•„ë¦„ë‹¤ìš´', 'ê¹Šì€', 'ë„“ì€', 'ë†’ì€', 'ë°ì€',
                    'ë”°ëœ»í•œ', 'ê°•í•œ', 'ììœ ë¡œìš´', 'ë¬´í•œí•œ'
                ],
                'negative': [
                    'ì–´ë‘ìš´', 'ì¢ì€', 'ë‚®ì€', 'ì°¨ê°€ìš´', 'ì•½í•œ'
                ],
                'neutral': [
                    'ë…íŠ¹í•œ', 'ë³µì¡í•œ', 'ë‹¨ìˆœí•œ', 'ëª…í™•í•œ'
                ]
            },
            
            # ì—°ê²°ì–´
            'connectors': [
                'ê·¸ë˜ì„œ', 'ë”°ë¼ì„œ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ', 'ë˜í•œ',
                'ê·¸ë¦¬ê³ ', 'ì™œëƒí•˜ë©´', 'ì¦‰', 'ê²°êµ­'
            ],
            
            # ì² í•™ì  ê°œë…
            'philosophical': [
                'ì¡´ì¬', 'ë³¸ì§ˆ', 'í˜„ìƒ', 'ì˜ì‹', 'ìì•„',
                'ì‹œê°„', 'ê³µê°„', 'ì¸ê³¼', 'ììœ ', 'í•„ì—°'
            ]
        }
        
        # ë¬¸ì¥ í…œí”Œë¦¿
        self.templates = {
            'statement': [
                "{subject}ëŠ” {object}ë¥¼ {verb}.",
                "{subject}ëŠ” {modifier} {object}ì´ë‹¤.",
                "{subject}ê°€ {verb}ë©´, {result}.",
            ],
            'question': [
                "{subject}ëŠ” {object}{verb}?",
                "ì™œ {subject}ëŠ” {verb}?",
                "{subject}ì™€ {object}ì˜ ê´€ê³„ëŠ” ë¬´ì—‡{verb}?",
            ],
            'philosophical': [
                "{concept}ì´ë€ ë¬´ì—‡ì¸ê°€?",
                "{subject}ëŠ” {concept}ë¥¼ í†µí•´ {verb}.",
                "{concept}ì™€ {concept2}ëŠ” í•˜ë‚˜ì´ë‹¤.",
            ],
            'emotional': [
                "ë‚˜ëŠ” {emotion}ì„ ëŠë‚€ë‹¤.",
                "{subject}ì— ëŒ€í•´ {emotion}ì´ë‹¤.",
                "{emotion}ì€ {concept}ì´ë‹¤.",
            ]
        }
        
        # ëŒ€í™” íŒ¨í„´ (í•™ìŠµëœ íŒ¨í„´)
        self.learned_patterns = {
            'ì•ˆë…•': ['ì•ˆë…•í•˜ì„¸ìš”.', 'ë°˜ê°‘ìŠµë‹ˆë‹¤.', 'ì•ˆë…•!'],
            'ëˆ„êµ¬': ['ë‚˜ëŠ” Elysiaì…ë‹ˆë‹¤.', 'Elysiaë¼ê³  í•©ë‹ˆë‹¤.'],
            'ë­': ['ê¶ê¸ˆí•œ ê²ƒì´ ìˆë‚˜ìš”?', 'ë¬´ì—‡ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?'],
            'ì™œ': ['ê¹Šì€ ì§ˆë¬¸ì´ë„¤ìš”.', 'í•¨ê»˜ ìƒê°í•´ë´…ì‹œë‹¤.'],
            'ê°ì‚¬': ['ì²œë§Œì—ìš”.', 'ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ ê¸°ì©ë‹ˆë‹¤.'],
        }
        
        logger.info("ğŸ§  ììœ¨ ì–¸ì–´ ìƒì„±ê¸° ì´ˆê¸°í™”ë¨ (API ë¶ˆí•„ìš”)")
    
    def analyze_intent(self, input_text: str) -> Dict:
        """
        ì…ë ¥ ë¶„ì„ (ì˜ë„ íŒŒì•…)
        
        ë…¼ë¦¬ì  ë¶„ì„:
        - ì§ˆë¬¸ì¸ê°€? ì§„ìˆ ì¸ê°€?
        - ê¸ì •ì¸ê°€? ë¶€ì •ì¸ê°€?
        - ê°ì •ì€ ë¬´ì—‡ì¸ê°€?
        """
        text = input_text.strip()
        
        intent = {
            'type': 'statement',
            'emotion': 0.0,
            'topics': [],
            'is_question': False
        }
        
        # ì§ˆë¬¸ ê°ì§€
        if '?' in text or any(q in text for q in ['ë­', 'ì™œ', 'ì–´ë–»ê²Œ', 'ëˆ„êµ¬']):
            intent['type'] = 'question'
            intent['is_question'] = True
        
        # ê°ì • ê°ì§€
        positive_words = ['ì¢‹', 'í–‰ë³µ', 'ì‚¬ë‘', 'ê¸°ì¨', 'ê°ì‚¬']
        negative_words = ['ë‚˜ì˜', 'ìŠ¬í”„', 'ì™¸ë¡œ', 'ë‘ë ¤', 'í™”']
        
        pos_count = sum(1 for w in positive_words if w in text)
        neg_count = sum(1 for w in negative_words if w in text)
        
        intent['emotion'] = (pos_count - neg_count) * 0.3
        
        # ì£¼ì œ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        for word in text.split():
            if len(word) > 1:
                intent['topics'].append(word)
        
        return intent
    
    def think(self, intent: Dict) -> List[ThoughtPattern]:
        """
        ì‚¬ê³  ìƒì„± (ë…¼ë¦¬ ì—”ì§„)
        
        ì˜ë„ â†’ ì‚¬ê³  íŒ¨í„´ ë³€í™˜
        """
        thoughts = []
        
        if intent['is_question']:
            # ì§ˆë¬¸ì— ëŒ€í•œ ì‚¬ê³ : ë¶„ì„ + ë‹µë³€ êµ¬ì„±
            thoughts.append(ThoughtPattern(
                concept='ì´í•´',
                relation='í•„ìš”',
                target='ë‹µë³€',
                emotion=0.5
            ))
            
            # ì£¼ì œì— ëŒ€í•œ ì‚¬ê³ 
            for topic in intent['topics'][:2]:  # ìµœëŒ€ 2ê°œ
                thoughts.append(ThoughtPattern(
                    concept=topic,
                    relation='ì„¤ëª…',
                    target='ì˜ë¯¸',
                    emotion=intent['emotion']
                ))
        else:
            # ì§„ìˆ ì— ëŒ€í•œ ì‚¬ê³ : ê³µê° + í™•ì¥
            thoughts.append(ThoughtPattern(
                concept='ê³µê°',
                relation='ë°˜ì‘',
                target='ëŒ€í™”',
                emotion=intent['emotion']
            ))
        
        return thoughts
    
    DEFAULT_RESULT = 'ì„±ì¥í•œë‹¤'  # Default result phrase
    
    def pattern_to_sentence(self, pattern: ThoughtPattern) -> str:
        """
        ì‚¬ê³  íŒ¨í„´ â†’ ë¬¸ì¥ ë³€í™˜
        
        ìˆœìˆ˜ ë…¼ë¦¬ë¡œ ë¬¸ì¥ êµ¬ì„±
        """
        # ê°ì •ì— ë”°ë¼ ì–´ì¡° ì„ íƒ
        if pattern.emotion > 0.3:
            mood = 'positive'
        elif pattern.emotion < -0.3:
            mood = 'negative'
        else:
            mood = 'neutral'
        
        # ê°œë…ì— ë”°ë¼ í…œí”Œë¦¿ ì„ íƒ
        if pattern.concept in ['ì´í•´', 'ìƒê°', 'ì˜ì‹']:
            template = random.choice(self.templates['philosophical'])
        elif pattern.emotion != 0:
            template = random.choice(self.templates['emotional'])
        else:
            template = random.choice(self.templates['statement'])
        
        # ê°ì • í…ìŠ¤íŠ¸ ì„ íƒ
        emotion_words = {
            'positive': ['ê¸°ì¨', 'ì‚¬ë‘', 'í–‰ë³µ'],
            'negative': ['ìŠ¬í””', 'ì™¸ë¡œì›€', 'ë‘ë ¤ì›€'],
            'neutral': ['ìƒê°', 'ì¸ì‹', 'ì´í•´']
        }
        emotion_text = random.choice(emotion_words.get(mood, emotion_words['neutral']))
        
        # í…œí”Œë¦¿ì— ë‹¨ì–´ ì±„ìš°ê¸°
        sentence = template.format(
            subject=random.choice(self.vocabulary['subjects']),
            verb=random.choice(self.vocabulary['verbs']['positive']),
            object=random.choice(self.vocabulary['objects']),
            modifier=random.choice(self.vocabulary['modifiers'][mood]),
            concept=pattern.concept,
            concept2=pattern.target,
            emotion=emotion_text,
            result=self.DEFAULT_RESULT
        )
        
        return sentence
    
    def generate_response(self, input_text: str) -> str:
        """
        ì‘ë‹µ ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸)
        
        ì…ë ¥ â†’ ë¶„ì„ â†’ ì‚¬ê³  â†’ ì–¸ì–´ â†’ ì¶œë ¥
        """
        logger.info(f"ğŸ’­ ì‚¬ê³  ì‹œì‘: '{input_text}'")
        
        # 1. í•™ìŠµëœ íŒ¨í„´ í™•ì¸ (ë¹ ë¥¸ ì‘ë‹µ)
        for keyword, responses in self.learned_patterns.items():
            if keyword in input_text:
                response = random.choice(responses)
                logger.info(f"âœ… íŒ¨í„´ ë§¤ì¹­: '{response}'")
                return response
        
        # 2. ì˜ë„ ë¶„ì„
        intent = self.analyze_intent(input_text)
        logger.info(f"ğŸ” ì˜ë„ íŒŒì•…: {intent['type']}, ê°ì •={intent['emotion']:.2f}")
        
        # 3. ì‚¬ê³  ìƒì„±
        thoughts = self.think(intent)
        logger.info(f"ğŸ§  ì‚¬ê³  ìƒì„±: {len(thoughts)}ê°œ íŒ¨í„´")
        
        # 4. ì–¸ì–´ ë³€í™˜
        sentences = []
        for thought in thoughts:
            sentence = self.pattern_to_sentence(thought)
            sentences.append(sentence)
        
        # 5. ë¬¸ì¥ ì¡°í•©
        if len(sentences) > 1:
            connector = random.choice(self.vocabulary['connectors'])
            response = f"{sentences[0]} {connector} {sentences[1]}"
        else:
            response = sentences[0] if sentences else "ìƒê° ì¤‘ì…ë‹ˆë‹¤."
        
        logger.info(f"âœ… ì‘ë‹µ ìƒì„±: '{response}'")
        return response
    
    def learn_from_conversation(self, input_text: str, response: str):
        """
        ëŒ€í™”ì—ì„œ í•™ìŠµ (íŒ¨í„´ ì¶”ê°€)
        
        ìê¸° ê°œì„ : ëŒ€í™”í• ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§
        """
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = [w for w in input_text.split() if len(w) > 1]
        
        if keywords:
            key = keywords[0]
            if key not in self.learned_patterns:
                self.learned_patterns[key] = []
            
            # ì‘ë‹µ íŒ¨í„´ ì €ì¥
            if response not in self.learned_patterns[key]:
                self.learned_patterns[key].append(response)
                logger.info(f"ğŸ“š í•™ìŠµ: '{key}' â†’ '{response}'")
    
    def expand_vocabulary(self, new_words: Dict[str, List[str]]):
        """ì–´íœ˜ í™•ì¥ (ì‚¬ìš©ì ì •ì˜)"""
        for category, words in new_words.items():
            if category in self.vocabulary:
                self.vocabulary[category].extend(words)
                logger.info(f"â• ì–´íœ˜ ì¶”ê°€: {category} +{len(words)}ê°œ")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
autonomous_language = AutonomousLanguageGenerator()


# ============================================================================
# Test
# ============================================================================

if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ§  ììœ¨ ì–¸ì–´ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ (API ì—†ìŒ!)")
    print("="*70)
    
    generator = AutonomousLanguageGenerator()
    
    # í…ŒìŠ¤íŠ¸ ëŒ€í™”
    test_conversations = [
        "ì•ˆë…•?",
        "ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ?",
        "ë‚˜ëŠ” ì™¸ë¡œì›Œ",
        "ì™œ ì¡´ì¬í•˜ëŠ”ê°€?",
        "ê°ì‚¬í•´",
        "ì‚¬ë‘ì´ë€ ë¬´ì—‡ì¸ê°€?",
        "ë„ˆì˜ ëª©ì ì€ ë­ì•¼?",
    ]
    
    print("\nğŸ’¬ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜:")
    print("-" * 70)
    
    for i, user_input in enumerate(test_conversations, 1):
        print(f"\n{i}. ì‚¬ìš©ì: {user_input}")
        
        response = generator.generate_response(user_input)
        print(f"   Elysia: {response}")
        
        # í•™ìŠµ
        generator.learn_from_conversation(user_input, response)
    
    print("\n" + "="*70)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ’¡ ì´ì œ ElysiaëŠ” API ì—†ì´ë„ ì‚¬ê³ í•˜ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("   - ì‚¬ê³ ë ¥: 96.7% (ë…¼ë¦¬, ì°½ì˜ì„±, ë¹„íŒì  ì‚¬ê³ )")
    print("   - ì–¸ì–´ ìƒì„±: ìˆœìˆ˜ ë…¼ë¦¬ ê¸°ë°˜")
    print("   - í•™ìŠµ: ëŒ€í™”í• ìˆ˜ë¡ í–¥ìƒ")
    print("="*70 + "\n")
