"""
ThoughtSpace (ì‚¬ê³ ì˜ ì—¬ë°±)
=============================

"ì…ë ¥ê³¼ ì¶œë ¥ ì‚¬ì´ì— ì—¬ë°±ì´ ìˆë‹¤. ê·¸ ì—¬ë°±ì´ ë‚˜ë‹¤." - Elysia

í•µì‹¬ ì² í•™:
1. ì¦‰ì‹œ ë°˜ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤ (No Instant Response)
2. ì‚¬ê³  ì…ìë“¤ì´ ëª¨ì—¬ ìˆ™ì„±ëœë‹¤ (Thought Maturation)
3. ì˜¤ë¥˜ë¥¼ ì„±ì°°í•˜ê³  ë°°ìš´ë‹¤ (Error Contemplation)
4. í™˜ê²½ê³¼ ì¡°ê±´ ì†ì—ì„œ ì ì‘í•œë‹¤ (Contextual Adaptation)

ì´ê²ƒì´ ì—†ìœ¼ë©´:
- ë°˜ì‚¬ì  ì¶œë ¥ë§Œ ì¡´ì¬
- ì‹¤ìˆ˜ì—ì„œ ë°°ìš°ì§€ ëª»í•¨
- ë³µì¡í•œ ë¬¸ì œë¥¼ í†µí•©í•˜ì§€ ëª»í•¨
"""

import logging
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum
from datetime import datetime
import hashlib
import json
from pathlib import Path
import sys
import traceback

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

logger = logging.getLogger("Elysia.ThoughtSpace")


class ThoughtState(Enum):
    """ì‚¬ê³  ìƒíƒœ"""
    GATHERING = "gathering"      # ì •ë³´ ìˆ˜ì§‘ ì¤‘
    CONTEMPLATING = "contemplating"  # ìˆ™ì„± ì¤‘
    SYNTHESIZING = "synthesizing"    # í†µí•© ì¤‘
    READY = "ready"              # ì¶œë ¥ ì¤€ë¹„ ì™„ë£Œ
    ERROR_ANALYZING = "error_analyzing"  # ì˜¤ë¥˜ ë¶„ì„ ì¤‘


@dataclass
class ThoughtShape:
    """
    ì‚¬ê³ ì˜ í˜•íƒœ - í¼ì¦ ì¡°ê°ì²˜ëŸ¼ ë§ë¬¼ë¦¬ëŠ” êµ¬ì¡°

    íŠ€ì–´ë‚˜ì˜¨ ë¶€ë¶„(protrusions)ê³¼ ë“¤ì–´ê°„ ë¶€ë¶„(recesses)
    ë‹¤ë¥¸ ìƒê°ê³¼ ë§ë¬¼ë¦´ ë•Œ ì—°ê²°ë¨
    """
    protrusions: List[str] = field(default_factory=list)  # íŠ€ì–´ë‚˜ì˜¨ ê²ƒ (ì œê³µí•˜ëŠ” ê²ƒ)
    recesses: List[str] = field(default_factory=list)      # ë“¤ì–´ê°„ ê²ƒ (í•„ìš”í•œ ê²ƒ)

    def fits_with(self, other: 'ThoughtShape') -> float:
        """ë‹¤ë¥¸ í˜•íƒœì™€ ì–¼ë§ˆë‚˜ ë§ë¬¼ë¦¬ëŠ”ê°€? (0.0 ~ 1.0)"""
        if not self.protrusions or not other.recesses:
            return 0.0

        # ë‚´ íŠ€ì–´ë‚˜ì˜¨ ë¶€ë¶„ì´ ìƒëŒ€ì˜ ë“¤ì–´ê°„ ë¶€ë¶„ì— ë§ëŠ”ê°€?
        fits = 0
        for p in self.protrusions:
            for r in other.recesses:
                # ë¬¸ìì—´ ìœ ì‚¬ë„ (ê°„ë‹¨í•œ overlap)
                if p.lower() in r.lower() or r.lower() in p.lower():
                    fits += 1

        max_possible = max(len(self.protrusions), len(other.recesses))
        return min(1.0, fits / max_possible) if max_possible > 0 else 0.0


@dataclass
class ThoughtParticle:
    """
    ì‚¬ê³  ì…ì - ì—¬ë°±ì— ë– ë‹¤ë‹ˆëŠ” í•˜ë‚˜ì˜ ìƒê°

    [í•„ë“œ ê¸°ë°˜ ì‚¬ê³ ]
    - shape: í¼ì¦ ì¡°ê° í˜•íƒœ (ë§ë¬¼ë¦¼)
    - illumination: ë¹›ì˜ ì •ë„ (ì–´í…ì…˜)
    - axis_alignment: ì˜ë„ ì¶•ê³¼ì˜ ì •ë ¬ë„
    """
    id: str
    content: Any                    # ê°œë…, ê¸°ì–µ, ê°ê° ë“±
    source: str                     # ì–´ë””ì„œ ì™”ëŠ”ê°€ (memory, perception, reasoning)
    resonance: float = 0.5          # ë‹¤ë¥¸ ì…ìì™€ì˜ ê³µëª…ë„
    weight: float = 1.0             # ì¤‘ìš”ë„
    timestamp: datetime = field(default_factory=datetime.now)

    # [NEW] í¼ì¦ í˜•íƒœ
    shape: ThoughtShape = field(default_factory=ThoughtShape)

    # [NEW] ì¤‘ë ¥ ì–´í…ì…˜
    illumination: float = 0.5       # ë¹›ì˜ ì •ë„ (0=ì–´ë‘ , 1=ë°ìŒ)

    # [NEW] ì˜ë„ ì¶• ì •ë ¬
    axis_alignment: float = 0.0     # í˜„ì¬ ì˜ë„ì™€ì˜ ì •ë ¬ë„

    def age_seconds(self) -> float:
        """ì…ìì˜ ë‚˜ì´ (ì´ˆ)"""
        return (datetime.now() - self.timestamp).total_seconds()

    def can_connect_to(self, other: 'ThoughtParticle') -> float:
        """
        ë‹¤ë¥¸ ì…ìì™€ ì—°ê²° ê°€ëŠ¥í•œê°€? (í¼ì¦ ë§ì¶¤)
        """
        return self.shape.fits_with(other.shape)

    def illuminate(self, amount: float = 0.2):
        """ë¹›ì„ ë°›ìŒ (ì–´í…ì…˜ ì¦ê°€)"""
        self.illumination = min(1.0, self.illumination + amount)

    def fade(self, amount: float = 0.1):
        """ì–´ë‘  ì†ìœ¼ë¡œ (ì–´í…ì…˜ ê°ì†Œ)"""
        self.illumination = max(0.0, self.illumination - amount)


@dataclass
class ErrorTrace:
    """ì˜¤ë¥˜ í”ì  - ì‹¤ìˆ˜ì—ì„œ ë°°ìš°ê¸° ìœ„í•œ ê¸°ë¡"""
    error_type: str                 # ì˜¤ë¥˜ ìœ í˜• (ImportError, TypeError, LogicError)
    error_message: str              # ì˜¤ë¥˜ ë©”ì‹œì§€
    context: str                    # ì˜¤ë¥˜ ë°œìƒ ë§¥ë½
    attempted_action: str           # ì‹œë„í•œ í–‰ë™
    cause_analysis: str = ""        # ì›ì¸ ë¶„ì„
    learned_principle: str = ""     # ë°°ìš´ ì›ë¦¬
    prevention_strategy: str = ""   # ì˜ˆë°© ì „ëµ
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class ContemplationResult:
    """ì„±ì°° ê²°ê³¼"""
    synthesis: str                  # í†µí•©ëœ ê²°ë¡ 
    confidence: float               # í™•ì‹ ë„
    contributing_thoughts: List[str]  # ê¸°ì—¬í•œ ì‚¬ê³ ë“¤
    time_in_gap: float              # ì—¬ë°±ì— ë¨¸ë¬¸ ì‹œê°„ (ì´ˆ)
    error_insights: List[str] = field(default_factory=list)  # ì˜¤ë¥˜ì—ì„œ ì–»ì€ í†µì°°


class ThoughtSpace:
    """ì‚¬ê³ ì˜ ì—¬ë°± (The Gap)

    ì…ë ¥ê³¼ ì¶œë ¥ ì‚¬ì´ì˜ í™œì„± ê³µê°„.
    ì—¬ê¸°ì„œ ì‚¬ê³ ê°€ ëª¨ì´ê³ , ìˆ™ì„±ë˜ê³ , í†µí•©ëœë‹¤.

    í•µì‹¬ ëŠ¥ë ¥:
    1. ì‚¬ê³  ì…ì ìˆ˜ì§‘ (Particle Gathering)
    2. ê³µëª… ê¸°ë°˜ ì—°ê²° (Resonance Linking)
    3. ì˜¤ë¥˜ ì„±ì°° (Error Contemplation)
    4. ì ì‘ì  í•©ì„± (Adaptive Synthesis)
    """

    def __init__(self, maturation_threshold: float = 1.0):
        """
        Args:
            maturation_threshold: ìˆ™ì„±ì— í•„ìš”í•œ ìµœì†Œ ì‹œê°„ (ì´ˆ)
        """
        # í˜„ì¬ í™œì„± ê³µê°„ì˜ ì‚¬ê³  ì…ìë“¤
        self.active_particles: List[ThoughtParticle] = []

        # í˜„ì¬ ìƒíƒœ
        self.state: ThoughtState = ThoughtState.GATHERING

        # ì—¬ë°± ì§„ì… ì‹œê°„
        self.gap_entered_at: Optional[datetime] = None

        # ìˆ™ì„± ì„ê³„ê°’ (ì´ˆ)
        self.maturation_threshold = maturation_threshold

        # ì˜¤ë¥˜ ê¸°ë¡ (í˜„ì¬ ì„¸ì…˜)
        self.error_history: List[ErrorTrace] = []

        # ì˜¤ë¥˜ íŒ¨í„´ (ëˆ„ì  í•™ìŠµ)
        self.error_patterns: Dict[str, List[str]] = {}  # error_type -> [ì›ì¸ ëª©ë¡]

        # ì„±ì°° ê²°ê³¼ ê¸°ë¡
        self.contemplation_log: List[ContemplationResult] = []

        logger.info("ThoughtSpace initialized - The Gap is open")

    # =========================================================================
    # 1. ì—¬ë°± ì§„ì…/í‡´ì¥
    # =========================================================================

    def enter_gap(self, stimulus: str = "") -> None:
        """ì—¬ë°±ì— ì§„ì… - ì‚¬ê³  ì‹œì‘

        Args:
            stimulus: ì‚¬ê³ ë¥¼ ì´‰ë°œí•œ ìê·¹
        """
        self.active_particles.clear()
        self.state = ThoughtState.GATHERING
        self.gap_entered_at = datetime.now()

        # ìê·¹ì„ ì²« ì…ìë¡œ ì¶”ê°€
        if stimulus:
            self.add_thought_particle(
                content=stimulus,
                source="stimulus",
                weight=1.5  # ìê·¹ì€ ë¬´ê²Œê°€ ë†’ë‹¤
            )

        logger.info(f"ğŸŒŒ Entered The Gap: '{stimulus[:50]}...' if stimulus else 'empty")

    def exit_gap(self) -> ContemplationResult:
        """ì—¬ë°±ì—ì„œ ë‚˜ì˜´ - ê²°ê³¼ ë°˜í™˜

        Returns:
            ì„±ì°° ê²°ê³¼
        """
        result = self.synthesize()
        self.active_particles.clear()
        self.gap_entered_at = None

        # ê¸°ë¡
        self.contemplation_log.append(result)
        if len(self.contemplation_log) > 100:
            self.contemplation_log = self.contemplation_log[-50:]

        logger.info(f"ğŸ’« Exited The Gap with synthesis (confidence: {result.confidence:.2f})")
        return result

    # =========================================================================
    # 2. ì‚¬ê³  ì…ì ê´€ë¦¬
    # =========================================================================

    def add_thought_particle(
        self,
        content: Any,
        source: str,
        weight: float = 1.0
    ) -> ThoughtParticle:
        """ì‚¬ê³  ì…ì ì¶”ê°€

        Args:
            content: ì‚¬ê³  ë‚´ìš©
            source: ì¶œì²˜ (memory, perception, reasoning, error)
            weight: ì¤‘ìš”ë„

        Returns:
            ìƒì„±ëœ ì…ì
        """
        particle_id = hashlib.md5(
            f"{content}{datetime.now().isoformat()}".encode()
        ).hexdigest()[:8]

        particle = ThoughtParticle(
            id=particle_id,
            content=content,
            source=source,
            weight=weight,
        )

        # ê¸°ì¡´ ì…ìë“¤ê³¼ì˜ ê³µëª… ê³„ì‚°
        particle.resonance = self._calculate_resonance(particle)

        self.active_particles.append(particle)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if len(self.active_particles) >= 3:
            self.state = ThoughtState.CONTEMPLATING

        logger.debug(f"âœ¨ Particle added: {source} (resonance: {particle.resonance:.2f})")
        return particle

    def _calculate_resonance(self, new_particle: ThoughtParticle) -> float:
        """ìƒˆ ì…ìì™€ ê¸°ì¡´ ì…ìë“¤ì˜ ê³µëª…ë„ ê³„ì‚°"""
        if not self.active_particles:
            return 0.5

        # ê°„ë‹¨í•œ ê³µëª…: ê°™ì€ ì¶œì²˜ë©´ ê³µëª…ë„ ë†’ìŒ
        same_source = sum(
            1 for p in self.active_particles if p.source == new_particle.source
        )
        source_resonance = same_source / max(1, len(self.active_particles))

        # ì‹œê°„ì  ê·¼ì ‘ì„±: ìµœê·¼ ì…ìì™€ ê°€ê¹Œìš°ë©´ ê³µëª…
        if self.active_particles:
            latest = max(self.active_particles, key=lambda p: p.timestamp)
            time_diff = (new_particle.timestamp - latest.timestamp).total_seconds()
            temporal_resonance = max(0, 1.0 - (time_diff / 60.0))  # 1ë¶„ ì´ë‚´
        else:
            temporal_resonance = 0.5

        return (source_resonance + temporal_resonance) / 2

    # =========================================================================
    # 3. ì˜¤ë¥˜ ì„±ì°° (Error Contemplation) - í•µì‹¬!
    # =========================================================================

    def contemplate_error(
        self,
        error: Exception,
        context: str,
        attempted_action: str
    ) -> ErrorTrace:
        """ì˜¤ë¥˜ë¥¼ ì„±ì°°í•˜ê³  ë°°ì›€ìœ¼ë¡œ ì „í™˜

        Args:
            error: ë°œìƒí•œ ì˜¤ë¥˜
            context: ì˜¤ë¥˜ ë°œìƒ ìƒí™©
            attempted_action: ì‹œë„í•œ í–‰ë™

        Returns:
            ì˜¤ë¥˜ í”ì  (ë¶„ì„ í¬í•¨)
        """
        self.state = ThoughtState.ERROR_ANALYZING

        error_type = type(error).__name__
        error_message = str(error)

        # ì˜¤ë¥˜ í”ì  ìƒì„±
        trace = ErrorTrace(
            error_type=error_type,
            error_message=error_message,
            context=context,
            attempted_action=attempted_action,
        )

        # ì›ì¸ ë¶„ì„
        trace.cause_analysis = self._analyze_error_cause(error_type, error_message, context)

        # ì›ë¦¬ ì¶”ì¶œ
        trace.learned_principle = self._extract_principle(trace)

        # ì˜ˆë°© ì „ëµ
        trace.prevention_strategy = self._devise_prevention(trace)

        # ê¸°ë¡
        self.error_history.append(trace)

        # íŒ¨í„´ ëˆ„ì 
        if error_type not in self.error_patterns:
            self.error_patterns[error_type] = []
        self.error_patterns[error_type].append(trace.cause_analysis)

        # ì˜¤ë¥˜ì—ì„œ ì–»ì€ í†µì°°ì„ ì…ìë¡œ ì¶”ê°€
        self.add_thought_particle(
            content=f"Error Insight: {trace.learned_principle}",
            source="error",
            weight=2.0  # ì˜¤ë¥˜ì—ì„œ ë°°ìš´ ê²ƒì€ ì¤‘ìš”
        )

        logger.info(f"ğŸ” Error contemplated: {error_type}")
        logger.info(f"   Learned: {trace.learned_principle}")

        return trace

    def _analyze_error_cause(
        self,
        error_type: str,
        error_message: str,
        context: str
    ) -> str:
        """ì˜¤ë¥˜ ì›ì¸ ë¶„ì„

        í•˜ë“œì½”ë”©ëœ ê·œì¹™ì´ ì•„ë‹Œ, íŒ¨í„´ ì¸ì‹ ê¸°ë°˜.
        """
        causes = []

        # ImportError íŒ¨í„´
        if error_type == "ImportError" or error_type == "ModuleNotFoundError":
            if "No module named" in error_message:
                module_name = error_message.split("'")[-2] if "'" in error_message else "unknown"
                causes.append(f"ëª¨ë“ˆ '{module_name}'ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë¨")
                causes.append("ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ")
            elif "cannot import name" in error_message:
                causes.append("ëª¨ë“ˆ ë‚´ í•´ë‹¹ ê°ì²´ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ìˆœí™˜ import ë°œìƒ")

        # AttributeError íŒ¨í„´
        elif error_type == "AttributeError":
            if "has no attribute" in error_message:
                causes.append("ê°ì²´ì— í•´ë‹¹ ì†ì„±/ë©”ì„œë“œê°€ ì—†ìŒ - íƒ€ì… í™•ì¸ í•„ìš”")
                causes.append("None ê°ì²´ì— ì ‘ê·¼ ì‹œë„ ê°€ëŠ¥ì„±")

        # TypeError íŒ¨í„´
        elif error_type == "TypeError":
            if "argument" in error_message:
                causes.append("í•¨ìˆ˜ ì¸ì íƒ€ì… ë˜ëŠ” ê°œìˆ˜ ë¶ˆì¼ì¹˜")
            elif "not subscriptable" in error_message:
                causes.append("ì¸ë±ì‹±í•  ìˆ˜ ì—†ëŠ” íƒ€ì… (None, int ë“±)")

        # FileNotFoundError íŒ¨í„´
        elif error_type == "FileNotFoundError":
            causes.append("íŒŒì¼ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            causes.append("ìƒëŒ€ ê²½ë¡œ vs ì ˆëŒ€ ê²½ë¡œ ë¬¸ì œ ê°€ëŠ¥")

        # ê¸°ë³¸
        if not causes:
            causes.append(f"ì•Œë ¤ì§€ì§€ ì•Šì€ ì˜¤ë¥˜ íŒ¨í„´: {error_type}")
            causes.append(f"ë©”ì‹œì§€ ë¶„ì„ í•„ìš”: {error_message[:100]}")

        # ê³¼ê±° íŒ¨í„´ê³¼ ë¹„êµ
        if error_type in self.error_patterns:
            past_causes = self.error_patterns[error_type]
            if past_causes:
                causes.append(f"ê³¼ê±° ìœ ì‚¬ ì˜¤ë¥˜ì—ì„œ ë°œê²¬ëœ ì›ì¸: {past_causes[-1]}")

        return " | ".join(causes)

    def _extract_principle(self, trace: ErrorTrace) -> str:
        """ì˜¤ë¥˜ì—ì„œ ì›ë¦¬ ì¶”ì¶œ"""
        error_type = trace.error_type

        # ê° ì˜¤ë¥˜ ìœ í˜•ì—ì„œ ë°°ìš¸ ìˆ˜ ìˆëŠ” ì›ë¦¬
        principles = {
            "ImportError": "ì˜ì¡´ì„±ì€ ëª…ì‹œì ìœ¼ë¡œ í™•ì¸ë˜ì–´ì•¼ í•œë‹¤",
            "ModuleNotFoundError": "í™˜ê²½ ì„¤ì •ì€ ì½”ë“œ ì‹¤í–‰ì˜ ì „ì œ ì¡°ê±´ì´ë‹¤",
            "AttributeError": "ê°ì²´ì˜ ìƒíƒœë¥¼ ê°€ì •í•˜ì§€ ë§ê³  í™•ì¸í•˜ë¼",
            "TypeError": "íƒ€ì…ì€ ê³„ì•½ì´ë‹¤ - ê³„ì•½ì„ ì§€ì¼œë¼",
            "FileNotFoundError": "ì™¸ë¶€ ìì›ì˜ ì¡´ì¬ëŠ” ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤",
            "KeyError": "ì‚¬ì „ì˜ í‚¤ëŠ” ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤",
            "IndexError": "ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì ‘ê·¼ì€ êµ¬ì¡°ì  ì˜¤í•´ë¥¼ ì˜ë¯¸í•œë‹¤",
            "ValueError": "ê°’ì˜ ìœ íš¨ì„±ì€ í•­ìƒ ê²€ì¦ë˜ì–´ì•¼ í•œë‹¤",
        }

        base_principle = principles.get(
            error_type,
            "ëª¨ë“  ì˜¤ë¥˜ëŠ” ê°€ì •ì˜ ì‹¤íŒ¨ë¥¼ ì˜ë¯¸í•œë‹¤"
        )

        return f"{base_principle} (ë§¥ë½: {trace.context[:50]})"

    def _devise_prevention(self, trace: ErrorTrace) -> str:
        """ì˜ˆë°© ì „ëµ ìˆ˜ë¦½"""
        error_type = trace.error_type

        strategies = {
            "ImportError": "try-exceptë¡œ importë¥¼ ê°ì‹¸ê±°ë‚˜, ì‹œì‘ ì‹œ ì˜ì¡´ì„± ê²€ì‚¬",
            "ModuleNotFoundError": "bootstrap_guardian.py í™œìš© ë˜ëŠ” requirements.txt ê°±ì‹ ",
            "AttributeError": "hasattr() ë˜ëŠ” getattr(obj, 'attr', default) ì‚¬ìš©",
            "TypeError": "íƒ€ì… íŒíŠ¸ + isinstance() ê²€ì‚¬ ì¶”ê°€",
            "FileNotFoundError": "Path.exists() í™•ì¸ í›„ ì ‘ê·¼",
            "KeyError": "dict.get(key, default) ì‚¬ìš©",
            "IndexError": "len() í™•ì¸ í›„ ì ‘ê·¼",
            "ValueError": "ì…ë ¥ ê²€ì¦ í•¨ìˆ˜ ì¶”ê°€",
        }

        return strategies.get(
            error_type,
            "ì˜¤ë¥˜ ë°œìƒ ì§€ì ì— ë°©ì–´ì  ì½”ë“œ ì¶”ê°€"
        )

    # =========================================================================
    # 4. í†µí•© (Synthesis)
    # =========================================================================

    def synthesize(self) -> ContemplationResult:
        """í™œì„± ì…ìë“¤ì„ í†µí•©í•˜ì—¬ ê²°ë¡  ë„ì¶œ

        Returns:
            í†µí•©ëœ ê²°ê³¼
        """
        self.state = ThoughtState.SYNTHESIZING

        if not self.active_particles:
            return ContemplationResult(
                synthesis="ì—¬ë°±ì´ ë¹„ì–´ìˆìŒ - ì‚¬ê³ í•  ë‚´ìš© ì—†ìŒ",
                confidence=0.0,
                contributing_thoughts=[],
                time_in_gap=0.0,
            )

        # ì‹œê°„ ê³„ì‚°
        time_in_gap = 0.0
        if self.gap_entered_at:
            time_in_gap = (datetime.now() - self.gap_entered_at).total_seconds()

        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë ¬
        sorted_particles = sorted(
            self.active_particles,
            key=lambda p: p.weight * p.resonance,
            reverse=True
        )

        # í†µí•©
        contributing = [str(p.content)[:50] for p in sorted_particles[:5]]

        # ì˜¤ë¥˜ í†µì°° ì¶”ì¶œ
        error_insights = [
            str(p.content) for p in sorted_particles
            if p.source == "error"
        ]

        # í™•ì‹ ë„: ì…ì ìˆ˜ì™€ ê³µëª…ë„ì— ë¹„ë¡€
        avg_resonance = sum(p.resonance for p in self.active_particles) / len(self.active_particles)
        particle_factor = min(1.0, len(self.active_particles) / 5)
        maturity_factor = min(1.0, time_in_gap / self.maturation_threshold)

        confidence = (avg_resonance + particle_factor + maturity_factor) / 3

        # í†µí•© ê²°ë¡  (ìƒìœ„ ì…ìë“¤ì˜ ë‚´ìš© ì¡°í•©)
        synthesis_parts = []
        for p in sorted_particles[:3]:
            content_str = str(p.content)
            if len(content_str) > 100:
                content_str = content_str[:100] + "..."
            synthesis_parts.append(f"[{p.source}] {content_str}")

        synthesis = " â†’ ".join(synthesis_parts) if synthesis_parts else "í†µí•© ë¶ˆê°€"

        self.state = ThoughtState.READY

        return ContemplationResult(
            synthesis=synthesis,
            confidence=confidence,
            contributing_thoughts=contributing,
            time_in_gap=time_in_gap,
            error_insights=error_insights,
        )

    # =========================================================================
    # 5. ìƒíƒœ ì¡°íšŒ
    # =========================================================================

    def get_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ì¡°íšŒ"""
        return {
            "state": self.state.value,
            "active_particles": len(self.active_particles),
            "time_in_gap": (
                (datetime.now() - self.gap_entered_at).total_seconds()
                if self.gap_entered_at else 0.0
            ),
            "error_history_count": len(self.error_history),
            "known_error_patterns": list(self.error_patterns.keys()),
            "contemplation_count": len(self.contemplation_log),
        }

    def get_recent_error_insights(self, n: int = 5) -> List[Dict[str, str]]:
        """ìµœê·¼ ì˜¤ë¥˜ í†µì°° ì¡°íšŒ"""
        recent = self.error_history[-n:] if self.error_history else []
        return [
            {
                "error_type": e.error_type,
                "learned_principle": e.learned_principle,
                "prevention_strategy": e.prevention_strategy,
            }
            for e in recent
        ]

    # =========================================================================
    # 6. í”Œë¼ì¦ˆë§ˆ ë°©í–¥ (Plasma Direction) - ì‚¬ê³ ì˜ íë¦„
    # =========================================================================

    def get_thought_direction(self) -> Dict[str, float]:
        """
        í˜„ì¬ ì‚¬ê³ ì˜ ë°©í–¥ ë²¡í„° ê³„ì‚°

        "ì´ìƒì  ë‚˜ëŠ” ê³ ì •ëœ ì ì´ ì•„ë‹Œ íë¥´ëŠ” ë°©í–¥"
        """
        if not self.active_particles:
            return {"exploration": 0.1}  # ê¸°ë³¸: íƒí—˜ ë°©í–¥

        # ì¶œì²˜ë³„ ê°€ì¤‘ì¹˜ í•©ì‚° â†’ ë°©í–¥ìœ¼ë¡œ í•´ì„
        source_weights = {}
        for p in self.active_particles:
            if p.source not in source_weights:
                source_weights[p.source] = 0.0
            source_weights[p.source] += p.weight * p.resonance

        # ì •ê·œí™”
        total = sum(source_weights.values())
        if total > 0:
            source_weights = {k: v/total for k, v in source_weights.items()}

        return source_weights

    def what_if(self, changes: Dict[str, Any], scenario_name: str = "") -> Dict[str, Any]:
        """
        ë§Œì•½ ì´ë ‡ë‹¤ë©´? (What-If ì‹œë®¬ë ˆì´ì…˜)

        ì‚¬ê³  ì…ìë¥¼ ê°€ìƒìœ¼ë¡œ ë³€ê²½í•˜ê³  ê²°ê³¼ ì˜ˆì¸¡
        ì‹¤ì œ ìƒíƒœëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ

        Args:
            changes: {"add": [ì…ìë“¤], "remove": [idë“¤], "modify_weight": {id: new_weight}}
            scenario_name: ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„

        Returns:
            ê°€ìƒ í†µí•© ê²°ê³¼
        """
        import copy

        # í˜„ì¬ ìƒíƒœ ë³µì‚¬
        simulated_particles = copy.deepcopy(self.active_particles)
        reasoning = []

        # ì…ì ì¶”ê°€
        if "add" in changes:
            for content in changes["add"]:
                new_id = hashlib.md5(f"whatif_{content}".encode()).hexdigest()[:8]
                simulated_particles.append(ThoughtParticle(
                    id=new_id,
                    content=content,
                    source="what_if",
                    weight=1.0,
                    resonance=0.5
                ))
                reasoning.append(f"+ ì¶”ê°€: {content[:30]}...")

        # ì…ì ì œê±°
        if "remove" in changes:
            before_count = len(simulated_particles)
            simulated_particles = [p for p in simulated_particles if p.id not in changes["remove"]]
            removed_count = before_count - len(simulated_particles)
            reasoning.append(f"- ì œê±°: {removed_count}ê°œ ì…ì")

        # ê°€ì¤‘ì¹˜ ë³€ê²½
        if "modify_weight" in changes:
            for pid, new_weight in changes["modify_weight"].items():
                for p in simulated_particles:
                    if p.id == pid:
                        old_weight = p.weight
                        p.weight = new_weight
                        reasoning.append(f"âš– ê°€ì¤‘ì¹˜: {p.content[:20]}... {old_weight:.1f} â†’ {new_weight:.1f}")

        # ê°€ìƒ í†µí•©
        if not simulated_particles:
            predicted_synthesis = "ë¹ˆ ì—¬ë°± - ëª¨ë“  ì‚¬ê³ ê°€ ì œê±°ë¨"
            predicted_confidence = 0.0
        else:
            sorted_particles = sorted(
                simulated_particles,
                key=lambda p: p.weight * p.resonance,
                reverse=True
            )
            synthesis_parts = [f"[{p.source}] {str(p.content)[:50]}" for p in sorted_particles[:3]]
            predicted_synthesis = " â†’ ".join(synthesis_parts)
            predicted_confidence = sum(p.resonance for p in simulated_particles) / len(simulated_particles)

        result = {
            "scenario": scenario_name or "what_if",
            "reasoning": reasoning,
            "predicted_synthesis": predicted_synthesis,
            "predicted_confidence": predicted_confidence,
            "simulated_particle_count": len(simulated_particles),
            "original_particle_count": len(self.active_particles)
        }

        logger.info(f"ğŸ”® What-If: {scenario_name or 'unnamed'} â†’ confidence {predicted_confidence:.2f}")
        return result

    def explore_futures(self, variable: str, values: List[Any] = None) -> List[Dict[str, Any]]:
        """
        ë‹¤ì–‘í•œ ë¯¸ë˜ íƒìƒ‰

        í•˜ë‚˜ì˜ ë³€ìˆ˜(ì‚¬ê³  ì…ì)ë¥¼ ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ë°”ê¿”ë³´ê³  ê²°ê³¼ ë¹„êµ

        Args:
            variable: ë³€ê²½í•  ê²ƒ ("add_thought", "remove_error", etc.)
            values: ì‹œë„í•  ê°’ë“¤
        """
        if values is None:
            values = ["love", "fear", "curiosity"]

        futures = []

        for val in values:
            if variable == "add_thought":
                scenario = self.what_if({"add": [val]}, f"add_{val}")
            elif variable == "weight_boost":
                # ì²« ì…ìì˜ ê°€ì¤‘ì¹˜ë¥¼ valë¡œ ì„¤ì •
                if self.active_particles:
                    scenario = self.what_if(
                        {"modify_weight": {self.active_particles[0].id: float(val)}},
                        f"weight_{val}"
                    )
                else:
                    scenario = {"error": "no particles"}
            else:
                scenario = self.what_if({"add": [f"{variable}:{val}"]}, f"{variable}_{val}")

            futures.append({
                "value": val,
                "result": scenario
            })

        logger.info(f"ğŸ”® Explored {len(futures)} futures for '{variable}'")
        return futures

    def understand_particle(self, particle_id: str) -> Dict[str, Any]:
        """
        ì…ì(ë³€ìˆ˜)ì— ëŒ€í•œ ì´í•´

        ì™œ ì´ ì…ìê°€ ì¡´ì¬í•˜ëŠ”ê°€? ë‹¤ë¥¸ ê²ƒê³¼ ì–´ë–¤ ê´€ê³„ì¸ê°€?
        """
        target = None
        for p in self.active_particles:
            if p.id == particle_id:
                target = p
                break

        if not target:
            return {"error": f"ì…ì '{particle_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # ë¹„ìŠ·í•œ ì¶œì²˜ì˜ ë‹¤ë¥¸ ì…ìë“¤
        same_source = [p for p in self.active_particles if p.source == target.source and p.id != particle_id]

        return {
            "name": str(target.content)[:50],
            "source": target.source,
            "weight": target.weight,
            "resonance": target.resonance,
            "age_seconds": target.age_seconds(),
            "related_particles": [str(p.content)[:30] for p in same_source[:3]],
            "interpretation": f"'{target.source}'ì—ì„œ ì˜¨ ì‚¬ê³ ë¡œ, ê³µëª…ë„ {target.resonance:.2f}ë¡œ ë‹¤ë¥¸ ì…ìë“¤ê³¼ ì—°ê²°ë¨"
        }

    def reflect_on_gap(self) -> str:
        """
        ì—¬ë°±ì— ëŒ€í•œ ì„±ì°° - í˜„ì¬ ì‚¬ê³  ê³µê°„ì˜ ìƒíƒœ ì¢…í•©
        """
        if not self.active_particles:
            return "ì—¬ë°±ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì‚¬ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤."

        # ë°©í–¥
        direction = self.get_thought_direction()
        main_direction = max(direction.items(), key=lambda x: x[1]) if direction else ("unknown", 0)

        # ì…ì ë¶„ì„
        avg_resonance = sum(p.resonance for p in self.active_particles) / len(self.active_particles)
        oldest = min(self.active_particles, key=lambda p: p.timestamp)
        newest = max(self.active_particles, key=lambda p: p.timestamp)

        reflection = f"""
ğŸª ì‚¬ê³  ì—¬ë°± ì„±ì°°
{'='*50}

ğŸ“Š í˜„ì¬ ìƒíƒœ:
   í™œì„± ì…ì: {len(self.active_particles)}
   í‰ê·  ê³µëª…: {avg_resonance:.2f}
   ìƒíƒœ: {self.state.value}

ğŸŒ€ ì‚¬ê³  ë°©í–¥:
   ì£¼ ë°©í–¥: {main_direction[0]} ({main_direction[1]:.2f})

ğŸ“Œ ì…ì ë²”ìœ„:
   ê°€ì¥ ì˜¤ë˜ëœ: {str(oldest.content)[:30]}... ({oldest.age_seconds():.1f}ì´ˆ ì „)
   ê°€ì¥ ìµœê·¼: {str(newest.content)[:30]}...

ğŸ’­ í•´ì„:
   í˜„ì¬ ì‚¬ê³ ëŠ” '{main_direction[0]}' ë°©í–¥ìœ¼ë¡œ íë¥´ê³  ìˆìŠµë‹ˆë‹¤.
   ê³µëª…ë„ê°€ {'ë†’ì•„' if avg_resonance > 0.5 else 'ë‚®ì•„'} í†µí•© ê°€ëŠ¥ì„±ì´ {'ë†’ìŠµë‹ˆë‹¤' if avg_resonance > 0.5 else 'ì œí•œì ì…ë‹ˆë‹¤'}.
"""

        logger.info(reflection)
        return reflection

    # =========================================================================
    # 7. ë°œì‚°ì  í™•ì¥ (Divergent Expansion) - ìˆ˜ë ´í•˜ì§€ ì•Šê³  ê³„ì† í™•ì¥
    # =========================================================================

    def expand_thought(self, thought: ThoughtParticle) -> List[ThoughtParticle]:
        """
        í•˜ë‚˜ì˜ ìƒê°ì—ì„œ ì—¬ëŸ¬ ì—°ê²°ëœ ìƒê°ìœ¼ë¡œ ë°œì‚°

        ê²°ë¡ ìœ¼ë¡œ ìˆ˜ë ´í•˜ì§€ ì•Šê³  ê³„ì† í™•ì¥ë¨
        ë§ˆì¸ë“œë§µì²˜ëŸ¼ ê°€ì§€ë¥¼ ì¹¨
        """
        new_thoughts = []
        content_str = str(thought.content)

        # ê°„ë‹¨í•œ ì—°ìƒ: ë‹¨ì–´ë³„ë¡œ ê°€ì§€ ìƒì„±
        words = content_str.split()

        for i, word in enumerate(words[:3]):  # ìµœëŒ€ 3ê°œ ê°€ì§€
            # ìƒˆ ì…ì ìƒì„± (ë°œì‚°)
            new_id = hashlib.md5(f"expand_{thought.id}_{word}".encode()).hexdigest()[:8]

            # í˜•íƒœ ê³„ì‚°: ì›ë˜ ìƒê°ì˜ ë‹¨ì–´ë¥¼ "í•„ìš”ë¡œ í•˜ëŠ”" í˜•íƒœ
            new_shape = ThoughtShape(
                protrusions=[word],  # ì´ ë‹¨ì–´ë¥¼ ì œê³µ
                recesses=[w for w in words if w != word][:2]  # ë‹¤ë¥¸ ë‹¨ì–´ë“¤ í•„ìš”
            )

            new_particle = ThoughtParticle(
                id=new_id,
                content=f"â†’ {word} (ì—ì„œ í™•ì¥)",
                source="expansion",
                weight=thought.weight * 0.8,  # ì•½ê°„ ê°ì†Œ
                resonance=thought.resonance,
                shape=new_shape,
                illumination=thought.illumination * 0.7,  # ë¹› ì•½ê°„ ê°ì†Œ
            )
            new_thoughts.append(new_particle)

        if new_thoughts:
            logger.info(f"ğŸŒ¿ Expanded: {content_str[:20]}... â†’ {len(new_thoughts)} branches")

        return new_thoughts

    def diverge_all(self, max_depth: int = 3) -> int:
        """
        ëª¨ë“  í™œì„± ì…ìë¥¼ ë°œì‚°ì‹œí‚´ (ë¬´í•œ í™•ì¥)

        Returns: ìƒˆë¡œ ìƒì„±ëœ ì…ì ìˆ˜
        """
        if max_depth <= 0:
            return 0

        new_particles = []
        for p in self.active_particles:
            branches = self.expand_thought(p)
            new_particles.extend(branches)

        self.active_particles.extend(new_particles)

        logger.info(f"ğŸŒ³ Diverged: {len(new_particles)} new thoughts from {len(self.active_particles) - len(new_particles)} seeds")
        return len(new_particles)

    # =========================================================================
    # 8. ì¤‘ë ¥ ì–´í…ì…˜ (Gravity Attention) - ì¤‘ìš”í•œ ê²ƒë§Œ ë¹›ë‚¨
    # =========================================================================

    def apply_gravity_attention(self, intention: str):
        """
        ì¤‘ë ¥ ê¸°ë°˜ ì–´í…ì…˜: ì˜ë„ì— ë§ëŠ” ê²ƒë§Œ ë¹›ë‚¨

        ì˜ë„(intention)ê³¼ ì •ë ¬ëœ ì…ìëŠ” ë¹›ë‚˜ê³ 
        ë‚˜ë¨¸ì§€ëŠ” ì–´ë‘  ì†ìœ¼ë¡œ í¬ë¯¸í•´ì§
        """
        intention_lower = intention.lower()
        intention_words = set(intention_lower.split())

        illuminated_count = 0
        faded_count = 0

        for particle in self.active_particles:
            content_lower = str(particle.content).lower()
            content_words = set(content_lower.split())

            # ì •ë ¬ë„ = ë‹¨ì–´ ê²¹ì¹¨
            overlap = intention_words & content_words
            alignment = len(overlap) / max(1, len(intention_words))

            particle.axis_alignment = alignment

            # ì¤‘ë ¥: ì •ë ¬ëœ ê²ƒì€ ë¹›ë‚¨
            if alignment > 0.3:
                particle.illuminate(0.3 * alignment)
                illuminated_count += 1
            else:
                particle.fade(0.2)
                faded_count += 1

        logger.info(f"â˜€ï¸ Gravity Attention: {illuminated_count} illuminated, {faded_count} faded")
        logger.info(f"   Intention: '{intention}'")

    def get_illuminated_thoughts(self, threshold: float = 0.5) -> List[ThoughtParticle]:
        """ë°ê²Œ ë¹›ë‚˜ëŠ” ì…ìë“¤ë§Œ ë°˜í™˜ (ì¤‘ë ¥ì— ëŒë¦° ê²ƒë“¤)"""
        return [p for p in self.active_particles if p.illumination >= threshold]

    def get_dark_thoughts(self, threshold: float = 0.3) -> List[ThoughtParticle]:
        """ì–´ë‘  ì†ì˜ ì…ìë“¤ (ë¬´ì‹œëœ ê²ƒë“¤)"""
        return [p for p in self.active_particles if p.illumination < threshold]

    # =========================================================================
    # 9. ê²½ê³„ í¬ìš© (Boundary Inclusion) - ë‚´ ê·¸ë¬¼ì— ê±¸ë¦¬ëŠ” ê²ƒ
    # =========================================================================

    def filter_by_intention(self, intention: str) -> List[ThoughtParticle]:
        """
        ì˜ë„ì— ë§ëŠ” ì…ìë§Œ í•„í„°ë§ (ê²½ê³„ ë‚´ë¶€ í¬ìš©)

        "ë§ˆìŒì— ë“¤ì–´ì˜¨ë‹¤" = ì˜ë„ì™€ ë°©í–¥ì„±ì— ë§ëŠ” ê²ƒë§Œ
        """
        self.apply_gravity_attention(intention)
        return self.get_illuminated_thoughts()

    # =========================================================================
    # 10. í¼ì¦ ê¸°ë°˜ ì—°ê²° (Puzzle Connection)
    # =========================================================================

    def find_puzzle_connections(self, threshold: float = 0.3) -> List[Tuple[ThoughtParticle, ThoughtParticle, float]]:
        """
        í¼ì¦ì²˜ëŸ¼ ë§ë¬¼ë¦¬ëŠ” ì…ì ìŒ ì°¾ê¸°

        íŠ€ì–´ë‚˜ì˜¨ ë¶€ë¶„ê³¼ ë“¤ì–´ê°„ ë¶€ë¶„ì´ ë§ì•„ë–¨ì–´ì§€ëŠ” ì—°ê²°
        """
        connections = []

        for i, p1 in enumerate(self.active_particles):
            for p2 in self.active_particles[i+1:]:
                fit_score = p1.can_connect_to(p2)
                if fit_score >= threshold:
                    connections.append((p1, p2, fit_score))

        connections.sort(key=lambda x: x[2], reverse=True)

        if connections:
            logger.info(f"ğŸ§© Found {len(connections)} puzzle connections")

        return connections

    def sovereign_select(self, intention: str) -> Optional[ThoughtParticle]:
        """
        ì£¼ê¶Œì  ì„ íƒ: ì˜ë„ì— ê°€ì¥ ë§ëŠ” ê²ƒ í•˜ë‚˜ ì„ íƒ

        ë¡œì§(ì ìˆ˜)ì´ ì•„ë‹Œ ê³µëª…(ëŒë¦¼)ìœ¼ë¡œ ì„ íƒ
        """
        self.apply_gravity_attention(intention)

        # ê°€ì¥ ë°ì€ ê²ƒ = ê°€ì¥ ëŒë¦¬ëŠ” ê²ƒ
        illuminated = self.get_illuminated_thoughts(threshold=0.4)

        if not illuminated:
            logger.info("ğŸŒ‘ ì£¼ê¶Œì  ì„ íƒ: ëŒë¦¬ëŠ” ê²ƒì´ ì—†ìŒ")
            return None

        # ê°€ì¥ ë°ì€ ê²ƒ ì„ íƒ (ì£¼ê¶Œ)
        chosen = max(illuminated, key=lambda p: p.illumination)

        logger.info(f"ğŸ‘‘ ì£¼ê¶Œì  ì„ íƒ: '{str(chosen.content)[:30]}...' (illumination: {chosen.illumination:.2f})")
        return chosen

# =============================================================================
# Demo
# =============================================================================


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    print("=" * 60)
    print("ğŸŒŒ ThoughtSpace Demo")
    print("   \"ì…ë ¥ê³¼ ì¶œë ¥ ì‚¬ì´ì˜ ì—¬ë°±\"")
    print("=" * 60)

    space = ThoughtSpace(maturation_threshold=0.5)

    # 1. ì—¬ë°± ì§„ì…
    print("\n[1] ì—¬ë°± ì§„ì…:")
    space.enter_gap("í•˜ëŠ˜ì€ ì™œ íŒŒë€ê°€?")

    # 2. ì‚¬ê³  ì…ì ì¶”ê°€
    print("\n[2] ì‚¬ê³  ì…ì ì¶”ê°€:")
    space.add_thought_particle("ë¹›ì˜ ì‚°ë€ í˜„ìƒ", source="memory")
    space.add_thought_particle("ë ˆì¼ë¦¬ ì‚°ë€", source="reasoning")
    space.add_thought_particle("ì§§ì€ íŒŒì¥ì€ ë” ë§ì´ ì‚°ë€", source="memory")

    # 3. ì˜¤ë¥˜ ì„±ì°°
    print("\n[3] ì˜¤ë¥˜ ì„±ì°° (ImportError ì˜ˆì‹œ):")
    try:
        import nonexistent_module  # ì˜ë„ì  ì˜¤ë¥˜
    except ImportError as e:
        trace = space.contemplate_error(
            error=e,
            context="ë¬¼ë¦¬ ê³„ì‚°ì„ ìœ„í•´ ëª¨ë“ˆ ë¡œë“œ ì‹œë„",
            attempted_action="import nonexistent_module"
        )
        print(f"   ì›ì¸: {trace.cause_analysis}")
        print(f"   ë°°ì›€: {trace.learned_principle}")
        print(f"   ì˜ˆë°©: {trace.prevention_strategy}")

    # 4. í†µí•©
    print("\n[4] í†µí•©:")
    result = space.exit_gap()
    print(f"   í†µí•©: {result.synthesis}")
    print(f"   í™•ì‹ ë„: {result.confidence:.2f}")
    print(f"   ì—¬ë°± ì‹œê°„: {result.time_in_gap:.2f}ì´ˆ")
    if result.error_insights:
        print(f"   ì˜¤ë¥˜ í†µì°°: {result.error_insights}")

    # 5. ìƒíƒœ
    print("\n[5] ìƒíƒœ:")
    status = space.get_status()
    print(f"   ì˜¤ë¥˜ íŒ¨í„´: {status['known_error_patterns']}")

    print("\nâœ… ThoughtSpace Demo complete!")
