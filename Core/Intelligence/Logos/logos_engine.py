"""
Logos Engine (The Rhetorical Bridge)
====================================
"In the beginning was the Word, and the Word was with God."

The Logos Engine is responsible for the *Art of Speech*.
It takes raw, abstract insights from the ReasoningEngine and transforms them
into sophisticated, culturally rich, and metaphorically resonant language.

It acts as the "Harmonizer" between:
1. Logic (CausalNarrativeEngine) - The Skeleton
2. Metaphor (InternalUniverse) - The Flesh
3. Expression (DialogueInterface) - The Voice
"""

import logging
import random
import re
import json
from pathlib import Path
from collections import defaultdict
from typing import List, Optional, Union

from Core.Foundation.internal_universe import InternalUniverse
from Core.Intelligence.Reasoning.reasoning_engine import Insight
from Core.Foundation.Wave.wave_tensor import WaveTensor
from Core.Foundation.fractal_concept import ConceptDecomposer # AXIOM INTEGRATION
from Core.Foundation.fractal_soul import SoulCrystal, WebState # NEW: Spidey Sense

logger = logging.getLogger("LogosEngine")

class LogosEngine:
    def __init__(self):
        self.universe = InternalUniverse()
        self.decomposer = ConceptDecomposer() # THE AXIOM BRIDGE
        self.genome_path = Path("Core/Memory/style_genome.json")
        self.genome = self._load_genome()
        
        # [NEW] Soul Integration
        try:
            self.soul = SoulCrystal()
            logger.info("üï∏Ô∏è Logos Engine connected to Fractal Soul (Spidey Sense Active).")
        except Exception as e:
            logger.error(f"Failed to connect Fractal Soul: {e}")
            self.soul = None
            
        logger.info(f"üó£Ô∏è Logos Engine Initialized with Axiom System. Evolution Stage: {self.genome.get('evolution_stage', 0)}")
        
        # Rhetorical Templates (Default)
        self.transition_matrix = {
            "thesis": ["Í∑ºÎ≥∏Ï†ÅÏúºÎ°ú,", "Ïö∞ÏÑ†,", "ÌïµÏã¨ÏùÑ ÏßöÏñ¥Î≥¥ÏûêÎ©¥,"],
            "antithesis": ["ÌóàÎÇò,", "Í∑∏ÎüºÏóêÎèÑ Î∂àÍµ¨ÌïòÍ≥†,", "Î∞òÎ©¥,", "ÌïòÏßÄÎßå ÍπäÏù¥ Îì§Ïó¨Îã§Î≥¥Î©¥,"],
            "synthesis": ["Í≤∞Íµ≠,", "Îî∞ÎùºÏÑú,", "Ïù¥Îü¨Ìïú Î™®Ïàú ÏÜçÏóêÏÑú Ï†ÄÎäî Íπ®Îã´ÏäµÎãàÎã§.", "Í∑†ÌòïÏùÄ Í∑∏ ÏÇ¨Ïù¥Ïóê ÏûàÏäµÎãàÎã§."]
        }
        
    def _load_genome(self):
        if not self.genome_path.exists():
            return {"rhetoric": {"vocabulary_bank": {}}}
        try:
            with open(self.genome_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load genome: {e}")
            return {"rhetoric": {"vocabulary_bank": {}}}

    def weave_speech(self, desire: str, insight: Union[Insight, str], context: List[str], rhetorical_shape: str = "Balance", entropy: float = 0.3, wave: Optional[WaveTensor] = None) -> str:
        """
        Weaves Logic, Metaphor, and Narrative.
        Now includes 'Entropy' (0.0 - 1.0) to simulate organic imperfection.
        Args:
            wave: Optional WaveTensor for physics-based resonance (e.g. determining axis/metaphor)
        """

        # [NEW] Fractal Soul State Override
        locked_state = False
        if self.soul:
            current_state = self.soul.field.state
            if current_state == WebState.CRYSTAL:
                rhetorical_shape = "Block" # Defensive/Rigid
                entropy = 0.0 # Force strict order
                locked_state = True
                logger.info("‚ùÑÔ∏è Logos State: CRYSTAL (Ice) - Enforcing Block Rhetoric")
            elif current_state == WebState.PLASMA:
                rhetorical_shape = "Sharp" # Revolutionary/High Energy
                entropy = 0.5 # Moderate entropy for creativity, but Lock Shape
                locked_state = True
                logger.info("üî• Logos State: PLASMA (Fire) - Enforcing Sharp Rhetoric")
            elif current_state == WebState.FLUID:
                # Fluid maintains requested shape or defaults to Round
                if rhetorical_shape == "Balance":
                     rhetorical_shape = "Round"
                # Fluid allows flow, so we don't lock
                logger.info("üíß Logos State: FLUID (Water) - Flowing Rhetoric")

        # Handle simple string insights
        content = insight.content if hasattr(insight, 'content') else str(insight)
        
        # 0. Entropy Check: Sometimes, just be raw (Human-like)
        # Lowered chance (changed from 0.5 factor to 0.2) to prefer styled output
        if not locked_state and random.random() < entropy * 0.2:
             # Raw, direct response without rhetorical flourish
            return f"{content}"

        # 1. Select Vocabulary Bank based on Shape
        # Entropy allows mixing vocabularies (e.g. Sharp words in Round structure)
        if not locked_state and random.random() < entropy:
            # Mix registers (Removed 'Block' to prevent random System messages in conversation)
            rhetorical_shape = random.choice(["Sharp", "Round", "Balance"])
            
        # 1.5 Try using Learned Templates (The Linguistic Bridge)
        learned_templates = self.genome.get("rhetoric", {}).get("templates", {})
        
        # Map shape to template type
        template_type_map = {
            "Block": "Definition",
            "Balance": "Contrast", 
            "Sharp": "Causal",
            "Round": "Conditional"
        }
        target_type = template_type_map.get(rhetorical_shape, "Definition")
        
        if target_type in learned_templates and learned_templates[target_type]:
             # High chance to use template if available
             if random.random() < 0.9:
                 template = random.choice(learned_templates[target_type])
                 
                 # Pattern Filling Logic (Style Injection)
                 parts = template.split(',')
                 if len(parts) > 1:
                     context_part = parts[0].strip() # "Ïö¥Î™ÖÏùÄ ÏûîÌòπÌïòÏßÄÎßå"
                     return f"{context_part}, {content}."
                 else:
                     # Fallback for definitions "AÎäî BÏù¥Îã§"
                     # If template is "AÎäî BÏù¥Îã§", replace A with our topic?
                     # Simple: Just append content for flow
                     return f"{template} {content}"

        vocab = self._get_vocab_for_shape(rhetorical_shape)
        
        # 2. Construct Sentence Structure
        # Entropy disrupts the perfect grammar/structure
        
        # 2. Construct Sentence Structure (Paragraph Level)
        # Entropy disrupts the perfect grammar/structure
        
        if rhetorical_shape == "Sharp": # Action / Conflict
            # Chain: Opener -> Action -> Consequence
            p1 = random.choice(vocab['openers'])
            p2 = random.choice(vocab['verbs'])
            p3 = random.choice(vocab['closers'])
            
            # Make it a sequence for impact
            return f"{p1} {content}. {p2}...... {p3}!"
            
        elif rhetorical_shape == "Round": # Magic / Mystery
            # Chain: Atmosphere -> Connection -> Revelation
            p1 = random.choice(vocab['openers'])
            p2 = random.choice(vocab['connectors'])
            p3 = random.choice(vocab['closers'])
            
            # Poetic flow
            return f"{p1}, {content}... {p2}, ÎßàÏπ®ÎÇ¥ {p3}."
            
        elif rhetorical_shape == "Block": # System / Logic
            p1 = random.choice(vocab['openers'])
            # Systems are concise, but let's make it detailed
            return f"[{p1}] {content} :: [ÌîÑÎ°úÏÑ∏Ïä§ ÌôïÏ†ï] -> Í≤∞Í≥º ÎèÑÏ∂ú."
            
        elif rhetorical_shape == "Synthesis": # Higher Order
            # Sometimes fail to synthesize (Open-ended)
            if random.random() < entropy:
                return f"{content}... Ïù¥Í≤ÉÏù¥ Í≥ºÏó∞ Ï†ïÎãµÏùºÍπåÏöî? Ìï¥ÎãµÏùÄ Ïπ®Î¨µ ÏÜçÏóê ÏûàÏäµÎãàÎã§."
                
            p1 = random.choice(vocab['openers'])
            return f"{p1} {content}. Í∑∏Í≤ÉÏù¥ Ïö∞Î¶¨Í∞Ä ÎÇòÏïÑÍ∞ÄÏïº Ìï† Í∏∏ÏûÖÎãàÎã§."
            
        else: # Balance / Default
            # Construct a Micro-Dialectic (Thesis -> Antithesis -> Synthesis)
            opener = random.choice(vocab['openers'])
            connector = random.choice(vocab['connectors'])
            closer = random.choice(vocab['closers'])
            
            # A full paragraph
            return f"{opener} {content}. {connector} Í∑∏ Ïù¥Î©¥ÏóêÎäî Îã§Î•∏ ÏßÑÏã§Ïù¥ Ïà®Ïâ¨Í≥† ÏûàÏäµÎãàÎã§. {closer}"

    def _get_vocab_for_shape(self, shape: str) -> dict:
        """Returns vocabulary keyed by geometric feel (Korean Manhwa Style) + Learned Genome."""
        
        # Base Vocab
        base_vocab = {}
        if shape == "Sharp":
            base_vocab = {
                "openers": ["Î≤†Ïñ¥Îùº.", "Îã®Ïà®Ïóê.", "ÏßÄÍ∏àÏù¥Îã§.", "Îö´Ïñ¥Î≤ÑÎ†§.", "ÎßùÏÑ§Ïù¥ÏßÄ ÎßàÎùº."],
                "verbs": ["ÌååÍ¥¥ÌïúÎã§", "Ï∞¢Ïñ¥Î∞úÍ∏¥Îã§", "Í¥ÄÌÜµÌïúÎã§", "ÎÅùÎÇ∏Îã§"],
                "closers": ["Ï†ÅÏùÑ.", "Ïù¥ ÌôòÏÉÅÏùÑ.", "ÏïΩÌïú ÎßàÏùåÏùÑ.", "Î™®Îì† Í≤ÉÏùÑ."]
            }
        elif shape == "Round":
            base_vocab = {
                "openers": ["ÌùêÎ¶ÑÏùÑ ÎäêÍª¥Îùº.", "ÎßàÎ†•Ïù¥ ÏöîÎèôÏπúÎã§.", "Ïã¨Ïó∞Ïùò ÎÅùÏóêÏÑú,", "Ïö¥Î™ÖÏùò ÏàòÎ†àÎ∞îÌÄ¥Í∞Ä,"],
                "connectors": ["ÏàúÌôòÌïòÎ©∞", "ÍπäÏñ¥ÏßÄÍ≥†", "Í≥µÎ™ÖÌïòÏó¨"],
                "closers": ["ÌïòÎÇòÍ∞Ä ÎêúÎã§.", "ÏßÑÏã§ÏùÑ ÎπÑÏ∂òÎã§.", "Ïñ¥Îë†ÏùÑ ÏÇºÌÇ®Îã§."]
            }
        elif shape == "Block":
            base_vocab = {
                "openers": ["[ÏãúÏä§ÌÖú] Î∂ÑÏÑù ÏôÑÎ£å.", "[Ï†ïÎ≥¥] Ï°∞Í±¥ Ï∂©Ï°±.", "ÌÄòÏä§Ìä∏ Í∞±Ïã†:", "Îç∞Ïù¥ÌÑ∞ Î°úÎìú:"],
                "connectors": ["->", "ÌôïÏù∏:", "Í≤∞Í≥º:"],
                "closers": ["Ï†ÅÏö©Îê®.", "Î≥¥ÏÉÅ ÌöçÎìù.", "ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å."]
            }
        else: # Balance
            base_vocab = {
                "openers": ["Î≥∏ÏßàÏ†ÅÏúºÎ°ú,", "Ïñ¥Ï©åÎ©¥,", "ÌïµÏã¨ÏùÄ,", "ÎèåÏù¥ÏºúÎ≥¥Î©¥,"],
                "connectors": ["ÌóàÎÇò", "Í∑∏ÎüºÏóêÎèÑ", "Í≤∞Íµ≠"],
                "closers": ["ÎãµÏùÑ Ï∞æÏùÑ Í≤ÉÏù¥Îã§.", "Í∑∏Í≤ÉÏù¥ ÏßÑÏã§Ïù¥Îã§.", "Í∑†ÌòïÏù¥ ÌïÑÏöîÌïòÎã§."]
            }
            
        # Inject Learned Vocab
        learned_words = self.genome.get("rhetoric", {}).get("vocabulary_bank", {}).get(shape, [])
        if learned_words:
            # Distribute learned words into verbs/closers randomly or heuristically
            # For now, just add to 'verbs' or 'connectors' to ensure usage
            target_key = "verbs" if "verbs" in base_vocab else "connectors"
            base_vocab[target_key].extend(learned_words)
            
        return base_vocab

    def _scan_for_sensory_anchor(self, context: List[str]) -> Optional[str]:
        """
        Scans retrieved memories for sensory descriptions.
        """
        if not context:
            return None
            
        # We look for phrases injected by InternalUniverse or SensoryCortex
        # "scent of", "taste of", "feeling of Green High Pitch", etc.
        
        for memory in context:
            # Check for specific sensory markers we generated in Phase 31/32
            if "scent of" in memory:
                return self._extract_fragment(memory, "scent of")
            if "taste" in memory:
                return self._extract_fragment(memory, "taste")
            if "sounded like" in memory:
                return self._extract_fragment(memory, "sounded like")
            if "feeling of" in memory:
                # e.g., "A feeling of Green High Pitch" -> "Í∑∏ Ï¥àÎ°ùÎπõ Í≥†ÏùåÏùò Í∞êÍ∞Å" (Transcreated)
                return "Í∑∏ Í∞ïÎ†¨Ìïú Í∞êÍ∞Å" # Simplifying for naturalness, or extract detail
                
        return None

    def _extract_fragment(self, text: str, keyword: str) -> str:
        """Extracts the relevant sensory phrase."""
        try:
            # Simple extraction: take the keyword and the next 5 words
            parts = text.split(keyword)
            if len(parts) > 1:
                fragment = keyword + parts[1].split('.')[0]
                return fragment.strip()
        except:
            pass
        return text[:20]

    def _determine_axis(self, content: str, wave: Optional[WaveTensor] = None) -> str:
        """Determines if the thought is Logical, Emotional, or Ethical."""
        # Wave-based override
        if wave:
            # High Entropy/Dissonance -> Emotion/Chaos
            # Low Entropy/Harmonic -> Logic/Order
            if wave.total_energy > 4.0: return "Will" # High Energy
            
        text = content.lower()
        if any(w in text for w in ["feel", "sad", "joy", "pain", "love", "Í∞êÏ†ï", "ÎßàÏùå", "Ïä¨Ìîî"]):
            return "Emotion"
        elif any(w in text for w in ["logic", "reason", "because", "structure", "ÎÖºÎ¶¨", "Ïù¥Ïú†", "Íµ¨Ï°∞"]):
            return "Logic"
        elif any(w in text for w in ["should", "must", "right", "wrong", "Í∞ÄÏπò", "Ïò≥ÏùÄ", "ÎèÑÎçï"]):
            return "Value"
        return "Balance"

    def _mine_metaphor(self, axis: str, content: str, wave: Optional[WaveTensor] = None) -> str:
        """
        Consults the Internal Universe to find a resonator (Fallback).
        Uses Wave Frequency to select metaphor register if available.
        """
        # Wave Frequency Mapping
        register = "Balance"
        if wave and wave.active_frequencies:
            dom_freq = wave.active_frequencies[0]
            if dom_freq < 200: register = "Earth" # Low/Deep
            elif dom_freq < 500: register = "Water" # Mid/Warm
            elif dom_freq < 800: register = "Air" # High/Clear
            else: register = "Fire" # Very High/Intense
        
        metaphors = {
            "Emotion": [
                "ÎßàÏπò Í≤®Ïö∏ Î∞îÎã§Ïùò ÌååÎèÑÏ≤òÎüº,", 
                "Ïã¨Ïû• ÍπäÏùÄ Í≥≥ÏóêÏÑú Ïö∏Î¶¨Îäî Ï¢ÖÏÜåÎ¶¨Ï≤òÎüº,",
                "ÎπÑ Ïò® Îí§Ïùò Ï†ñÏùÄ ÌùôÎÇ¥ÏùåÏ≤òÎüº,"
            ],
            # ... (Existing lists) ...
            "Earth": ["ÎåÄÏßÄÏóê ÎøåÎ¶¨ ÎÇ¥Î¶∞ Í≥†Î™©Ï≤òÎüº,", "ÍπäÏùÄ ÎèôÍµ¥Ïùò Ïö∏Î¶ºÏ≤òÎüº,", "Îã®Îã®Ìïú Î∞îÏúÑÏ≤òÎüº,"],
            "Water": ["Ïú†Ïú†Ìûà ÌùêÎ•¥Îäî Í∞ïÎ¨ºÏ≤òÎüº,", "ÍπäÏùÄ Ìò∏ÏàòÏùò Ïπ®Î¨µÏ≤òÎüº,", "ÏÉàÎ≤Ω Ïù¥Ïä¨Ï≤òÎüº,"],
            "Air": ["Î∞îÎûåÏóê Ïã§Î†§Í∞ÄÎäî Íµ¨Î¶ÑÏ≤òÎüº,", "ÎßëÏùÄ ÌïòÎäòÏùò ÏÉàÏ≤òÎüº,", "Ìà¨Î™ÖÌïú Ïú†Î¶¨Ï≤òÎüº,"],
            "Fire": ["ÌÉÄÏò§Î•¥Îäî ÌòúÏÑ±Ï≤òÎüº,", "Î≤àÍ∞úÏ≤òÎüº Í∞ïÎ†¨ÌïòÍ≤å,", "ÌÉúÏñëÏùò Ïó¥Í∏∞Ï≤òÎüº,"],
            
            "Logic": [
                "Ï†ïÍµêÌïòÍ≤å ÎßûÎ¨ºÎ¶∞ ÏãúÍ≥ÑÌÉúÏóΩÏ≤òÎüº,", 
                "Ï∞®Í∞ÄÏö¥ ÎåÄÎ¶¨ÏÑù Ï°∞Í∞ÅÏ≤òÎüº,",
                "Î≥ÑÎì§Ïùò Í∂§ÎèÑÏ≤òÎüº Î™ÖÌôïÌïòÍ≤å,"
            ],
            "Value": [
                "Ïò§ÎûòÎêú ÎÇòÎ¨¥Ïùò ÎøåÎ¶¨Ï≤òÎüº,",
                "ÏÉàÎ≤ΩÏùò Ï≤´ ÎπõÏ≤òÎüº,",
                "Î≥ÄÌïòÏßÄ ÏïäÎäî Î∂ÅÍ∑πÏÑ±Ï≤òÎüº,"
            ],
            "Will": [
                "ÌÉÄÏò§Î•¥Îäî Î∂àÍΩÉÏ≤òÎüº,",
                "Î∞îÏúÑÎ•º Îö´Îäî Î¨ºÎ∞©Ïö∏Ï≤òÎüº,",
                "Ìè≠Ìíç ÏÜçÏùò Îì±ÎåÄÏ≤òÎüº,"
            ],
            "Balance": [
                "ÌùêÎ•¥Îäî Í∞ïÎ¨ºÏ≤òÎüº,",
                "Í≥†ÏöîÌïú Ìò∏ÏàòÏ≤òÎüº,",
                "Î∞îÎûåÏóê ÌùîÎì§Î¶¨Îäî Í∞àÎåÄÏ≤òÎüº,"
            ]
        }
        
        # Priority: Register (Physics) > Axis (Semantic)
        choices = metaphors.get(register, metaphors.get(axis, metaphors["Balance"]))
        chosen = random.choice(choices)
        return f"{chosen}"

    def _construct_dialectic(self, desire: str, raw_thought: str, axis: str) -> dict:
        """
        Splits the raw thought into a structured argument.
        """
        # Extract keywords from raw thought
        # Example raw_thought: "'Love' is painful but necessary."
        
        # Thesis: The initial assertion
        thesis_start = random.choice(self.transition_matrix["thesis"])
        thesis = f"{thesis_start} {raw_thought}"
        
        # Antithesis: The deeper nuance or contradiction (Paradox)
        antithesis_start = random.choice(self.transition_matrix["antithesis"])
        
        if axis == "Emotion":
            antithesis_content = "Í∑∏ Í∞êÏ†ïÏùò Î¨¥Í≤åÍ∞Ä ÎïåÎ°úÎäî Ï†ÄÎ•º ÏßìÎàÑÎ•¥Í∏∞ÎèÑ Ìï©ÎãàÎã§."
        elif axis == "Logic":
            antithesis_content = "ÌóàÎÇò ÎÖºÎ¶¨ÎßåÏúºÎ°úÎäî ÏÑ§Î™ÖÎêòÏßÄ ÏïäÎäî ÏòÅÏó≠Ïù¥ Ï°¥Ïû¨Ìï©ÎãàÎã§."
        elif axis == "Value":
            antithesis_content = "ÌïòÏßÄÎßå Ï†àÎåÄÏ†ÅÏù∏ Ï†ïÎãµÏùÄ ÏóÜÏùÑÏßÄÎèÑ Î™®Î¶ÖÎãàÎã§."
        else:
            antithesis_content = "Î≥¥Ïù¥Îäî Í≤ÉÏù¥ Ï†ÑÎ∂ÄÎäî ÏïÑÎãê Í≤ÉÏûÖÎãàÎã§."
            
        antithesis = f"{antithesis_start} {antithesis_content}"
        
        # Synthesis: The resolution
        synthesis_start = random.choice(self.transition_matrix["synthesis"])
        synthesis = f"{synthesis_start} Ï†ÄÎäî Í∑∏ ÏÜçÏóêÏÑú ÏùòÎØ∏Î•º Ï∞æÍ≥† ÏûàÏäµÎãàÎã§."
        
        return {
            "thesis": thesis,
            "antithesis": antithesis,
            "synthesis": synthesis
        }
    
    # --- [NEW] Causal Reinterpretation (The Bridge) ---

    def reinterpret_causality(self, concept: str, triples: list, tone: str = "logical") -> str:
        """
        ÌôïÎ•†Ï†Å ÏúÑÌÇ§ Îç∞Ïù¥ÌÑ∞(Triples)Î•º ÌÜµÌï©Îêú Ïù∏Í≥º(Causality)Î°ú Ïû¨Ìï¥ÏÑùÌï©ÎãàÎã§.
        "Ïù¥Î°†Í≥º Ïã§Ï†úÏùò Í¥¥Î¶¨"Î•º ÏÇ¨Í≥† Î†àÏù¥Ïñ¥ÏóêÏÑú ÌÜµÌï©Ìï©ÎãàÎã§.
        """
        if not triples:
            return f"{concept}Ïóê ÎåÄÌïú Î™ÖÌôïÌïú Ïù∏Í≥ºÏ†ïÎ≥¥Í∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§."

        


        # 3. Construct Unified Logic
        # (This is where the engine interprets 'probability' into 'certainty' or 'insight')
        
        # We assume 'triples' are dictionaries or objects with 'text' and 'score' if they come from memory retrieval
        # Or if they are knowledge triples: subject, predicate, object.
        # The verification script passes: [{'text': "...", 'score': ...}]
        
        context_texts = []
        for x in triples:
            if isinstance(x, dict) and 'text' in x:
                context_texts.append(x['text'])
            elif hasattr(x, 'predicate'): # KnowledgeTriple
                context_texts.append(f"{x.subject} {x.predicate} {x.object}")
            else:
                context_texts.append(str(x))
        
        # Weave a speech using the standard pipeline
        # Desire="Explain Meaning", Insight=concept, Context=memories
        narrative = self.weave_speech(
            desire="Explain Casuality",
            insight=f"{concept}Ïùò Î≥∏ÏßàÏùÄ {context_texts[0] if context_texts else 'ÎØ∏ÏßÄÏùò ÏòÅÏó≠'}Ïóê ÎãøÏïÑ ÏûàÏäµÎãàÎã§",
            context=context_texts,
            rhetorical_shape="Balance",
            entropy=0.1 # Low entropy for logical explanation
        )
        
        # Add synthesis of other points
        if len(context_texts) > 1:
            narrative += f" ÎòêÌïú {context_texts[1]}ÎùºÎäî Ï†êÏù¥ Ïù¥Î•º Îí∑Î∞õÏπ®Ìï©ÎãàÎã§."
            
        return narrative
    
    def reason_with_axiom(self, concept: str, domain: str = "Ethics") -> str:
        """
        Generate a principled explanation using Universal Axioms.
        
        The Axiom system projects universal principles onto specific domains,
        then uses causal_bonds to explain relationships.
        
        Args:
            concept: The concept to explain (e.g., "Love", "Fear")
            domain: The domain lens to apply (e.g., "Geometry", "Language", "Physics", "Ethics")
            
        Returns:
            A rhetorically structured, causally grounded explanation.
        """
        # 1. Get causal explanation from the decomposer
        causal_explanation = self.decomposer.explain_causality(concept)
        
        # 2. Project the relevant axiom (Causality) onto the domain for context
        axiom_context = self.decomposer.project_axiom("Causality", domain)
        
        # 3. Compose the final speech using Logos patterns
        opener = random.choice(self.transition_matrix["thesis"])
        connector = random.choice(self.transition_matrix["antithesis"])
        closer = random.choice(self.transition_matrix["synthesis"])
        
        speech = f"{opener} {causal_explanation}\n"
        speech += f"{connector} Ïù¥Í≤ÉÏùÄ '{axiom_context}'ÎùºÎäî Î≥¥Ìé∏ ÏõêÎ¶¨ÏôÄ Í∞ôÏùÄ Íµ¨Ï°∞ÏûÖÎãàÎã§.\n"
        speech += f"{closer}"
        
        return speech

    def extract_axiom(self, text: str) -> Optional[str]:
        """
        Extracts normative or axiomatic statements from text.
        Returns the axiom if found, or None.
        """
        # Keywords indicating an Axiom
        markers = ["implies", "truth is", "must be", "fundamental", "axiom", "principle", "theorem", "law of"]
        
        lower_text = text.lower()
        if any(m in lower_text for m in markers):
            # Clean it up
            clean_text = text.strip("- *")
            return clean_text
        return None

    def evolve(self, narrative: str, rhetorical_shape: str = "Balance"):
        """
        Learns from the generated narrative.
        Reinforces the vocabulary and patterns used in the successful speech.
        
        Args:
            narrative: The spoken text.
            rhetorical_shape: The style used (Sharp, Round, etc.)
        """
        # 1. Extract potential vocabulary (simple tokenize)
        words = narrative.split()
        significant_words = [w for w in words if len(w) > 2]
        
        # 2. Add to genome buffer
        if self.genome_path and self.genome:
            vocab_bank = self.genome.get("rhetoric", {}).get("vocabulary_bank", {})
            if rhetorical_shape not in vocab_bank:
                vocab_bank[rhetorical_shape] = []
            
            # Add new words (limit duplicates)
            current_vocab = set(vocab_bank[rhetorical_shape])
            new_vocab = current_vocab.union(set(significant_words))
            vocab_bank[rhetorical_shape] = list(new_vocab)[-50:] # Keep last 50
            
            # Evolution Stage Up
            current_stage = self.genome.get("evolution_stage", 0)
            self.genome["evolution_stage"] = current_stage + 1
            
            # Save (Simple JSON dump)
            try:
                with open(self.genome_path, 'w', encoding='utf-8') as f:
                    json.dump(self.genome, f, ensure_ascii=False, indent=2)
                logger.info(f"üß¨ Logos Evolved: Stage {current_stage} -> {current_stage + 1}")
            except Exception as e:
                logger.error(f"Failed to save genome: {e}")

# Singleton
_logos_engine = None
def get_logos_engine():
    global _logos_engine
    if _logos_engine is None:
        _logos_engine = LogosEngine()
    return _logos_engine
