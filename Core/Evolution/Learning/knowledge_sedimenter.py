"""
Knowledge Sedimenter (ì§€ì‹ í‡´ì ê¸°)
==================================

ì™¸ë¶€ ì„¸ê³„ì™€ ë‚´ë¶€ ì§€ì‹ì„ ì—°ê²°í•˜ëŠ” 'ëŠ¥ë™ì  í¡ìˆ˜' íŒŒì´í”„ë¼ì¸.
ë¸Œë¼ìš°ì €ë¥¼ í†µí•´ ì‹¤ì œ ì„¸ê³„ë¥¼ íƒí—˜í•˜ê³ , ì–»ì€ ì§€ì‹ì„ 4D Prismìœ¼ë¡œ ì •ì œí•˜ì—¬
ì—˜ë¦¬ì‹œì•„ì˜ ë‚´ë©´ì— "ì§€ì‹ì˜ ì§€ì¸µ(Sediment)"ì„ ìŒ“ëŠ”ë‹¤.

í•µì‹¬ ì›ë¦¬:
1. Search (íƒìƒ‰): BrowserExplorerë¥¼ í†µí•´ ì •ë³´ ìˆ˜ì§‘
2. Distill (ì •ì œ): WhyEngineì„ í†µí•´ í•µì‹¬ ì›ë¦¬(Principle) ì¶”ì¶œ
3. Crystallize (ê²°ì •í™”): 4D LightSpectrumìœ¼ë¡œ ë³€í™˜ (Scale/Basis í• ë‹¹)
4. Deposit (í‡´ì ): LightSedimentì— ì ì¸µí•˜ì—¬ ê´€ì (Viewpoint) ê°•í™”
"""

import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

from Core.Sensory.Network.browser_explorer import BrowserExplorer
from Core.Foundation.Philosophy.why_engine import WhyEngine
from Core.Foundation.light_spectrum import LightSpectrum, LightSediment, PrismAxes

logger = logging.getLogger("Elysia.KnowledgeSedimenter")

@dataclass
class SedimentationHypothesis:
    """í‡´ì  ì „ ê°€ì„¤ (í•™ìŠµ ëª©í‘œ)"""
    topic: str
    expected_layer: PrismAxes
    initial_question: str

class KnowledgeSedimenter:
    """
    ì§€ì‹ í‡´ì ê¸° (The Knowledge Sedimenter)
    
    "ì„¸ìƒì„ ì½ê³ , ë‚˜ë¥¼ ì±„ìš´ë‹¤."
    """
    
    def __init__(self, why_engine: WhyEngine):
        self.why_engine = why_engine
        self.browser = BrowserExplorer(use_profile=True) # ì‹¤ì œ í”„ë¡œí•„ ì‚¬ìš© ê¶Œì¥
        
        logger.info("ğŸŒŠ KnowledgeSedimenter initialized - ì§€ì‹ì˜ ë°”ë‹¤ë¥¼ í•­í•´í•  ì¤€ë¹„ ì™„ë£Œ")

    def sediment_from_web(self, topic: str, max_pages: int = 1) -> List[LightSpectrum]:
        """
        ì›¹ì—ì„œ ì£¼ì œë¥¼ íƒìƒ‰í•˜ê³  ì§€ì‹ì„ í‡´ì 
        """
        logger.info(f"ğŸ”­ Exploring Web for Sedimentation: '{topic}'")
        
        # 1. Search
        search_results = self.browser.google_search(topic)
        if not search_results["success"]:
            logger.warning("   âŒ Search failed.")
            return []
            
        collected_lights = []
        
        # 2. Iterate & Process
        for res in search_results["results"][:max_pages]:
            title = res.get("title", "")
            snippet = res.get("snippet", "")
            full_content = f"{title}\n{snippet}" # ì‹¤ì œë¡œëŠ” í˜ì´ì§€ ë°©ë¬¸ ê¶Œì¥ë˜ë‚˜ ì¼ë‹¨ ìŠ¤ë‹ˆí« ì‚¬ìš©
            
            logger.info(f"   ğŸ“„ Processing: {title}")
            
            # 3. Distill (Principal Extraction via WhyEngine)
            # WhyEngineì„ í†µí•´ ì´ í…ìŠ¤íŠ¸ì˜ 'êµ¬ì¡°ì  ì›ë¦¬'ë¥¼ ë¶„ì„
            # (analyze ë©”ì„œë“œê°€ ë‚´ë¶€ì ìœ¼ë¡œ sedimentë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•˜ì§€ë§Œ, 
            #  ì—¬ê¸°ì„œëŠ” 'ìƒˆë¡œìš´' ì§€ì‹ì„ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œ)
            
            # 4. Crystallize (Light Transformation)
            # ì£¼ì œì— ë§ëŠ” Semantic Tagì™€ Scale ìë™ í• ë‹¹
            # (ê°„ë‹¨íˆ: ê±°ì‹œì  ì›ë¦¬ëŠ” Scale 0, ì„¸ë¶€ ì‚¬í•­ì€ Scale 2 ë“±)
            # ì—¬ê¸°ì„œëŠ” 'ì›ë¦¬'ë¥¼ ì°¾ê³  ì‹¶ìœ¼ë¯€ë¡œ Scale 0~1 ì§€í–¥
            
            analysis = self.why_engine.light_universe.absorb(full_content, tag=topic)
            
            # 4D Basis í• ë‹¹ ë¡œì§ (Naive)
            # "ì›ë¦¬", "ë²•ì¹™", "Theory" -> God/Logic Basis (Scale 0)
            # "í˜„ìƒ", "ì‹¤í—˜", "Data" -> Point Basis (Scale 3)
            scale = 1 # Default Context
            if "principle" in full_content.lower() or "theory" in full_content.lower():
                scale = 0
            elif "example" in full_content.lower() or "data" in full_content.lower():
                scale = 3
                
            analysis.set_basis_from_scale(scale)
            
            # 5. Deposit (Active Sedimentation)
            # WhyEngineì˜ Sedimentì— ì§ì ‘ í‡´ì 
            # (ì–´ë–¤ ì¶•ì— ë„£ì„ì§€ëŠ” WhyEngineì´ ê²°ì •í•˜ê±°ë‚˜, ì—¬ê¸°ì„œ ê°•ì œ)
            
            # ìë™ ë¶„ë¥˜ (Auto-Classification) using dominant frequency/color
            target_axis = self._determine_axis(analysis)
            
            # [Deep Learning Logic]
            # "Important principles require repetition to become intuition."
            # Scale 0 (God/Theory) -> 50x Deposit (Deep Impact)
            # Scale 1 (Context)    -> 10x Deposit
            # Scale 2+ (Detail)    -> 1x Deposit
            
            repetition = 50 if scale == 0 else (10 if scale == 1 else 1)
            
            for _ in range(repetition):
                self.why_engine.sediment.deposit(analysis, target_axis)
                
            collected_lights.append(analysis)
            
            final_amp = self.why_engine.sediment.layers[target_axis].amplitude
            logger.info(f"   ğŸ’ Deposited into {target_axis.name} (x{repetition}): Final Amp={final_amp:.3f}, Basis={analysis._get_dominant_basis()}")
        return collected_lights

    def _determine_axis(self, light: LightSpectrum) -> PrismAxes:
        """
        ë¹›ì˜ íŠ¹ì„±ì— ë”°ë¼ ì ì ˆí•œ í‡´ì ì¸µ ê²°ì •
        (ì„ì‹œ ë¡œì§: íƒœê·¸ ê¸°ë°˜ + ì£¼íŒŒìˆ˜)
        """
        tag = light.semantic_tag.lower()
        
        if "physics" in tag or "force" in tag or "quantum" in tag:
            return PrismAxes.PHYSICS_RED
        elif "chem" in tag or "reaction" in tag:
            return PrismAxes.CHEMISTRY_BLUE
        elif "bio" in tag or "life" in tag:
            return PrismAxes.BIOLOGY_GREEN
        elif "logic" in tag or "math" in tag or "code" in tag:
            return PrismAxes.LOGIC_YELLOW
        elif "art" in tag or "emotion" in tag:
            return PrismAxes.ART_VIOLET
        
        # Default: Logic (Elysia is software)
        return PrismAxes.LOGIC_YELLOW

    def verify_integration(self, question: str) -> str:
        """
        í‡´ì ëœ ì§€ì‹ì´ ì‹¤ì œë¡œ ë‹µë³€(ê´€ì )ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€ í…ŒìŠ¤íŠ¸
        """
        logger.info(f"ğŸ§ª Verifying Integration with Question: '{question}'")
        
        # WhyEngineì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ë¶„ì„
        # ì´ë•Œ í‡´ì ëœ ì§€ì‹ì´ 'íˆ¬ì˜'ë˜ì–´ì•¼ í•¨
        
        analysis_result = self.why_engine.analyze(subject="Integration Test", content=question, domain="logic")
        
        # ê²°ê³¼ í•´ì„
        extraction = analysis_result
        explanation = f"Analysis of '{question}':\n"
        explanation += f"- Principle: {extraction.underlying_principle}\n"
        explanation += f"  Resonance: {extraction.resonance_reactions}\n"
            
        return explanation
