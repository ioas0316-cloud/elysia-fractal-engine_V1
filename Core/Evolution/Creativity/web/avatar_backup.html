<!DOCTYPE html>
<html lang="ko">

<head>
    <meta charset="UTF-8">
    <title>Elysia Avatar | ÏóòÎ¶¨ÏãúÏïÑ ÏïÑÎ∞îÌÉÄ</title>
    <style>
        * {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            background: linear-gradient(135deg, #0a0a1a 0%, #1a0a2a 100%);
            overflow: hidden;
            display: flex;
            height: 100vh;
            font-family: 'Segoe UI', sans-serif;
            color: #e0e0e0;
        }

        /* Left Panel - Thinking Process */
        #thinking-panel {
            width: 300px;
            background: rgba(10, 20, 40, 0.9);
            border-right: 1px solid #52ffa8;
            display: flex;
            flex-direction: column;
            padding: 15px;
        }

        #thinking-panel h3 {
            color: #52ffa8;
            margin: 0 0 10px 0;
            font-size: 14px;
        }

        #thinking-log {
            flex: 1;
            overflow-y: auto;
            font-family: monospace;
            font-size: 11px;
            color: #88aacc;
        }

        #thinking-log .thought {
            padding: 5px;
            margin-bottom: 5px;
            border-left: 2px solid #52ffa8;
            background: rgba(82, 255, 168, 0.05);
        }

        #spirits-display {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 5px;
            margin-top: 10px;
        }

        .spirit {
            text-align: center;
            padding: 5px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 5px;
            font-size: 10px;
        }

        .spirit .bar {
            height: 4px;
            background: #333;
            border-radius: 2px;
            margin-top: 3px;
        }

        .spirit .fill {
            height: 100%;
            border-radius: 2px;
        }

        /* Center - Face */
        #face-panel {
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        #status {
            color: #52ffa8;
            font-family: monospace;
            font-size: 12px;
            margin-bottom: 10px;
        }

        canvas {
            box-shadow: 0 0 50px rgba(82, 255, 168, 0.5);
            border-radius: 20px;
            max-width: 500px;
            max-height: 500px;
        }

        /* Right Panel - Chat */
        #chat-panel {
            width: 350px;
            background: rgba(10, 20, 40, 0.9);
            border-left: 1px solid #52ffa8;
            display: flex;
            flex-direction: column;
        }

        #chat-panel h3 {
            color: #52ffa8;
            margin: 0;
            padding: 15px;
            font-size: 14px;
            border-bottom: 1px solid #333;
        }

        #chat-log {
            flex: 1;
            overflow-y: auto;
            padding: 10px;
        }

        .msg {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 10px;
            max-width: 90%;
        }

        .msg.user {
            background: #1a3a5a;
            margin-left: auto;
            border-bottom-right-radius: 0;
        }

        .msg.elysia {
            background: rgba(82, 255, 168, 0.15);
            margin-right: auto;
            border-bottom-left-radius: 0;
        }

        #chat-input-container {
            padding: 10px;
            border-top: 1px solid #333;
            display: flex;
            gap: 8px;
        }

        #chat-input {
            flex: 1;
            background: #0a1a2a;
            border: 1px solid #52ffa8;
            color: #fff;
            padding: 10px;
            border-radius: 20px;
            outline: none;
        }

        #chat-send {
            background: #52ffa8;
            border: none;
            color: #000;
            padding: 10px 20px;
            border-radius: 20px;
            cursor: pointer;
            font-weight: bold;
        }
    </style>
</head>

<body>
    <!-- Left: Thinking Process -->
    <div id="thinking-panel">
        <h3>üß† ÏÇ¨Í≥† Í≥ºÏ†ï (Thinking)</h3>
        <div id="thinking-log"></div>
        <div id="spirits-display"></div>
    </div>

    <!-- Center: Avatar Face -->
    <div id="face-panel">
        <div id="status">‚óè Connecting... (Click to Wake)</div>
        <canvas id="glcanvas" width="500" height="500"></canvas>
    </div>

    <!-- Right: Chat -->
    <div id="chat-panel">
        <h3>üí¨ ÎåÄÌôî (Chat)</h3>
        <div id="chat-log"></div>
        <div id="chat-input-container">
            <input type="text" id="chat-input" placeholder="Î©îÏãúÏßÄÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî..." />
            <button id="chat-send">Ï†ÑÏÜ°</button>
        </div>
    </div>

    <script>
        const canvas = document.getElementById('glcanvas');
        const gl = canvas.getContext('webgl');

        // State
        let expression = { mouth_curve: 0, eye_open: 1.0, brow_furrow: 0, beat: 0 };
        let audioState = { volume: 0, brightness: 0, noise: 0 };
        let gaze = { x: 0, y: 0 };

        // --- WEBSOCKET CONNECTION ---
        const wsUrl = `ws://${window.location.hostname}:8765`;
        const ws = new WebSocket(wsUrl);
        ws.onopen = () => document.getElementById("status").innerText = "‚óè Linked | üñ±Ô∏è Click to Activate";
        ws.onmessage = (e) => {
            const data = JSON.parse(e.data);

            // 1. Expression Update
            if (data.expression) {
                expression = data.expression;
            }

            // 2. Spirits Update (for thinking panel)
            if (data.spirits) {
                updateSpiritsDisplay(data.spirits);
            }

            // 3. Speech Output (TTS + Chat)
            if (data.type === "speech") {
                addChatMessage(data.content, "elysia");
                speak(data.content, data.spirits); // Pass spirits
                addThought("ÏùëÎãµ: " + data.content.substring(0, 50) + "...");
            }
        };

        // --- CHAT UI ---
        const chatInput = document.getElementById("chat-input");
        const chatSend = document.getElementById("chat-send");
        const chatLog = document.getElementById("chat-log");

        function addChatMessage(text, sender) {
            const msg = document.createElement("div");
            msg.className = "msg " + sender;
            msg.textContent = text;
            chatLog.appendChild(msg);
            chatLog.scrollTop = chatLog.scrollHeight;
        }

        function sendChat() {
            const text = chatInput.value.trim();
            if (!text) return;

            addChatMessage(text, "user");
            addThought("ÏûÖÎ†•: " + text);

            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "text", content: text }));
            }
            chatInput.value = "";
        }

        chatSend.onclick = sendChat;
        chatInput.onkeypress = (e) => { if (e.key === "Enter") sendChat(); };

        // --- THINKING PANEL ---
        const thinkingLog = document.getElementById("thinking-log");
        const spiritsDisplay = document.getElementById("spirits-display");

        function addThought(text) {
            const thought = document.createElement("div");
            thought.className = "thought";
            thought.textContent = new Date().toLocaleTimeString() + " | " + text;
            thinkingLog.appendChild(thought);
            thinkingLog.scrollTop = thinkingLog.scrollHeight;

            // Keep only last 50 thoughts
            while (thinkingLog.children.length > 50) {
                thinkingLog.removeChild(thinkingLog.firstChild);
            }
        }

        function updateSpiritsDisplay(spirits) {
            const colors = {
                fire: "#ff4444", water: "#4488ff", earth: "#88aa44",
                air: "#aaccff", light: "#ffff88", dark: "#665588", aether: "#aa44ff"
            };

            spiritsDisplay.innerHTML = "";
            for (const [name, value] of Object.entries(spirits)) {
                const div = document.createElement("div");
                div.className = "spirit";
                div.innerHTML = `
                    <div>${name}</div>
                    <div class="bar"><div class="fill" style="width:${value * 100}%; background:${colors[name] || '#52ffa8'}"></div></div>
                `;
                spiritsDisplay.appendChild(div);
            }
        }

        // --- VOICE ENGINE (STT & TTS) ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.lang = 'ko-KR';
        recognition.interimResults = false;

        const synthesis = window.speechSynthesis;

        recognition.onresult = (event) => {
            const last = event.results.length - 1;
            const text = event.results[last][0].transcript;
            console.log("Heard: " + text);

            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "text", content: text }));
            }
        };

        recognition.onend = () => {
            if (audioCtx) recognition.start();
        };

        function speak(text, spirits) {
            synthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'ko-KR';

            // Default "Pretty" Voice Settings
            let pitch = 1.2; // Slightly higher base pitch for femininity
            let rate = 1.0;

            if (spirits) {
                // Emotional Modulation
                // High Energy (Fire/Light) -> Faster, Higher Pitch
                // Low Energy (Water/Dark) -> Slower, Lower Pitch
                // Calm (Earth) -> Steady Rate, Normal Pitch

                const fire = spirits.fire || 0;
                const water = spirits.water || 0;
                const light = spirits.light || 0;
                const dark = spirits.dark || 0;
                const earth = spirits.earth || 0;

                if (fire > 0.6 || light > 0.6) {
                    pitch += 0.2;
                    rate += 0.2;
                } else if (water > 0.6 || dark > 0.6) {
                    pitch -= 0.1;
                    rate -= 0.2; // Slower for sadness/calm
                }

                // Whimsy/Aether (Ethereal)
                if ((spirits.aether || 0) > 0.5) {
                    pitch += 0.1;
                    rate -= 0.1; // Slow and high (Ethereal)
                }
            }

            // Clamp
            pitch = Math.max(0.8, Math.min(1.8, pitch));
            rate = Math.max(0.6, Math.min(1.5, rate));

            utterance.pitch = pitch;
            utterance.rate = rate;

            // Fake talk volume
            let talkLoop;
            utterance.onstart = () => {
                talkLoop = setInterval(() => { audioState.volume = Math.random() * 0.4 + 0.1; }, 100);
            };
            utterance.onend = () => {
                clearInterval(talkLoop);
                audioState.volume = 0.0;
            };
            synthesis.speak(utterance);
        }

        // --- VISION & AUDIO ENGINE (Synesthesia) ---
        let audioCtx, analyser, micStream;
        let video, motionCanvas, motionCtx;
        let screenVideo, screenCanvas, screenCtx;
        let lastFrameData = null;

        async function initSystems() {
            if (audioCtx) return;

            try {
                // 1. Audio Setup (More likely to succeed)
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 1024;

                // 2. Try Combined Audio+Video
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });

                    // Video setup
                    video = document.createElement('video');
                    motionCanvas = document.createElement('canvas');
                    motionCanvas.width = 320;
                    motionCanvas.height = 240;
                    motionCtx = motionCanvas.getContext('2d');
                    video.srcObject = stream;
                    video.play();
                    processVision();

                    // Audio from stream
                    micStream = audioCtx.createMediaStreamSource(stream);
                    micStream.connect(analyser);
                    document.getElementById("status").innerHTML = "‚óè Full Synesthesia | üëÅÔ∏è Seeing | üëÇ Hearing <br>[ <a href='#' onclick='initScreen()'>üì∫ Share Screen</a> ]";

                } catch (videoErr) {
                    // Fallback: Audio Only
                    console.warn("Video failed, trying audio-only:", videoErr.message);
                    try {
                        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        micStream = audioCtx.createMediaStreamSource(audioStream);
                        micStream.connect(analyser);
                        document.getElementById("status").innerHTML = "‚óè Audio Only | üëÇ Hearing (No Camera) <br>[ <a href='#' onclick='initScreen()'>üì∫ Share Screen</a> ]";
                    } catch (audioErr) {
                        console.warn("Audio also failed:", audioErr.message);
                        document.getElementById("status").innerHTML = "‚óè No Sensors (Will still respond to text)";
                    }
                }

                // 3. Start processing
                processAudio();
                recognition.start();

            } catch (e) {
                console.error(e);
                document.getElementById("status").innerText = "‚óè Offline Mode (Sensors Unavailable)";
            }
        }

        async function initScreen() {
            try {
                screenVideo = document.createElement('video');
                screenCanvas = document.createElement('canvas');
                screenCanvas.width = 100; // Low res for color avg
                screenCanvas.height = 100;
                screenCtx = screenCanvas.getContext('2d');

                const displayStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
                screenVideo.srcObject = displayStream;
                screenVideo.play();

                // Connect System Audio if available (Chrome tab audio)
                if (displayStream.getAudioTracks().length > 0) {
                    const sysSource = audioCtx.createMediaStreamSource(displayStream);
                    sysSource.connect(analyser); // Mix into same analyser
                }

                processScreen();
                document.getElementById("status").innerHTML += " | üì∫ Watching Screen";

            } catch (e) {
                console.error("Screen Share Error", e);
            }
        }

        function processScreen() {
            if (screenVideo && screenVideo.readyState === screenVideo.HAVE_ENOUGH_DATA) {
                screenCtx.drawImage(screenVideo, 0, 0, 100, 100);
                const frame = screenCtx.getImageData(0, 0, 100, 100);
                const data = frame.data;

                let r = 0, g = 0, b = 0;
                for (let i = 0; i < data.length; i += 4) {
                    r += data[i];
                    g += data[i + 1];
                    b += data[i + 2];
                }
                const pixels = data.length / 4;
                r = Math.floor(r / pixels);
                g = Math.floor(g / pixels);
                b = Math.floor(b / pixels);

                // Send Atmosphere
                if (ws && ws.readyState === WebSocket.OPEN && Math.random() < 0.05) {
                    ws.send(JSON.stringify({
                        type: "screen_atmosphere",
                        r: r, g: g, b: b
                    }));
                }
            }
            requestAnimationFrame(processScreen);
        }

        function processAudio() {
            if (!analyser) return;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteFrequencyData(dataArray);

            // A. Volume (Energy)
            let sum = 0;
            // B. Spectral Centroid (Brightness/Tone)
            let weightedSum = 0;

            // Bands for Vowel Visemes
            let lowSum = 0, highSum = 0;

            for (let i = 0; i < bufferLength; i++) {
                const val = dataArray[i];
                sum += val;
                weightedSum += val * i;

                if (i < bufferLength * 0.1) lowSum += val;
                else if (i > bufferLength * 0.3) highSum += val;
            }

            let avg = sum / bufferLength;
            // Normalize brightness (0 to ~200 typically for speech)
            let centroid = sum > 0 ? weightedSum / sum : 0;
            let brightness = centroid / (bufferLength / 2); // Roughly 0 to 1

            if (!synthesis.speaking) {
                audioState.volume = avg / 256;
                audioState.brightness = brightness;
            }

            // Viseme Width
            let lowAvg = lowSum / (bufferLength * 0.1 || 1);
            let highAvg = highSum / (bufferLength * 0.7 || 1);
            let width = (highAvg - lowAvg) / 50.0;
            expression.mouth_width = Math.max(-0.8, Math.min(0.8, width));

            // Send Deep Analysis to Soul
            if (ws && ws.readyState === WebSocket.OPEN && Math.random() < 0.1) {
                ws.send(JSON.stringify({
                    type: "audio_analysis",
                    volume: audioState.volume,
                    brightness: audioState.brightness, // Nuance: Tone Color
                    noise: 0 // TODO: Turbulence
                }));
            }

            requestAnimationFrame(processAudio);
        }

        function processVision() {
            if (video && video.readyState === video.HAVE_ENOUGH_DATA) {
                motionCtx.drawImage(video, 0, 0, 320, 240);
                const frame = motionCtx.getImageData(0, 0, 320, 240);
                const data = frame.data;
                const length = data.length;

                let sumX = 0, sumY = 0, count = 0;

                if (lastFrameData) {
                    // Skip pixels for perf
                    for (let i = 0; i < length; i += 16) {
                        const diff = Math.abs(data[i] - lastFrameData[i]) +
                            Math.abs(data[i + 1] - lastFrameData[i + 1]);
                        if (diff > 50) {
                            const index = i / 4;
                            sumX += (index % 320);
                            sumY += Math.floor(index / 320);
                            count++;
                        }
                    }
                }
                lastFrameData = data; // Note: In real app, clone data. Here relying on capture rate.

                if (count > 5) {
                    let avgX = sumX / count;
                    let avgY = sumY / count;
                    // Normalize & Mirror X
                    let targetX = -((avgX / 320) * 2 - 1);
                    let targetY = (avgY / 240) * 2 - 1;

                    gaze.x += (targetX - gaze.x) * 0.1;
                    gaze.y += (targetY - gaze.y) * 0.1;

                    // Send Presence
                    if (ws && ws.readyState === WebSocket.OPEN && Math.random() < 0.05) {
                        ws.send(JSON.stringify({ type: "vision", presence: true, x: gaze.x, y: gaze.y }));
                    }
                }
            }
            requestAnimationFrame(processVision);
        }

        window.addEventListener('click', () => {
            initSystems();
        });

        // --- SHADER ---
        const vsSource = `attribute vec2 a_pos; attribute vec2 a_uv; varying vec2 v_uv; void main(){ gl_Position=vec4(a_pos,0,1); v_uv=a_uv; }`;
        const fsSource = `
            precision mediump float;
            varying vec2 v_uv;
            uniform sampler2D u_img;
            uniform float u_time;
            
            uniform float u_mouth; uniform float u_eye; uniform float u_brow; uniform float u_beat;
            uniform float u_vol; uniform float u_width;
            uniform float u_gx; uniform float u_gy; // Gaze

            void main() {
                vec2 uv = v_uv;
                
                // Flow (Subtle)
                uv.x += sin(u_time*1.0 + uv.x*5.0)*0.00005; // Reduced from 0.0002
                uv.y += cos(u_time*0.8 + uv.y*5.0)*0.00005;
                
                // Gaze (Pupils)
                // Left 0.36, Right 0.64. Radius ~0.06
                // Move uv OPPOSITE to gaze direction to shift pupil texture
                vec2 gOffset = vec2(u_gx, u_gy*0.5) * 0.03;
                float dL = distance(uv, vec2(0.36, 0.53));
                float dR = distance(uv, vec2(0.64, 0.53));
                if(dL < 0.06) uv -= gOffset * (1.0 - dL/0.06);
                if(dR < 0.06) uv -= gOffset * (1.0 - dR/0.06);

                // Breathing
                uv.y += sin(u_time*2.0)*0.003 * uv.y;

                // Mouth
                vec2 mPos = vec2(0.5, 0.33);
                float dM = distance(uv, mPos);
                if (dM < 0.15) {
                    float inf = 1.0 - dM/0.15;
                    // Smile
                    float xd = abs(uv.x - 0.5);
                    uv.y -= xd * u_mouth * 0.2 * inf;
                    // Width
                    uv.x -= (uv.x - 0.5) * u_width * 0.4 * inf;
                    // Audio
                    if(uv.y < 0.33) uv.y += u_vol * 0.15 * inf;
                }

                // Blink Mechanism (Simplified)
                // Only distort UVs if eye is closed (u_eye < 0.5)
                if (u_eye < 0.8) {
                    if(dL < 0.08 || dR < 0.08) {
                        float lid = 0.53; // Eye center Y
                        // Squeeze Y towards center to simulate closing
                        uv.y = lid + (uv.y - lid) / (u_eye + 0.1); 
                    }
                }

                vec4 c = texture2D(u_img, uv);
                
                // NO BLUSH - Pure texture only
                gl_FragColor = c;
            }
        `;

        function create(type, src) {
            const s = gl.createShader(type); gl.shaderSource(s, src); gl.compileShader(s);
            if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) console.error(gl.getShaderInfoLog(s));
            return s;
        }
        const prog = gl.createProgram();
        gl.attachShader(prog, create(gl.VERTEX_SHADER, vsSource));
        gl.attachShader(prog, create(gl.FRAGMENT_SHADER, fsSource));
        gl.linkProgram(prog); gl.useProgram(prog);

        const buf = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, buf);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]), gl.STATIC_DRAW);
        const aPos = gl.getAttribLocation(prog, "a_pos");
        gl.enableVertexAttribArray(aPos); gl.vertexAttribPointer(aPos, 2, gl.FLOAT, false, 0, 0);

        const tBuf = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, tBuf);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]), gl.STATIC_DRAW);
        const aUv = gl.getAttribLocation(prog, "a_uv");
        gl.enableVertexAttribArray(aUv); gl.vertexAttribPointer(aUv, 2, gl.FLOAT, false, 0, 0);

        const tex = gl.createTexture();
        const img = new Image(); img.src = "elysia_face.png";
        img.onload = () => {
            gl.bindTexture(gl.TEXTURE_2D, tex);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            render(0);
        };

        const locs = {
            time: gl.getUniformLocation(prog, "u_time"),
            mouth: gl.getUniformLocation(prog, "u_mouth"),
            eye: gl.getUniformLocation(prog, "u_eye"),
            brow: gl.getUniformLocation(prog, "u_brow"),
            beat: gl.getUniformLocation(prog, "u_beat"),
            vol: gl.getUniformLocation(prog, "u_vol"),
            width: gl.getUniformLocation(prog, "u_width"),
            gx: gl.getUniformLocation(prog, "u_gx"),
            gy: gl.getUniformLocation(prog, "u_gy")
        };

        function render(t) {
            gl.uniform1f(locs.time, t * 0.001);
            gl.uniform1f(locs.mouth, expression.mouth_curve);
            gl.uniform1f(locs.eye, expression.eye_open);
            gl.uniform1f(locs.brow, expression.brow_furrow);
            gl.uniform1f(locs.beat, expression.beat);
            gl.uniform1f(locs.vol, audioState.volume * 2.5);
            gl.uniform1f(locs.width, expression.mouth_width || 0);
            gl.uniform1f(locs.gx, gaze.x);
            gl.uniform1f(locs.gy, gaze.y);

            gl.drawArrays(gl.TRIANGLES, 0, 6);
            requestAnimationFrame(render);
        }
    </script>
</body>

</html>